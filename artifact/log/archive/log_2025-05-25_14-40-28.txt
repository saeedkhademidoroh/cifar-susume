
ğŸ“œ  Logging experiment output:
/content/drive/MyDrive/src/cifar-susume/artifact/log/log_2025-05-25_14-40-28.txt

ğŸ¯  _load_previous_results

âš™ï¸   Piplining experiment 1/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_base.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r1 with 'm9_base'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d[0][0]      â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation          â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation[0][0]  â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_1[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_1[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_2[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2        â”‚ (None, 32, 32,    â”‚          0 â”‚ add[0][0]         â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_2[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_3[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_3        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_3[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_4[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_2[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_4        â”‚ (None, 32, 32,    â”‚          0 â”‚ add_1[0][0]       â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_4[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_5[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_5        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_5[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_6[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_2 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_4[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_6        â”‚ (None, 32, 32,    â”‚          0 â”‚ add_2[0][0]       â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_6[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_7[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_7        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_7[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_8[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_6[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_3 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_9[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_8        â”‚ (None, 16, 16,    â”‚          0 â”‚ add_3[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_8[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_10[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_9        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_9[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_11[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_4 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_8[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_10       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_4[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_10[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_12[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_11       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_11[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_13[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_5 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_10[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_12       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_5[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_12[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_14[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_13       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_13[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_15[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_12[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_6 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_14       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_6[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_14[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_17[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_15       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_15[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_18[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_7 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_14[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_16       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_7[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_16[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_19[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_17       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_17[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_20[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_8 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_16[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_18       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_8[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_18[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)       â”‚ (None, 10)        â”‚        650 â”‚ global_average_pâ€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m9_r1_m9_base at epoch_161

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.1
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 170
Test-Time Augment:  ON â€” running 5 augmented passes per sample
Epochs:             200
Batch Size:         128
Epoch 162/200

Epoch 162: val_accuracy improved from -inf to 0.79400, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 162: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_162.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_162

ğŸ•’  Recording time at 18:11

313/313 - 24s - 76ms/step - accuracy: 0.8184 - loss: 0.7699 - val_accuracy: 0.7940 - val_loss: 0.8041 - learning_rate: 5.0000e-04
Epoch 163/200

Epoch 163: val_accuracy improved from 0.79400 to 0.80220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 163: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_163.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_163

ğŸ•’  Recording time at 18:11

313/313 - 14s - 45ms/step - accuracy: 0.8641 - loss: 0.5271 - val_accuracy: 0.8022 - val_loss: 0.7244 - learning_rate: 5.0000e-04
Epoch 164/200

Epoch 164: val_accuracy improved from 0.80220 to 0.80720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 164: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_164.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_164

ğŸ•’  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.8926 - loss: 0.4417 - val_accuracy: 0.8072 - val_loss: 0.7178 - learning_rate: 5.0000e-04
Epoch 165/200

Epoch 165: val_accuracy improved from 0.80720 to 0.80960, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 165: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_165.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_165

ğŸ•’  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.9136 - loss: 0.3803 - val_accuracy: 0.8096 - val_loss: 0.7255 - learning_rate: 5.0000e-04
Epoch 166/200

Epoch 166: val_accuracy did not improve from 0.80960

Epoch 166: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_166.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_166

ğŸ•’  Recording time at 18:12

313/313 - 14s - 45ms/step - accuracy: 0.9291 - loss: 0.3399 - val_accuracy: 0.8078 - val_loss: 0.7350 - learning_rate: 5.0000e-04
Epoch 167/200

Epoch 167: val_accuracy did not improve from 0.80960

Epoch 167: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_167.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_167

ğŸ•’  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.9439 - loss: 0.3005 - val_accuracy: 0.8006 - val_loss: 0.7580 - learning_rate: 5.0000e-04
Epoch 168/200

Epoch 168: val_accuracy did not improve from 0.80960

Epoch 168: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_168.keras

Epoch 168: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_168

ğŸ•’  Recording time at 18:13

313/313 - 14s - 46ms/step - accuracy: 0.9562 - loss: 0.2676 - val_accuracy: 0.8016 - val_loss: 0.7673 - learning_rate: 5.0000e-04
Epoch 169/200

Epoch 169: val_accuracy did not improve from 0.80960

Epoch 169: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_169.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_169

ğŸ•’  Recording time at 18:13

313/313 - 15s - 47ms/step - accuracy: 0.9711 - loss: 0.2317 - val_accuracy: 0.8014 - val_loss: 0.7716 - learning_rate: 5.0000e-05
Epoch 170/200

Epoch 170: val_accuracy did not improve from 0.80960

Epoch 170: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_170.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_170

ğŸ•’  Recording time at 18:13

313/313 - 15s - 46ms/step - accuracy: 0.9733 - loss: 0.2284 - val_accuracy: 0.8030 - val_loss: 0.7714 - learning_rate: 5.0000e-05
Epoch 171/200

Epoch 171: val_accuracy did not improve from 0.80960

Epoch 171: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_171.keras

Epoch 171: ReduceLROnPlateau reducing learning rate to 1e-05.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_171

ğŸ•’  Recording time at 18:13

313/313 - 14s - 46ms/step - accuracy: 0.9747 - loss: 0.2234 - val_accuracy: 0.8046 - val_loss: 0.7740 - learning_rate: 5.0000e-05
Epoch 172/200

Epoch 172: val_accuracy did not improve from 0.80960

Epoch 172: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_172.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_172

ğŸ•’  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9765 - loss: 0.2204 - val_accuracy: 0.8034 - val_loss: 0.7758 - learning_rate: 1.0000e-05
Epoch 173/200

Epoch 173: val_accuracy did not improve from 0.80960

Epoch 173: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_173.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_173

ğŸ•’  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9761 - loss: 0.2211 - val_accuracy: 0.8038 - val_loss: 0.7759 - learning_rate: 1.0000e-05
Epoch 174/200

Epoch 174: val_accuracy did not improve from 0.80960

Epoch 174: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_174.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_174

ğŸ•’  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9756 - loss: 0.2217 - val_accuracy: 0.8038 - val_loss: 0.7759 - learning_rate: 1.0000e-05
Epoch 175/200

Epoch 175: val_accuracy did not improve from 0.80960

Epoch 175: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_175.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_175

ğŸ•’  Recording time at 18:14

313/313 - 15s - 46ms/step - accuracy: 0.9759 - loss: 0.2197 - val_accuracy: 0.8032 - val_loss: 0.7767 - learning_rate: 1.0000e-05
Epoch 176/200

Epoch 176: val_accuracy did not improve from 0.80960

Epoch 176: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_176.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_176

ğŸ•’  Recording time at 18:14

313/313 - 15s - 46ms/step - accuracy: 0.9775 - loss: 0.2190 - val_accuracy: 0.8042 - val_loss: 0.7771 - learning_rate: 1.0000e-05
Epoch 177/200

Epoch 177: val_accuracy did not improve from 0.80960

Epoch 177: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_177.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_177

ğŸ•’  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9774 - loss: 0.2183 - val_accuracy: 0.8042 - val_loss: 0.7771 - learning_rate: 1.0000e-05
Epoch 178/200

Epoch 178: val_accuracy did not improve from 0.80960

Epoch 178: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_178.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_178

ğŸ•’  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9778 - loss: 0.2174 - val_accuracy: 0.8040 - val_loss: 0.7775 - learning_rate: 1.0000e-05
Epoch 179/200

Epoch 179: val_accuracy did not improve from 0.80960

Epoch 179: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_179.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_179

ğŸ•’  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9778 - loss: 0.2172 - val_accuracy: 0.8044 - val_loss: 0.7781 - learning_rate: 1.0000e-05
Epoch 180/200

Epoch 180: val_accuracy did not improve from 0.80960

Epoch 180: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_180.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_180

ğŸ•’  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9768 - loss: 0.2188 - val_accuracy: 0.8050 - val_loss: 0.7789 - learning_rate: 1.0000e-05
Epoch 180: early stopping
Restoring model weights from the end of the best epoch: 165.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ“ˆ  TTA applied â€” averaged over 5 runs

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 1,
    "config_name": "m9_base",
    "date": "2025-05-25",
    "time": "14:46:31",
    "duration": "0:06:02",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": 0.1,
        "patience": 3,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.21722985804080963,
    "min_train_loss_epoch": 18,
    "max_train_acc": 0.9778249859809875,
    "max_train_acc_epoch": 17,
    "min_val_loss": 0.7178073525428772,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.8095999956130981,
    "max_val_acc_epoch": 4,
    "final_test_loss": 0.6421958804130554,
    "final_test_acc": 0.8518999814987183
  }
]

âœ…   m9 run 1 with 'm9_base' successfully executed

âš™ï¸   Piplining experiment 2/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_legacy.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m6_r1 with 'm6_legacy'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_1       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚        896 â”‚ input_layer_1[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_21[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_19       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_22 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_19[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_22[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_20       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_23 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_20[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_23[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_9 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_19[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_21       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_9[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_24 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_21[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_24[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_22       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_25 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_22[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_25[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_10 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_21[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_23       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_10[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_27 (Conv2D)  â”‚ (None, 16, 16,    â”‚     18,496 â”‚ activation_23[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_27[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_24       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_28 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_24[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_28[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_26 (Conv2D)  â”‚ (None, 16, 16,    â”‚      2,112 â”‚ activation_23[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_11 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ conv2d_26[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_25       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_11[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_29 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_25[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_29[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_26       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_30 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_26[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_30[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_12 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ activation_25[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_27       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_12[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_32 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚     73,856 â”‚ activation_27[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_32[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_28       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_33 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_28[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_33[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_31 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚      8,320 â”‚ activation_27[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_13 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_31[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_29       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_13[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_34 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_29[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_34[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_30       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_35 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_30[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_35[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_14 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_29[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_31       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_14[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 128)       â”‚          0 â”‚ activation_31[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)   â”‚ (None, 128)       â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)     â”‚ (None, 10)        â”‚      1,290 â”‚ dropout[0][0]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 0 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  OFF
Epochs:             100
Batch Size:         32
Epoch 1/100

Epoch 1: val_accuracy improved from -inf to 0.38720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 18:17

1250/1250 - 27s - 21ms/step - accuracy: 0.3486 - loss: 2.1334 - val_accuracy: 0.3872 - val_loss: 2.2016 - learning_rate: 0.0500
Epoch 2/100

Epoch 2: val_accuracy improved from 0.38720 to 0.55360, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 18:17

1250/1250 - 14s - 11ms/step - accuracy: 0.5486 - loss: 1.5537 - val_accuracy: 0.5536 - val_loss: 1.5417 - learning_rate: 0.0500
Epoch 3/100

Epoch 3: val_accuracy did not improve from 0.55360

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 18:17

1250/1250 - 14s - 11ms/step - accuracy: 0.6394 - loss: 1.3539 - val_accuracy: 0.5416 - val_loss: 1.6438 - learning_rate: 0.0500
Epoch 4/100

Epoch 4: val_accuracy improved from 0.55360 to 0.59680, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.6870 - loss: 1.2757 - val_accuracy: 0.5968 - val_loss: 1.5545 - learning_rate: 0.0500
Epoch 5/100

Epoch 5: val_accuracy did not improve from 0.59680

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_05.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_5

ğŸ•’  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7120 - loss: 1.2492 - val_accuracy: 0.5362 - val_loss: 1.8778 - learning_rate: 0.0500
Epoch 6/100

Epoch 6: val_accuracy improved from 0.59680 to 0.60440, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_06.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_6

ğŸ•’  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7242 - loss: 1.2324 - val_accuracy: 0.6044 - val_loss: 1.6845 - learning_rate: 0.0500
Epoch 7/100

Epoch 7: val_accuracy improved from 0.60440 to 0.69220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_07.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_7

ğŸ•’  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7357 - loss: 1.2288 - val_accuracy: 0.6922 - val_loss: 1.2949 - learning_rate: 0.0500
Epoch 8/100

Epoch 8: val_accuracy did not improve from 0.69220

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_08.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_8

ğŸ•’  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7461 - loss: 1.2226 - val_accuracy: 0.6752 - val_loss: 1.4182 - learning_rate: 0.0500
Epoch 9/100

Epoch 9: val_accuracy did not improve from 0.69220

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_09.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_9

ğŸ•’  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7458 - loss: 1.2268 - val_accuracy: 0.6192 - val_loss: 1.6468 - learning_rate: 0.0500
Epoch 10/100

Epoch 10: val_accuracy did not improve from 0.69220

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_10.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_10

ğŸ•’  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7523 - loss: 1.2222 - val_accuracy: 0.6718 - val_loss: 1.5163 - learning_rate: 0.0500
Epoch 11/100

Epoch 11: val_accuracy did not improve from 0.69220

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_11.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_11

ğŸ•’  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7566 - loss: 1.2233 - val_accuracy: 0.6700 - val_loss: 1.5401 - learning_rate: 0.0500
Epoch 12/100

Epoch 12: val_accuracy did not improve from 0.69220

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_12.keras

Epoch 12: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_12

ğŸ•’  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7605 - loss: 1.2234 - val_accuracy: 0.5540 - val_loss: 2.1300 - learning_rate: 0.0500
Epoch 13/100

Epoch 13: val_accuracy improved from 0.69220 to 0.73340, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_13.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_13

ğŸ•’  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8209 - loss: 0.9897 - val_accuracy: 0.7334 - val_loss: 1.2561 - learning_rate: 0.0250
Epoch 14/100

Epoch 14: val_accuracy did not improve from 0.73340

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_14.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_14

ğŸ•’  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8284 - loss: 0.9320 - val_accuracy: 0.7322 - val_loss: 1.2128 - learning_rate: 0.0250
Epoch 15/100

Epoch 15: val_accuracy did not improve from 0.73340

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_15.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_15

ğŸ•’  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8260 - loss: 0.9455 - val_accuracy: 0.6816 - val_loss: 1.3792 - learning_rate: 0.0250
Epoch 16/100

Epoch 16: val_accuracy did not improve from 0.73340

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_16.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_16

ğŸ•’  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8308 - loss: 0.9437 - val_accuracy: 0.6132 - val_loss: 1.6371 - learning_rate: 0.0250
Epoch 17/100

Epoch 17: val_accuracy did not improve from 0.73340

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_17.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_17

ğŸ•’  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8344 - loss: 0.9459 - val_accuracy: 0.7028 - val_loss: 1.4423 - learning_rate: 0.0250
Epoch 18/100

Epoch 18: val_accuracy improved from 0.73340 to 0.78120, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_18.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_18

ğŸ•’  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8374 - loss: 0.9517 - val_accuracy: 0.7812 - val_loss: 1.1349 - learning_rate: 0.0250
Epoch 19/100

Epoch 19: val_accuracy did not improve from 0.78120

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_19.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_19

ğŸ•’  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8413 - loss: 0.9501 - val_accuracy: 0.6996 - val_loss: 1.4932 - learning_rate: 0.0250
Epoch 20/100

Epoch 20: val_accuracy did not improve from 0.78120

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_20.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_20

ğŸ•’  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8401 - loss: 0.9630 - val_accuracy: 0.6574 - val_loss: 1.6702 - learning_rate: 0.0250
Epoch 21/100

Epoch 21: val_accuracy did not improve from 0.78120

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_21.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_21

ğŸ•’  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8411 - loss: 0.9702 - val_accuracy: 0.6948 - val_loss: 1.4395 - learning_rate: 0.0250
Epoch 22/100

Epoch 22: val_accuracy improved from 0.78120 to 0.78480, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_22.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_22

ğŸ•’  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8444 - loss: 0.9720 - val_accuracy: 0.7848 - val_loss: 1.1605 - learning_rate: 0.0250
Epoch 23/100

Epoch 23: val_accuracy did not improve from 0.78480

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_23.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_23

ğŸ•’  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8458 - loss: 0.9767 - val_accuracy: 0.7336 - val_loss: 1.3498 - learning_rate: 0.0250
Epoch 24/100

Epoch 24: val_accuracy did not improve from 0.78480

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_24.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_24

ğŸ•’  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8477 - loss: 0.9766 - val_accuracy: 0.7688 - val_loss: 1.2396 - learning_rate: 0.0250
Epoch 25/100

Epoch 25: val_accuracy did not improve from 0.78480

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_25.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_25

ğŸ•’  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8493 - loss: 0.9770 - val_accuracy: 0.7272 - val_loss: 1.3799 - learning_rate: 0.0250
Epoch 26/100

Epoch 26: val_accuracy did not improve from 0.78480

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_26.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_26

ğŸ•’  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.8492 - loss: 0.9765 - val_accuracy: 0.7694 - val_loss: 1.1950 - learning_rate: 0.0250
Epoch 27/100

Epoch 27: val_accuracy did not improve from 0.78480

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_27.keras

Epoch 27: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_27

ğŸ•’  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.8498 - loss: 0.9852 - val_accuracy: 0.7566 - val_loss: 1.2905 - learning_rate: 0.0250
Epoch 28/100

Epoch 28: val_accuracy improved from 0.78480 to 0.80720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_28.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_28

ğŸ•’  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.9094 - loss: 0.7684 - val_accuracy: 0.8072 - val_loss: 1.0563 - learning_rate: 0.0125
Epoch 29/100

Epoch 29: val_accuracy did not improve from 0.80720

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_29.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_29

ğŸ•’  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.9257 - loss: 0.6734 - val_accuracy: 0.8058 - val_loss: 1.0492 - learning_rate: 0.0125
Epoch 30/100

Epoch 30: val_accuracy did not improve from 0.80720

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_30.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_30

ğŸ•’  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9175 - loss: 0.6821 - val_accuracy: 0.7866 - val_loss: 1.1216 - learning_rate: 0.0125
Epoch 31/100

Epoch 31: val_accuracy did not improve from 0.80720

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_31.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_31

ğŸ•’  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9143 - loss: 0.6930 - val_accuracy: 0.7470 - val_loss: 1.4144 - learning_rate: 0.0125
Epoch 32/100

Epoch 32: val_accuracy did not improve from 0.80720

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_32.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_32

ğŸ•’  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9150 - loss: 0.6933 - val_accuracy: 0.7592 - val_loss: 1.2430 - learning_rate: 0.0125
Epoch 33/100

Epoch 33: val_accuracy improved from 0.80720 to 0.81180, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_33.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_33

ğŸ•’  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9134 - loss: 0.7035 - val_accuracy: 0.8118 - val_loss: 1.0465 - learning_rate: 0.0125
Epoch 34/100

Epoch 34: val_accuracy did not improve from 0.81180

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_34.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_34

ğŸ•’  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9190 - loss: 0.6983 - val_accuracy: 0.7620 - val_loss: 1.2311 - learning_rate: 0.0125
Epoch 35/100

Epoch 35: val_accuracy did not improve from 0.81180

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_35.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_35

ğŸ•’  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9172 - loss: 0.6985 - val_accuracy: 0.7938 - val_loss: 1.1554 - learning_rate: 0.0125
Epoch 36/100

Epoch 36: val_accuracy did not improve from 0.81180

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_36.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_36

ğŸ•’  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9200 - loss: 0.6993 - val_accuracy: 0.7752 - val_loss: 1.1677 - learning_rate: 0.0125
Epoch 37/100

Epoch 37: val_accuracy did not improve from 0.81180

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_37.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_37

ğŸ•’  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9188 - loss: 0.7059 - val_accuracy: 0.7776 - val_loss: 1.1959 - learning_rate: 0.0125
Epoch 38/100

Epoch 38: val_accuracy did not improve from 0.81180

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_38.keras

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_38

ğŸ•’  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9182 - loss: 0.7168 - val_accuracy: 0.7928 - val_loss: 1.1652 - learning_rate: 0.0125
Epoch 39/100

Epoch 39: val_accuracy improved from 0.81180 to 0.84420, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_39.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_39

ğŸ•’  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9695 - loss: 0.5564 - val_accuracy: 0.8442 - val_loss: 0.9471 - learning_rate: 0.0063
Epoch 40/100

Epoch 40: val_accuracy improved from 0.84420 to 0.84740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_40.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_40

ğŸ•’  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9895 - loss: 0.4501 - val_accuracy: 0.8474 - val_loss: 0.9084 - learning_rate: 0.0063
Epoch 41/100

Epoch 41: val_accuracy did not improve from 0.84740

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_41.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_41

ğŸ•’  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9912 - loss: 0.3963 - val_accuracy: 0.8410 - val_loss: 0.9220 - learning_rate: 0.0063
Epoch 42/100

Epoch 42: val_accuracy did not improve from 0.84740

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_42.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_42

ğŸ•’  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9841 - loss: 0.3840 - val_accuracy: 0.8260 - val_loss: 0.9827 - learning_rate: 0.0063
Epoch 43/100

Epoch 43: val_accuracy did not improve from 0.84740

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_43.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_43

ğŸ•’  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9669 - loss: 0.4189 - val_accuracy: 0.8122 - val_loss: 1.0386 - learning_rate: 0.0063
Epoch 44/100

Epoch 44: val_accuracy did not improve from 0.84740

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_44.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_44

ğŸ•’  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9606 - loss: 0.4363 - val_accuracy: 0.8186 - val_loss: 0.9724 - learning_rate: 0.0063
Epoch 45/100

Epoch 45: val_accuracy did not improve from 0.84740

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_45.keras

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_45

ğŸ•’  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9616 - loss: 0.4391 - val_accuracy: 0.8224 - val_loss: 0.9451 - learning_rate: 0.0063
Epoch 46/100

Epoch 46: val_accuracy improved from 0.84740 to 0.85040, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_46.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_46

ğŸ•’  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9875 - loss: 0.3611 - val_accuracy: 0.8504 - val_loss: 0.8415 - learning_rate: 0.0031
Epoch 47/100

Epoch 47: val_accuracy improved from 0.85040 to 0.85380, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_47.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_47

ğŸ•’  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9975 - loss: 0.3124 - val_accuracy: 0.8538 - val_loss: 0.8122 - learning_rate: 0.0031
Epoch 48/100

Epoch 48: val_accuracy did not improve from 0.85380

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_48.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_48

ğŸ•’  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9989 - loss: 0.2863 - val_accuracy: 0.8520 - val_loss: 0.7982 - learning_rate: 0.0031
Epoch 49/100

Epoch 49: val_accuracy improved from 0.85380 to 0.85840, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_49.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_49

ğŸ•’  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.2652 - val_accuracy: 0.8584 - val_loss: 0.7673 - learning_rate: 0.0031
Epoch 50/100

Epoch 50: val_accuracy did not improve from 0.85840

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_50.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_50

ğŸ•’  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9996 - loss: 0.2461 - val_accuracy: 0.8584 - val_loss: 0.7479 - learning_rate: 0.0031
Epoch 51/100

Epoch 51: val_accuracy improved from 0.85840 to 0.86200, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_51.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_51

ğŸ•’  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.2293 - val_accuracy: 0.8620 - val_loss: 0.7304 - learning_rate: 0.0031
Epoch 52/100

Epoch 52: val_accuracy did not improve from 0.86200

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_52.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_52

ğŸ•’  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9997 - loss: 0.2130 - val_accuracy: 0.8600 - val_loss: 0.7122 - learning_rate: 0.0031
Epoch 53/100

Epoch 53: val_accuracy did not improve from 0.86200

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_53.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_53

ğŸ•’  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9997 - loss: 0.1980 - val_accuracy: 0.8582 - val_loss: 0.6992 - learning_rate: 0.0031
Epoch 54/100

Epoch 54: val_accuracy did not improve from 0.86200

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_54.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_54

ğŸ•’  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.1859 - val_accuracy: 0.8566 - val_loss: 0.6882 - learning_rate: 0.0031
Epoch 55/100

Epoch 55: val_accuracy did not improve from 0.86200

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_55.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_55

ğŸ•’  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1726 - val_accuracy: 0.8616 - val_loss: 0.6596 - learning_rate: 0.0031
Epoch 56/100

Epoch 56: val_accuracy did not improve from 0.86200

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_56.keras

Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_56

ğŸ•’  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1610 - val_accuracy: 0.8620 - val_loss: 0.6500 - learning_rate: 0.0031
Epoch 57/100

Epoch 57: val_accuracy improved from 0.86200 to 0.86300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_57.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_57

ğŸ•’  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1523 - val_accuracy: 0.8630 - val_loss: 0.6425 - learning_rate: 0.0016
Epoch 58/100

Epoch 58: val_accuracy did not improve from 0.86300

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_58.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_58

ğŸ•’  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1465 - val_accuracy: 0.8614 - val_loss: 0.6365 - learning_rate: 0.0016
Epoch 59/100

Epoch 59: val_accuracy did not improve from 0.86300

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_59.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_59

ğŸ•’  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1415 - val_accuracy: 0.8614 - val_loss: 0.6321 - learning_rate: 0.0016
Epoch 60/100

Epoch 60: val_accuracy did not improve from 0.86300

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_60.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_60

ğŸ•’  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1362 - val_accuracy: 0.8598 - val_loss: 0.6257 - learning_rate: 0.0016
Epoch 61/100

Epoch 61: val_accuracy did not improve from 0.86300

Epoch 61: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_61.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_61

ğŸ•’  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1313 - val_accuracy: 0.8608 - val_loss: 0.6216 - learning_rate: 0.0016
Epoch 62/100

Epoch 62: val_accuracy did not improve from 0.86300

Epoch 62: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_62.keras

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_62

ğŸ•’  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1266 - val_accuracy: 0.8610 - val_loss: 0.6172 - learning_rate: 0.0016
Epoch 63/100

Epoch 63: val_accuracy did not improve from 0.86300

Epoch 63: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_63.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_63

ğŸ•’  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1232 - val_accuracy: 0.8598 - val_loss: 0.6141 - learning_rate: 7.8125e-04
Epoch 64/100

Epoch 64: val_accuracy did not improve from 0.86300

Epoch 64: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_64.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_64

ğŸ•’  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1210 - val_accuracy: 0.8610 - val_loss: 0.6061 - learning_rate: 7.8125e-04
Epoch 65/100

Epoch 65: val_accuracy did not improve from 0.86300

Epoch 65: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_65.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_65

ğŸ•’  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1187 - val_accuracy: 0.8612 - val_loss: 0.6056 - learning_rate: 7.8125e-04
Epoch 66/100

Epoch 66: val_accuracy did not improve from 0.86300

Epoch 66: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_66.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_66

ğŸ•’  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1166 - val_accuracy: 0.8616 - val_loss: 0.6027 - learning_rate: 7.8125e-04
Epoch 67/100

Epoch 67: val_accuracy did not improve from 0.86300

Epoch 67: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_67.keras

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_67

ğŸ•’  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1146 - val_accuracy: 0.8604 - val_loss: 0.6023 - learning_rate: 7.8125e-04
Epoch 68/100

Epoch 68: val_accuracy did not improve from 0.86300

Epoch 68: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_68.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_68

ğŸ•’  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1130 - val_accuracy: 0.8612 - val_loss: 0.5983 - learning_rate: 3.9063e-04
Epoch 69/100

Epoch 69: val_accuracy did not improve from 0.86300

Epoch 69: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_69.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_69

ğŸ•’  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1120 - val_accuracy: 0.8618 - val_loss: 0.5988 - learning_rate: 3.9063e-04
Epoch 70/100

Epoch 70: val_accuracy did not improve from 0.86300

Epoch 70: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_70.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_70

ğŸ•’  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1110 - val_accuracy: 0.8608 - val_loss: 0.5978 - learning_rate: 3.9063e-04
Epoch 71/100

Epoch 71: val_accuracy did not improve from 0.86300

Epoch 71: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_71.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_71

ğŸ•’  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1100 - val_accuracy: 0.8608 - val_loss: 0.5977 - learning_rate: 3.9063e-04
Epoch 72/100

Epoch 72: val_accuracy did not improve from 0.86300

Epoch 72: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_72.keras

Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_72

ğŸ•’  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1091 - val_accuracy: 0.8610 - val_loss: 0.5960 - learning_rate: 3.9063e-04
Epoch 72: early stopping
Restoring model weights from the end of the best epoch: 57.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 6,
    "run": 1,
    "config_name": "m6_legacy",
    "date": "2025-05-25",
    "time": "15:03:44",
    "duration": "0:17:13",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 0,
        "factor": 0.5,
        "patience": 5,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 0.10906655341386795,
    "min_train_loss_epoch": 72,
    "max_train_acc": 1.0,
    "max_train_acc_epoch": 63,
    "min_val_loss": 0.5960099697113037,
    "min_val_loss_epoch": 72,
    "max_val_acc": 0.8629999756813049,
    "max_val_acc_epoch": 57,
    "final_test_loss": 0.7124512195587158,
    "final_test_acc": 0.8601999878883362
  }
]

âœ…   m6 run 1 with 'm6_legacy' successfully executed

âš™ï¸   Piplining experiment 3/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_rebase.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m6_r2 with 'm6_rebase'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_2"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_2       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_36 (Conv2D)  â”‚ (None, 32, 32,    â”‚        896 â”‚ input_layer_2[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_36[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_32       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_37 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_32[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_37[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_33       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_38 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_33[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_38[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_15 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_32[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_34       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_15[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_39 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_34[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_39[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_35       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_40 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_35[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_40[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_16 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_34[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_36       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_16[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_42 (Conv2D)  â”‚ (None, 16, 16,    â”‚     18,496 â”‚ activation_36[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_42[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_37       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_43 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_37[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_43[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_41 (Conv2D)  â”‚ (None, 16, 16,    â”‚      2,112 â”‚ activation_36[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_17 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ conv2d_41[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_38       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_17[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_44 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_38[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_44[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_39       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_45 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_39[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_45[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_18 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ activation_38[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_40       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_18[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_47 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚     73,856 â”‚ activation_40[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_47[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_41       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_48 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_41[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_48[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_46 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚      8,320 â”‚ activation_40[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_19 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_46[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_42       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_19[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_49 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_42[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_49[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_43       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_50 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_43[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_50[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_20 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_42[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_44       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_20[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 128)       â”‚          0 â”‚ activation_44[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout) â”‚ (None, 128)       â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)     â”‚ (None, 10)        â”‚      1,290 â”‚ dropout_1[0][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  ON â€” running 5 augmented passes per sample
Epochs:             100
Batch Size:         32

ğŸ”  StepLR applied â€” epoch 0, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 0, learning rate set to 0.01000

Epoch 1/100

Epoch 1: val_accuracy improved from -inf to 0.34300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 18:34

1250/1250 - 24s - 19ms/step - accuracy: 0.3490 - loss: 2.2070 - val_accuracy: 0.3430 - val_loss: 2.4257

ğŸ”  StepLR applied â€” epoch 1, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 1, learning rate set to 0.02000

Epoch 2/100

Epoch 2: val_accuracy improved from 0.34300 to 0.46600, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 18:34

1250/1250 - 14s - 11ms/step - accuracy: 0.4949 - loss: 1.7875 - val_accuracy: 0.4660 - val_loss: 1.8872

ğŸ”  StepLR applied â€” epoch 2, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 2, learning rate set to 0.03000

Epoch 3/100

Epoch 3: val_accuracy did not improve from 0.46600

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.5614 - loss: 1.5819 - val_accuracy: 0.4242 - val_loss: 2.2471

ğŸ”  StepLR applied â€” epoch 3, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 3, learning rate set to 0.04000

Epoch 4/100

Epoch 4: val_accuracy improved from 0.46600 to 0.54480, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6033 - loss: 1.4883 - val_accuracy: 0.5448 - val_loss: 1.7313

ğŸ”  StepLR applied â€” epoch 4, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 4, learning rate set to 0.05000

Epoch 5/100

Epoch 5: val_accuracy did not improve from 0.54480

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_05.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_5

ğŸ•’  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6266 - loss: 1.4788 - val_accuracy: 0.5286 - val_loss: 1.8470

ğŸ”  StepLR applied â€” epoch 5, learning rate set to 0.05000

Epoch 6/100

Epoch 6: val_accuracy improved from 0.54480 to 0.58000, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_06.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_6

ğŸ•’  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6453 - loss: 1.4462 - val_accuracy: 0.5800 - val_loss: 1.7034

ğŸ”  StepLR applied â€” epoch 6, learning rate set to 0.05000

Epoch 7/100

Epoch 7: val_accuracy did not improve from 0.58000

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_07.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_7

ğŸ•’  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6625 - loss: 1.4300 - val_accuracy: 0.5546 - val_loss: 1.7715

ğŸ”  StepLR applied â€” epoch 7, learning rate set to 0.05000

Epoch 8/100

Epoch 8: val_accuracy did not improve from 0.58000

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_08.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_8

ğŸ•’  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6708 - loss: 1.4144 - val_accuracy: 0.5770 - val_loss: 1.8003

ğŸ”  StepLR applied â€” epoch 8, learning rate set to 0.05000

Epoch 9/100

Epoch 9: val_accuracy did not improve from 0.58000

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_09.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_9

ğŸ•’  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6828 - loss: 1.4109 - val_accuracy: 0.4722 - val_loss: 2.3730

ğŸ”  StepLR applied â€” epoch 9, learning rate set to 0.05000

Epoch 10/100

Epoch 10: val_accuracy did not improve from 0.58000

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_10.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_10

ğŸ•’  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6806 - loss: 1.4180 - val_accuracy: 0.4818 - val_loss: 2.2048

ğŸ”  StepLR applied â€” epoch 10, learning rate set to 0.05000

Epoch 11/100

Epoch 11: val_accuracy did not improve from 0.58000

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_11.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_11

ğŸ•’  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6898 - loss: 1.4019 - val_accuracy: 0.4874 - val_loss: 1.9737

ğŸ”  StepLR applied â€” epoch 11, learning rate set to 0.05000

Epoch 12/100

Epoch 12: val_accuracy improved from 0.58000 to 0.58740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_12.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_12

ğŸ•’  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6917 - loss: 1.4105 - val_accuracy: 0.5874 - val_loss: 1.8314

ğŸ”  StepLR applied â€” epoch 12, learning rate set to 0.05000

Epoch 13/100

Epoch 13: val_accuracy improved from 0.58740 to 0.58760, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_13.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_13

ğŸ•’  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6957 - loss: 1.4066 - val_accuracy: 0.5876 - val_loss: 1.7643

ğŸ”  StepLR applied â€” epoch 13, learning rate set to 0.05000

Epoch 14/100

Epoch 14: val_accuracy did not improve from 0.58760

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_14.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_14

ğŸ•’  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6985 - loss: 1.4068 - val_accuracy: 0.5684 - val_loss: 1.7364

ğŸ”  StepLR applied â€” epoch 14, learning rate set to 0.05000

Epoch 15/100

Epoch 15: val_accuracy did not improve from 0.58760

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_15.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_15

ğŸ•’  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6977 - loss: 1.4072 - val_accuracy: 0.5818 - val_loss: 1.7638

ğŸ”  StepLR applied â€” epoch 15, learning rate set to 0.05000

Epoch 16/100

Epoch 16: val_accuracy improved from 0.58760 to 0.62180, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_16.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_16

ğŸ•’  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7041 - loss: 1.4043 - val_accuracy: 0.6218 - val_loss: 1.6960

ğŸ”  StepLR applied â€” epoch 16, learning rate set to 0.05000

Epoch 17/100

Epoch 17: val_accuracy did not improve from 0.62180

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_17.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_17

ğŸ•’  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7058 - loss: 1.4072 - val_accuracy: 0.5786 - val_loss: 1.8239

ğŸ”  StepLR applied â€” epoch 17, learning rate set to 0.05000

Epoch 18/100

Epoch 18: val_accuracy improved from 0.62180 to 0.64520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_18.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_18

ğŸ•’  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7066 - loss: 1.4099 - val_accuracy: 0.6452 - val_loss: 1.5998

ğŸ”  StepLR applied â€” epoch 18, learning rate set to 0.05000

Epoch 19/100

Epoch 19: val_accuracy did not improve from 0.64520

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_19.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_19

ğŸ•’  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7103 - loss: 1.4040 - val_accuracy: 0.6098 - val_loss: 1.7417

ğŸ”  StepLR applied â€” epoch 19, learning rate set to 0.05000

Epoch 20/100

Epoch 20: val_accuracy did not improve from 0.64520

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_20.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_20

ğŸ•’  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7087 - loss: 1.4203 - val_accuracy: 0.6026 - val_loss: 1.7973

ğŸ”  StepLR applied â€” epoch 20, learning rate set to 0.05000

Epoch 21/100

Epoch 21: val_accuracy improved from 0.64520 to 0.65680, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_21.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_21

ğŸ•’  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7113 - loss: 1.4085 - val_accuracy: 0.6568 - val_loss: 1.5570

ğŸ”  StepLR applied â€” epoch 21, learning rate set to 0.05000

Epoch 22/100

Epoch 22: val_accuracy did not improve from 0.65680

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_22.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_22

ğŸ•’  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7133 - loss: 1.4098 - val_accuracy: 0.5494 - val_loss: 1.9204

ğŸ”  StepLR applied â€” epoch 22, learning rate set to 0.05000

Epoch 23/100

Epoch 23: val_accuracy did not improve from 0.65680

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_23.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_23

ğŸ•’  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7167 - loss: 1.4047 - val_accuracy: 0.6014 - val_loss: 1.7473

ğŸ”  StepLR applied â€” epoch 23, learning rate set to 0.05000

Epoch 24/100

Epoch 24: val_accuracy did not improve from 0.65680

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_24.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_24

ğŸ•’  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7102 - loss: 1.4114 - val_accuracy: 0.5538 - val_loss: 1.8093

ğŸ”  StepLR applied â€” epoch 24, learning rate set to 0.05000

Epoch 25/100

Epoch 25: val_accuracy did not improve from 0.65680

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_25.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_25

ğŸ•’  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7154 - loss: 1.4121 - val_accuracy: 0.6260 - val_loss: 1.6438

ğŸ”  StepLR applied â€” epoch 25, learning rate set to 0.05000

Epoch 26/100

Epoch 26: val_accuracy did not improve from 0.65680

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_26.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_26

ğŸ•’  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7179 - loss: 1.4036 - val_accuracy: 0.5530 - val_loss: 1.9996

ğŸ”  StepLR applied â€” epoch 26, learning rate set to 0.05000

Epoch 27/100

Epoch 27: val_accuracy did not improve from 0.65680

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_27.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_27

ğŸ•’  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7183 - loss: 1.4040 - val_accuracy: 0.5606 - val_loss: 1.9666

ğŸ”  StepLR applied â€” epoch 27, learning rate set to 0.05000

Epoch 28/100

Epoch 28: val_accuracy did not improve from 0.65680

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_28.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_28

ğŸ•’  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7162 - loss: 1.4136 - val_accuracy: 0.6174 - val_loss: 1.6526

ğŸ”  StepLR applied â€” epoch 28, learning rate set to 0.05000

Epoch 29/100

Epoch 29: val_accuracy did not improve from 0.65680

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_29.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_29

ğŸ•’  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7176 - loss: 1.3987 - val_accuracy: 0.6406 - val_loss: 1.6566

ğŸ”  StepLR applied â€” epoch 29, learning rate set to 0.05000

Epoch 30/100

Epoch 30: val_accuracy did not improve from 0.65680

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_30.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_30

ğŸ•’  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7189 - loss: 1.4048 - val_accuracy: 0.6480 - val_loss: 1.6249

ğŸ”  StepLR applied â€” epoch 30, learning rate set to 0.05000

Epoch 31/100

Epoch 31: val_accuracy did not improve from 0.65680

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_31.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_31

ğŸ•’  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7199 - loss: 1.4129 - val_accuracy: 0.6540 - val_loss: 1.6328

ğŸ”  StepLR applied â€” epoch 31, learning rate set to 0.05000

Epoch 32/100

Epoch 32: val_accuracy did not improve from 0.65680

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_32.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_32

ğŸ•’  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7206 - loss: 1.4077 - val_accuracy: 0.6388 - val_loss: 1.6326

ğŸ”  StepLR applied â€” epoch 32, learning rate set to 0.05000

Epoch 33/100

Epoch 33: val_accuracy improved from 0.65680 to 0.66400, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_33.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_33

ğŸ•’  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7238 - loss: 1.4014 - val_accuracy: 0.6640 - val_loss: 1.5346

ğŸ”  StepLR applied â€” epoch 33, learning rate set to 0.05000

Epoch 34/100

Epoch 34: val_accuracy did not improve from 0.66400

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_34.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_34

ğŸ•’  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7192 - loss: 1.4095 - val_accuracy: 0.6036 - val_loss: 1.7646

ğŸ”  StepLR applied â€” epoch 34, learning rate set to 0.05000

Epoch 35/100

Epoch 35: val_accuracy did not improve from 0.66400

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_35.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_35

ğŸ•’  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7224 - loss: 1.4022 - val_accuracy: 0.6300 - val_loss: 1.6947

ğŸ”  StepLR applied â€” epoch 35, learning rate set to 0.05000

Epoch 36/100

Epoch 36: val_accuracy did not improve from 0.66400

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_36.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_36

ğŸ•’  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7199 - loss: 1.4087 - val_accuracy: 0.5994 - val_loss: 1.7751

ğŸ”  StepLR applied â€” epoch 36, learning rate set to 0.05000

Epoch 37/100

Epoch 37: val_accuracy did not improve from 0.66400

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_37.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_37

ğŸ•’  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7253 - loss: 1.3956 - val_accuracy: 0.5672 - val_loss: 1.8838

ğŸ”  StepLR applied â€” epoch 37, learning rate set to 0.05000

Epoch 38/100

Epoch 38: val_accuracy did not improve from 0.66400

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_38.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_38

ğŸ•’  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7236 - loss: 1.4058 - val_accuracy: 0.5726 - val_loss: 1.9171

ğŸ”  StepLR applied â€” epoch 38, learning rate set to 0.05000

Epoch 39/100

Epoch 39: val_accuracy did not improve from 0.66400

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_39.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_39

ğŸ•’  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7221 - loss: 1.4139 - val_accuracy: 0.5594 - val_loss: 1.9635

ğŸ”  StepLR applied â€” epoch 39, learning rate set to 0.05000

Epoch 40/100

Epoch 40: val_accuracy did not improve from 0.66400

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_40.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_40

ğŸ•’  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7255 - loss: 1.4036 - val_accuracy: 0.5726 - val_loss: 1.8687

ğŸ”  StepLR applied â€” epoch 40, learning rate set to 0.05000

Epoch 41/100

Epoch 41: val_accuracy did not improve from 0.66400

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_41.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_41

ğŸ•’  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4045 - val_accuracy: 0.6094 - val_loss: 1.8171

ğŸ”  StepLR applied â€” epoch 41, learning rate set to 0.05000

Epoch 42/100

Epoch 42: val_accuracy did not improve from 0.66400

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_42.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_42

ğŸ•’  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7260 - loss: 1.4046 - val_accuracy: 0.5898 - val_loss: 1.7790

ğŸ”  StepLR applied â€” epoch 42, learning rate set to 0.05000

Epoch 43/100

Epoch 43: val_accuracy did not improve from 0.66400

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_43.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_43

ğŸ•’  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4046 - val_accuracy: 0.5794 - val_loss: 2.0507

ğŸ”  StepLR applied â€” epoch 43, learning rate set to 0.05000

Epoch 44/100

Epoch 44: val_accuracy did not improve from 0.66400

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_44.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_44

ğŸ•’  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7261 - loss: 1.3963 - val_accuracy: 0.6404 - val_loss: 1.6546

ğŸ”  StepLR applied â€” epoch 44, learning rate set to 0.05000

Epoch 45/100

Epoch 45: val_accuracy improved from 0.66400 to 0.68580, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_45.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_45

ğŸ•’  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7261 - loss: 1.4052 - val_accuracy: 0.6858 - val_loss: 1.5176

ğŸ”  StepLR applied â€” epoch 45, learning rate set to 0.05000

Epoch 46/100

Epoch 46: val_accuracy did not improve from 0.68580

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_46.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_46

ğŸ•’  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7270 - loss: 1.3998 - val_accuracy: 0.6330 - val_loss: 1.6918

ğŸ”  StepLR applied â€” epoch 46, learning rate set to 0.05000

Epoch 47/100

Epoch 47: val_accuracy did not improve from 0.68580

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_47.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_47

ğŸ•’  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7262 - loss: 1.4058 - val_accuracy: 0.6446 - val_loss: 1.6173

ğŸ”  StepLR applied â€” epoch 47, learning rate set to 0.05000

Epoch 48/100

Epoch 48: val_accuracy did not improve from 0.68580

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_48.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_48

ğŸ•’  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4086 - val_accuracy: 0.5608 - val_loss: 2.0059

ğŸ”  StepLR applied â€” epoch 48, learning rate set to 0.05000

Epoch 49/100

Epoch 49: val_accuracy did not improve from 0.68580

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_49.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_49

ğŸ•’  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7294 - loss: 1.3996 - val_accuracy: 0.5266 - val_loss: 2.1115

ğŸ”  StepLR applied â€” epoch 49, learning rate set to 0.05000

Epoch 50/100

Epoch 50: val_accuracy did not improve from 0.68580

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_50.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_50

ğŸ•’  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7306 - loss: 1.3959 - val_accuracy: 0.4774 - val_loss: 2.5955

ğŸ”  StepLR applied â€” epoch 50, learning rate set to 0.05000

Epoch 51/100

Epoch 51: val_accuracy did not improve from 0.68580

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_51.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_51

ğŸ•’  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7256 - loss: 1.4062 - val_accuracy: 0.6318 - val_loss: 1.6524

ğŸ”  StepLR applied â€” epoch 51, learning rate set to 0.05000

Epoch 52/100

Epoch 52: val_accuracy did not improve from 0.68580

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_52.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_52

ğŸ•’  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7282 - loss: 1.4057 - val_accuracy: 0.6300 - val_loss: 1.7030

ğŸ”  StepLR applied â€” epoch 52, learning rate set to 0.05000

Epoch 53/100

Epoch 53: val_accuracy did not improve from 0.68580

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_53.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_53

ğŸ•’  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7265 - loss: 1.4013 - val_accuracy: 0.5626 - val_loss: 1.9467

ğŸ”  StepLR applied â€” epoch 53, learning rate set to 0.05000

Epoch 54/100

Epoch 54: val_accuracy did not improve from 0.68580

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_54.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_54

ğŸ•’  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7248 - loss: 1.4136 - val_accuracy: 0.5086 - val_loss: 2.0775

ğŸ”  StepLR applied â€” epoch 54, learning rate set to 0.05000

Epoch 55/100

Epoch 55: val_accuracy did not improve from 0.68580

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_55.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_55

ğŸ•’  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7276 - loss: 1.4078 - val_accuracy: 0.5236 - val_loss: 2.0100

ğŸ”  StepLR applied â€” epoch 55, learning rate set to 0.05000

Epoch 56/100

Epoch 56: val_accuracy did not improve from 0.68580

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_56.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_56

ğŸ•’  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7292 - loss: 1.4041 - val_accuracy: 0.6522 - val_loss: 1.6272

ğŸ”  StepLR applied â€” epoch 56, learning rate set to 0.05000

Epoch 57/100

Epoch 57: val_accuracy did not improve from 0.68580

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_57.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_57

ğŸ•’  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7301 - loss: 1.4078 - val_accuracy: 0.6364 - val_loss: 1.7368

ğŸ”  StepLR applied â€” epoch 57, learning rate set to 0.05000

Epoch 58/100

Epoch 58: val_accuracy did not improve from 0.68580

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_58.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_58

ğŸ•’  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7312 - loss: 1.4102 - val_accuracy: 0.6000 - val_loss: 1.8182

ğŸ”  StepLR applied â€” epoch 58, learning rate set to 0.05000

Epoch 59/100

Epoch 59: val_accuracy did not improve from 0.68580

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_59.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_59

ğŸ•’  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7270 - loss: 1.4105 - val_accuracy: 0.5868 - val_loss: 1.8197

ğŸ”  StepLR applied â€” epoch 59, learning rate set to 0.05000

Epoch 60/100

Epoch 60: val_accuracy did not improve from 0.68580

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_60.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_60

ğŸ•’  Recording time at 18:48

1250/1250 - 14s - 11ms/step - accuracy: 0.7317 - loss: 1.4013 - val_accuracy: 0.6732 - val_loss: 1.5377
Epoch 60: early stopping
Restoring model weights from the end of the best epoch: 45.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ“ˆ  TTA applied â€” averaged over 5 runs

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 6,
    "run": 2,
    "config_name": "m6_rebase",
    "date": "2025-05-25",
    "time": "15:18:47",
    "duration": "0:15:02",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 1.3956196308135986,
    "min_train_loss_epoch": 37,
    "max_train_acc": 0.7317000031471252,
    "max_train_acc_epoch": 60,
    "min_val_loss": 1.5175951719284058,
    "min_val_loss_epoch": 45,
    "max_val_acc": 0.6858000159263611,
    "max_val_acc_epoch": 45,
    "final_test_loss": 1.467358946800232,
    "final_test_acc": 0.7242000102996826
  }
]

âœ…   m6 run 2 with 'm6_rebase' successfully executed

âš™ï¸   Piplining experiment 4/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_tuned.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r2 with 'm9_tuned'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_3"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_3       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_51 (Conv2D)  â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer_3[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_51[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_45       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_52 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_45[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_52[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_46       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_53 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_46[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_53[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_21 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_45[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_47       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_21[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_54 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_47[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_54[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_48       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_55 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_48[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_55[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_22 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_47[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_49       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_22[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_56 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_49[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_56[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_50       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_57 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_50[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_57[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_23 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_49[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_51       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_23[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_58 (Conv2D)  â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_51[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_58[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_52       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_59 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_52[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_59[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_60 (Conv2D)  â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_51[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_24 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_60[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_53       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_24[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_61 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_53[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_61[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_54       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_62 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_54[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_62[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_25 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_53[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_55       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_25[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_63 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_55[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_63[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_56       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_64 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_56[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_64[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_26 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_55[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_57       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_26[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_65 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_57[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_65[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_58       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_66 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_58[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_66[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_67 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_57[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_27 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_67[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_59       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_27[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_68 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_59[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_68[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_60       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_69 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_60[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_69[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_28 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_59[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_61       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_28[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_70 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_61[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_70[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_62       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_71 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_62[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_71[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_29 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_61[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_63       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_29[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_63[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)     â”‚ (None, 10)        â”‚        650 â”‚ global_average_pâ€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0001)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 170
Test-Time Augment:  ON â€” running 5 augmented passes per sample
Epochs:             200
Batch Size:         128

ğŸ”  StepLR applied â€” epoch 0, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 0, learning rate set to 0.01000

Epoch 1/200

Epoch 1: val_accuracy improved from -inf to 0.32020, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 18:49

313/313 - 30s - 95ms/step - accuracy: 0.3678 - loss: 1.7875 - val_accuracy: 0.3202 - val_loss: 2.0255

ğŸ”  StepLR applied â€” epoch 1, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 1, learning rate set to 0.02000

Epoch 2/200

Epoch 2: val_accuracy improved from 0.32020 to 0.37220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 18:49

313/313 - 9s - 27ms/step - accuracy: 0.5103 - loss: 1.4106 - val_accuracy: 0.3722 - val_loss: 2.1162

ğŸ”  StepLR applied â€” epoch 2, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 2, learning rate set to 0.03000

Epoch 3/200

Epoch 3: val_accuracy improved from 0.37220 to 0.43760, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 18:49

313/313 - 9s - 28ms/step - accuracy: 0.6143 - loss: 1.1589 - val_accuracy: 0.4376 - val_loss: 2.3789

ğŸ”  StepLR applied â€” epoch 3, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 3, learning rate set to 0.04000

Epoch 4/200

Epoch 4: val_accuracy improved from 0.43760 to 0.55200, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 18:50

313/313 - 9s - 27ms/step - accuracy: 0.6813 - loss: 0.9873 - val_accuracy: 0.5520 - val_loss: 1.5126

ğŸ”  StepLR applied â€” epoch 4, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 4, learning rate set to 0.05000

Epoch 5/200

Epoch 5: val_accuracy did not improve from 0.55200

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_05.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_5

ğŸ•’  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.7207 - loss: 0.8950 - val_accuracy: 0.5382 - val_loss: 1.7122

ğŸ”  StepLR applied â€” epoch 5, learning rate set to 0.05000

Epoch 6/200

Epoch 6: val_accuracy improved from 0.55200 to 0.65800, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_06.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_6

ğŸ•’  Recording time at 18:50

313/313 - 8s - 27ms/step - accuracy: 0.7622 - loss: 0.7837 - val_accuracy: 0.6580 - val_loss: 1.0946

ğŸ”  StepLR applied â€” epoch 6, learning rate set to 0.05000

Epoch 7/200

Epoch 7: val_accuracy improved from 0.65800 to 0.71300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_07.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_7

ğŸ•’  Recording time at 18:50

313/313 - 8s - 27ms/step - accuracy: 0.7959 - loss: 0.7041 - val_accuracy: 0.7130 - val_loss: 0.9871

ğŸ”  StepLR applied â€” epoch 7, learning rate set to 0.05000

Epoch 8/200

Epoch 8: val_accuracy did not improve from 0.71300

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_08.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_8

ğŸ•’  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8156 - loss: 0.6534 - val_accuracy: 0.5248 - val_loss: 1.9036

ğŸ”  StepLR applied â€” epoch 8, learning rate set to 0.05000

Epoch 9/200

Epoch 9: val_accuracy did not improve from 0.71300

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_09.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_9

ğŸ•’  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8333 - loss: 0.6055 - val_accuracy: 0.6412 - val_loss: 1.2340

ğŸ”  StepLR applied â€” epoch 9, learning rate set to 0.05000

Epoch 10/200

Epoch 10: val_accuracy did not improve from 0.71300

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_10.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_10

ğŸ•’  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8467 - loss: 0.5707 - val_accuracy: 0.7058 - val_loss: 1.0921

ğŸ”  StepLR applied â€” epoch 10, learning rate set to 0.05000

Epoch 11/200

Epoch 11: val_accuracy did not improve from 0.71300

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_11.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_11

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8589 - loss: 0.5392 - val_accuracy: 0.6884 - val_loss: 1.0423

ğŸ”  StepLR applied â€” epoch 11, learning rate set to 0.05000

Epoch 12/200

Epoch 12: val_accuracy did not improve from 0.71300

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_12.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_12

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8729 - loss: 0.5096 - val_accuracy: 0.6594 - val_loss: 1.3295

ğŸ”  StepLR applied â€” epoch 12, learning rate set to 0.05000

Epoch 13/200

Epoch 13: val_accuracy did not improve from 0.71300

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_13.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_13

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8834 - loss: 0.4871 - val_accuracy: 0.6726 - val_loss: 1.3992

ğŸ”  StepLR applied â€” epoch 13, learning rate set to 0.05000

Epoch 14/200

Epoch 14: val_accuracy did not improve from 0.71300

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_14.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_14

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8924 - loss: 0.4661 - val_accuracy: 0.6880 - val_loss: 1.3026

ğŸ”  StepLR applied â€” epoch 14, learning rate set to 0.05000

Epoch 15/200

Epoch 15: val_accuracy did not improve from 0.71300

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_15.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_15

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8992 - loss: 0.4511 - val_accuracy: 0.6610 - val_loss: 1.5440

ğŸ”  StepLR applied â€” epoch 15, learning rate set to 0.05000

Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.71300

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_16.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_16

ğŸ•’  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.9081 - loss: 0.4327 - val_accuracy: 0.6906 - val_loss: 1.3796

ğŸ”  StepLR applied â€” epoch 16, learning rate set to 0.05000

Epoch 17/200

Epoch 17: val_accuracy improved from 0.71300 to 0.72140, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_17.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_17

ğŸ•’  Recording time at 18:51

313/313 - 9s - 27ms/step - accuracy: 0.9156 - loss: 0.4184 - val_accuracy: 0.7214 - val_loss: 1.3642

ğŸ”  StepLR applied â€” epoch 17, learning rate set to 0.05000

Epoch 18/200

Epoch 18: val_accuracy improved from 0.72140 to 0.72500, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_18.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_18

ğŸ•’  Recording time at 18:52

313/313 - 8s - 27ms/step - accuracy: 0.9201 - loss: 0.4109 - val_accuracy: 0.7250 - val_loss: 1.2447

ğŸ”  StepLR applied â€” epoch 18, learning rate set to 0.05000

Epoch 19/200

Epoch 19: val_accuracy did not improve from 0.72500

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_19.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_19

ğŸ•’  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9240 - loss: 0.4062 - val_accuracy: 0.6302 - val_loss: 2.0122

ğŸ”  StepLR applied â€” epoch 19, learning rate set to 0.05000

Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.72500

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_20.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_20

ğŸ•’  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9275 - loss: 0.4027 - val_accuracy: 0.6792 - val_loss: 1.9238

ğŸ”  StepLR applied â€” epoch 20, learning rate set to 0.05000

Epoch 21/200

Epoch 21: val_accuracy did not improve from 0.72500

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_21.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_21

ğŸ•’  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9325 - loss: 0.3949 - val_accuracy: 0.7236 - val_loss: 1.3729

ğŸ”  StepLR applied â€” epoch 21, learning rate set to 0.05000

Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.72500

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_22.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_22

ğŸ•’  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9366 - loss: 0.3863 - val_accuracy: 0.7088 - val_loss: 1.6697

ğŸ”  StepLR applied â€” epoch 22, learning rate set to 0.05000

Epoch 23/200

Epoch 23: val_accuracy improved from 0.72500 to 0.73620, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_23.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_23

ğŸ•’  Recording time at 18:52

313/313 - 8s - 27ms/step - accuracy: 0.9383 - loss: 0.3823 - val_accuracy: 0.7362 - val_loss: 1.3619

ğŸ”  StepLR applied â€” epoch 23, learning rate set to 0.05000

Epoch 24/200

Epoch 24: val_accuracy improved from 0.73620 to 0.73740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_24.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_24

ğŸ•’  Recording time at 18:52

313/313 - 9s - 27ms/step - accuracy: 0.9470 - loss: 0.3654 - val_accuracy: 0.7374 - val_loss: 1.3658

ğŸ”  StepLR applied â€” epoch 24, learning rate set to 0.05000

Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.73740

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_25.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_25

ğŸ•’  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9467 - loss: 0.3683 - val_accuracy: 0.7044 - val_loss: 1.5576

ğŸ”  StepLR applied â€” epoch 25, learning rate set to 0.05000

Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.73740

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_26.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_26

ğŸ•’  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9479 - loss: 0.3685 - val_accuracy: 0.6764 - val_loss: 1.9882

ğŸ”  StepLR applied â€” epoch 26, learning rate set to 0.05000

Epoch 27/200

Epoch 27: val_accuracy improved from 0.73740 to 0.74520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_27.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_27

ğŸ•’  Recording time at 18:53

313/313 - 8s - 27ms/step - accuracy: 0.9480 - loss: 0.3709 - val_accuracy: 0.7452 - val_loss: 1.2282

ğŸ”  StepLR applied â€” epoch 27, learning rate set to 0.05000

Epoch 28/200

Epoch 28: val_accuracy improved from 0.74520 to 0.74740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_28.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_28

ğŸ•’  Recording time at 18:53

313/313 - 9s - 29ms/step - accuracy: 0.9557 - loss: 0.3502 - val_accuracy: 0.7474 - val_loss: 1.2927

ğŸ”  StepLR applied â€” epoch 28, learning rate set to 0.05000

Epoch 29/200

Epoch 29: val_accuracy improved from 0.74740 to 0.76700, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_29.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_29

ğŸ•’  Recording time at 18:53

313/313 - 9s - 27ms/step - accuracy: 0.9520 - loss: 0.3659 - val_accuracy: 0.7670 - val_loss: 1.2624

ğŸ”  StepLR applied â€” epoch 29, learning rate set to 0.05000

Epoch 30/200

Epoch 30: val_accuracy did not improve from 0.76700

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_30.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_30

ğŸ•’  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9550 - loss: 0.3592 - val_accuracy: 0.7298 - val_loss: 1.5746

ğŸ”  StepLR applied â€” epoch 30, learning rate set to 0.05000

Epoch 31/200

Epoch 31: val_accuracy did not improve from 0.76700

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_31.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_31

ğŸ•’  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9562 - loss: 0.3534 - val_accuracy: 0.7496 - val_loss: 1.3534

ğŸ”  StepLR applied â€” epoch 31, learning rate set to 0.05000

Epoch 32/200

Epoch 32: val_accuracy did not improve from 0.76700

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_32.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_32

ğŸ•’  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9535 - loss: 0.3650 - val_accuracy: 0.7406 - val_loss: 1.4698

ğŸ”  StepLR applied â€” epoch 32, learning rate set to 0.05000

Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.76700

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_33.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_33

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9597 - loss: 0.3479 - val_accuracy: 0.6880 - val_loss: 1.7370

ğŸ”  StepLR applied â€” epoch 33, learning rate set to 0.05000

Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.76700

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_34.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_34

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9638 - loss: 0.3381 - val_accuracy: 0.7434 - val_loss: 1.5414

ğŸ”  StepLR applied â€” epoch 34, learning rate set to 0.05000

Epoch 35/200

Epoch 35: val_accuracy did not improve from 0.76700

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_35.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_35

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9628 - loss: 0.3422 - val_accuracy: 0.7222 - val_loss: 1.5945

ğŸ”  StepLR applied â€” epoch 35, learning rate set to 0.05000

Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.76700

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_36.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_36

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9591 - loss: 0.3521 - val_accuracy: 0.6694 - val_loss: 2.2073

ğŸ”  StepLR applied â€” epoch 36, learning rate set to 0.05000

Epoch 37/200

Epoch 37: val_accuracy did not improve from 0.76700

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_37.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_37

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9635 - loss: 0.3441 - val_accuracy: 0.7578 - val_loss: 1.3617

ğŸ”  StepLR applied â€” epoch 37, learning rate set to 0.05000

Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.76700

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_38.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_38

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9653 - loss: 0.3363 - val_accuracy: 0.7192 - val_loss: 1.5206

ğŸ”  StepLR applied â€” epoch 38, learning rate set to 0.05000

Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.76700

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_39.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_39

ğŸ•’  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9612 - loss: 0.3484 - val_accuracy: 0.7504 - val_loss: 1.3339

ğŸ”  StepLR applied â€” epoch 39, learning rate set to 0.05000

Epoch 40/200

Epoch 40: val_accuracy did not improve from 0.76700

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_40.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_40

ğŸ•’  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9634 - loss: 0.3409 - val_accuracy: 0.7184 - val_loss: 1.4740

ğŸ”  StepLR applied â€” epoch 40, learning rate set to 0.05000

Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.76700

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_41.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_41

ğŸ•’  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9611 - loss: 0.3504 - val_accuracy: 0.7338 - val_loss: 1.4550

ğŸ”  StepLR applied â€” epoch 41, learning rate set to 0.05000

Epoch 42/200

Epoch 42: val_accuracy did not improve from 0.76700

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_42.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_42

ğŸ•’  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9627 - loss: 0.3451 - val_accuracy: 0.6980 - val_loss: 1.6881

ğŸ”  StepLR applied â€” epoch 42, learning rate set to 0.05000

Epoch 43/200

Epoch 43: val_accuracy did not improve from 0.76700

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_43.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_43

ğŸ•’  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9611 - loss: 0.3514 - val_accuracy: 0.7240 - val_loss: 1.4740

ğŸ”  StepLR applied â€” epoch 43, learning rate set to 0.05000

Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.76700

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_44.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_44

ğŸ•’  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9704 - loss: 0.3266 - val_accuracy: 0.7488 - val_loss: 1.5234
Epoch 44: early stopping
Restoring model weights from the end of the best epoch: 29.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ“ˆ  TTA applied â€” averaged over 5 runs

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 2,
    "config_name": "m9_tuned",
    "date": "2025-05-25",
    "time": "15:26:14",
    "duration": "0:07:26",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.32662540674209595,
    "min_train_loss_epoch": 44,
    "max_train_acc": 0.9703750014305115,
    "max_train_acc_epoch": 44,
    "min_val_loss": 0.9870940446853638,
    "min_val_loss_epoch": 7,
    "max_val_acc": 0.7670000195503235,
    "max_val_acc_epoch": 29,
    "final_test_loss": 1.351456880569458,
    "final_test_acc": 0.771399974822998
  }
]

âœ…   m9 run 2 with 'm9_tuned' successfully executed

âš™ï¸   Piplining experiment 5/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_drop.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r3 with 'm9_drop'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_4"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_4       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_72 (Conv2D)  â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer_4[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_72[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_64       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_73 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_64[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_73[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_65       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_74 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_65[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_74[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_30 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_64[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_66       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_30[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_75 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_66[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_75[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_67       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_76 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_67[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_76[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_31 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_66[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_68       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_31[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_77 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_68[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_77[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_69       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_78 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_69[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_78[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_32 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_68[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_70       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_32[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_79 (Conv2D)  â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_70[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_79[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_71       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_80 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_71[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_80[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_81 (Conv2D)  â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_70[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_33 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_81[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_72       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_33[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_82 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_72[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_82[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_73       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_83 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_73[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_83[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_34 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_72[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_74       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_34[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_84 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_74[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_84[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_75       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_85 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_75[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_85[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_35 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_74[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_76       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_35[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_86 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_76[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_86[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_77       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_87 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_77[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_87[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_88 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_76[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_36 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_88[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_78       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_36[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_89 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_78[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_89[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_79       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_90 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_79[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_90[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_37 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_78[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_80       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_37[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_91 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_80[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_91[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_81       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_92 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_81[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_92[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_38 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_80[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_82       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_38[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_82[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout) â”‚ (None, 64)        â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)     â”‚ (None, 10)        â”‚        650 â”‚ dropout_2[0][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0001)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 160
Test-Time Augment:  ON â€” running 5 augmented passes per sample
Epochs:             200
Batch Size:         128

ğŸ”  StepLR applied â€” epoch 0, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 0, learning rate set to 0.01000

Epoch 1/200

Epoch 1: val_accuracy improved from -inf to 0.22920, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 18:57

313/313 - 30s - 96ms/step - accuracy: 0.3192 - loss: 1.9030 - val_accuracy: 0.2292 - val_loss: 3.1916

ğŸ”  StepLR applied â€” epoch 1, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 1, learning rate set to 0.02000

Epoch 2/200

Epoch 2: val_accuracy improved from 0.22920 to 0.38020, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.4668 - loss: 1.5259 - val_accuracy: 0.3802 - val_loss: 2.2680

ğŸ”  StepLR applied â€” epoch 2, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 2, learning rate set to 0.03000

Epoch 3/200

Epoch 3: val_accuracy improved from 0.38020 to 0.48060, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.5677 - loss: 1.2789 - val_accuracy: 0.4806 - val_loss: 1.8876

ğŸ”  StepLR applied â€” epoch 3, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 3, learning rate set to 0.04000

Epoch 4/200

Epoch 4: val_accuracy improved from 0.48060 to 0.49520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.6316 - loss: 1.1219 - val_accuracy: 0.4952 - val_loss: 1.8482

ğŸ”  StepLR applied â€” epoch 4, learning rate set to 0.05000


ğŸ”¥  WarmupLR applied â€” epoch 4, learning rate set to 0.05000

Epoch 5/200

Epoch 5: val_accuracy improved from 0.49520 to 0.63300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_05.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_5

ğŸ•’  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.6798 - loss: 1.0105 - val_accuracy: 0.6330 - val_loss: 1.2658

ğŸ”  StepLR applied â€” epoch 5, learning rate set to 0.05000

Epoch 6/200

Epoch 6: val_accuracy did not improve from 0.63300

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_06.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_6

ğŸ•’  Recording time at 18:57

313/313 - 8s - 27ms/step - accuracy: 0.7251 - loss: 0.9015 - val_accuracy: 0.5322 - val_loss: 1.9594

ğŸ”  StepLR applied â€” epoch 6, learning rate set to 0.05000

Epoch 7/200

Epoch 7: val_accuracy improved from 0.63300 to 0.67320, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_07.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_7

ğŸ•’  Recording time at 18:57

313/313 - 9s - 27ms/step - accuracy: 0.7547 - loss: 0.8208 - val_accuracy: 0.6732 - val_loss: 1.1420

ğŸ”  StepLR applied â€” epoch 7, learning rate set to 0.05000

Epoch 8/200

Epoch 8: val_accuracy improved from 0.67320 to 0.71460, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_08.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_8

ğŸ•’  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.7811 - loss: 0.7553 - val_accuracy: 0.7146 - val_loss: 0.9816

ğŸ”  StepLR applied â€” epoch 8, learning rate set to 0.05000

Epoch 9/200

Epoch 9: val_accuracy improved from 0.71460 to 0.71560, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_09.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_9

ğŸ•’  Recording time at 18:58

313/313 - 9s - 27ms/step - accuracy: 0.7981 - loss: 0.7169 - val_accuracy: 0.7156 - val_loss: 1.0697

ğŸ”  StepLR applied â€” epoch 9, learning rate set to 0.05000

Epoch 10/200

Epoch 10: val_accuracy did not improve from 0.71560

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_10.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_10

ğŸ•’  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.8156 - loss: 0.6691 - val_accuracy: 0.7060 - val_loss: 1.0624

ğŸ”  StepLR applied â€” epoch 10, learning rate set to 0.05000

Epoch 11/200

Epoch 11: val_accuracy improved from 0.71560 to 0.74700, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_11.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_11

ğŸ•’  Recording time at 18:58

313/313 - 9s - 28ms/step - accuracy: 0.8292 - loss: 0.6390 - val_accuracy: 0.7470 - val_loss: 0.8687

ğŸ”  StepLR applied â€” epoch 11, learning rate set to 0.05000

Epoch 12/200

Epoch 12: val_accuracy did not improve from 0.74700

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_12.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_12

ğŸ•’  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.8392 - loss: 0.6144 - val_accuracy: 0.6732 - val_loss: 1.2394

ğŸ”  StepLR applied â€” epoch 12, learning rate set to 0.05000

Epoch 13/200

Epoch 13: val_accuracy did not improve from 0.74700

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_13.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_13

ğŸ•’  Recording time at 18:58

313/313 - 9s - 28ms/step - accuracy: 0.8503 - loss: 0.5891 - val_accuracy: 0.7274 - val_loss: 1.1147

ğŸ”  StepLR applied â€” epoch 13, learning rate set to 0.05000

Epoch 14/200

Epoch 14: val_accuracy did not improve from 0.74700

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_14.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_14

ğŸ•’  Recording time at 18:58

313/313 - 9s - 27ms/step - accuracy: 0.8605 - loss: 0.5649 - val_accuracy: 0.6822 - val_loss: 1.1741

ğŸ”  StepLR applied â€” epoch 14, learning rate set to 0.05000

Epoch 15/200

Epoch 15: val_accuracy did not improve from 0.74700

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_15.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_15

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8676 - loss: 0.5490 - val_accuracy: 0.7214 - val_loss: 1.1425

ğŸ”  StepLR applied â€” epoch 15, learning rate set to 0.05000

Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.74700

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_16.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_16

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8777 - loss: 0.5227 - val_accuracy: 0.7206 - val_loss: 1.0881

ğŸ”  StepLR applied â€” epoch 16, learning rate set to 0.05000

Epoch 17/200

Epoch 17: val_accuracy did not improve from 0.74700

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_17.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_17

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8836 - loss: 0.5158 - val_accuracy: 0.7114 - val_loss: 1.1080

ğŸ”  StepLR applied â€” epoch 17, learning rate set to 0.05000

Epoch 18/200

Epoch 18: val_accuracy did not improve from 0.74700

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_18.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_18

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8899 - loss: 0.5022 - val_accuracy: 0.7150 - val_loss: 1.2614

ğŸ”  StepLR applied â€” epoch 18, learning rate set to 0.05000

Epoch 19/200

Epoch 19: val_accuracy did not improve from 0.74700

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_19.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_19

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8966 - loss: 0.4877 - val_accuracy: 0.6182 - val_loss: 1.9345

ğŸ”  StepLR applied â€” epoch 19, learning rate set to 0.05000

Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.74700

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_20.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_20

ğŸ•’  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8990 - loss: 0.4895 - val_accuracy: 0.6522 - val_loss: 1.6315

ğŸ”  StepLR applied â€” epoch 20, learning rate set to 0.05000

Epoch 21/200

Epoch 21: val_accuracy improved from 0.74700 to 0.75900, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_21.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_21

ğŸ•’  Recording time at 18:59

313/313 - 9s - 27ms/step - accuracy: 0.9079 - loss: 0.4653 - val_accuracy: 0.7590 - val_loss: 1.1308

ğŸ”  StepLR applied â€” epoch 21, learning rate set to 0.05000

Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.75900

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_22.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_22

ğŸ•’  Recording time at 19:00

313/313 - 8s - 26ms/step - accuracy: 0.9048 - loss: 0.4763 - val_accuracy: 0.7004 - val_loss: 1.4640

ğŸ”  StepLR applied â€” epoch 22, learning rate set to 0.05000

Epoch 23/200

Epoch 23: val_accuracy did not improve from 0.75900

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_23.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_23

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9118 - loss: 0.4670 - val_accuracy: 0.5998 - val_loss: 1.8911

ğŸ”  StepLR applied â€” epoch 23, learning rate set to 0.05000

Epoch 24/200

Epoch 24: val_accuracy did not improve from 0.75900

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_24.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_24

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9153 - loss: 0.4606 - val_accuracy: 0.7248 - val_loss: 1.4108

ğŸ”  StepLR applied â€” epoch 24, learning rate set to 0.05000

Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.75900

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_25.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_25

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9214 - loss: 0.4488 - val_accuracy: 0.7228 - val_loss: 1.2478

ğŸ”  StepLR applied â€” epoch 25, learning rate set to 0.05000

Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.75900

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_26.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_26

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9254 - loss: 0.4405 - val_accuracy: 0.6516 - val_loss: 1.8442

ğŸ”  StepLR applied â€” epoch 26, learning rate set to 0.05000

Epoch 27/200

Epoch 27: val_accuracy did not improve from 0.75900

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_27.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_27

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9265 - loss: 0.4425 - val_accuracy: 0.7512 - val_loss: 1.1791

ğŸ”  StepLR applied â€” epoch 27, learning rate set to 0.05000

Epoch 28/200

Epoch 28: val_accuracy did not improve from 0.75900

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_28.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_28

ğŸ•’  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9299 - loss: 0.4385 - val_accuracy: 0.7574 - val_loss: 1.2305

ğŸ”  StepLR applied â€” epoch 28, learning rate set to 0.05000

Epoch 29/200

Epoch 29: val_accuracy did not improve from 0.75900

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_29.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_29

ğŸ•’  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9341 - loss: 0.4310 - val_accuracy: 0.7456 - val_loss: 1.2688

ğŸ”  StepLR applied â€” epoch 29, learning rate set to 0.05000

Epoch 30/200

Epoch 30: val_accuracy did not improve from 0.75900

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_30.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_30

ğŸ•’  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9361 - loss: 0.4226 - val_accuracy: 0.7244 - val_loss: 1.3107

ğŸ”  StepLR applied â€” epoch 30, learning rate set to 0.05000

Epoch 31/200

Epoch 31: val_accuracy did not improve from 0.75900

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_31.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_31

ğŸ•’  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9369 - loss: 0.4294 - val_accuracy: 0.7360 - val_loss: 1.2586

ğŸ”  StepLR applied â€” epoch 31, learning rate set to 0.05000

Epoch 32/200

Epoch 32: val_accuracy improved from 0.75900 to 0.77960, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_32.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_32

ğŸ•’  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9408 - loss: 0.4176 - val_accuracy: 0.7796 - val_loss: 1.1445

ğŸ”  StepLR applied â€” epoch 32, learning rate set to 0.05000

Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.77960

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_33.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_33

ğŸ•’  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9394 - loss: 0.4215 - val_accuracy: 0.7658 - val_loss: 1.1015

ğŸ”  StepLR applied â€” epoch 33, learning rate set to 0.05000

Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.77960

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_34.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_34

ğŸ•’  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9409 - loss: 0.4246 - val_accuracy: 0.7572 - val_loss: 1.2689

ğŸ”  StepLR applied â€” epoch 34, learning rate set to 0.05000

Epoch 35/200

Epoch 35: val_accuracy did not improve from 0.77960

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_35.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_35

ğŸ•’  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9413 - loss: 0.4243 - val_accuracy: 0.7656 - val_loss: 1.1685

ğŸ”  StepLR applied â€” epoch 35, learning rate set to 0.05000

Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.77960

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_36.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_36

ğŸ•’  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9416 - loss: 0.4255 - val_accuracy: 0.7770 - val_loss: 1.2026

ğŸ”  StepLR applied â€” epoch 36, learning rate set to 0.05000

Epoch 37/200

Epoch 37: val_accuracy did not improve from 0.77960

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_37.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_37

ğŸ•’  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9444 - loss: 0.4170 - val_accuracy: 0.7612 - val_loss: 1.1638

ğŸ”  StepLR applied â€” epoch 37, learning rate set to 0.05000

Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.77960

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_38.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_38

ğŸ•’  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9495 - loss: 0.4051 - val_accuracy: 0.7576 - val_loss: 1.3194

ğŸ”  StepLR applied â€” epoch 38, learning rate set to 0.05000

Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.77960

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_39.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_39

ğŸ•’  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9452 - loss: 0.4169 - val_accuracy: 0.7556 - val_loss: 1.1856

ğŸ”  StepLR applied â€” epoch 39, learning rate set to 0.05000

Epoch 40/200

Epoch 40: val_accuracy did not improve from 0.77960

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_40.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_40

ğŸ•’  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9492 - loss: 0.4077 - val_accuracy: 0.7090 - val_loss: 1.6402

ğŸ”  StepLR applied â€” epoch 40, learning rate set to 0.05000

Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.77960

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_41.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_41

ğŸ•’  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9492 - loss: 0.4084 - val_accuracy: 0.6970 - val_loss: 1.6289

ğŸ”  StepLR applied â€” epoch 41, learning rate set to 0.05000

Epoch 42/200

Epoch 42: val_accuracy did not improve from 0.77960

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_42.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_42

ğŸ•’  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9484 - loss: 0.4156 - val_accuracy: 0.7242 - val_loss: 1.5309

ğŸ”  StepLR applied â€” epoch 42, learning rate set to 0.05000

Epoch 43/200

Epoch 43: val_accuracy did not improve from 0.77960

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_43.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_43

ğŸ•’  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9534 - loss: 0.3997 - val_accuracy: 0.7272 - val_loss: 1.4719

ğŸ”  StepLR applied â€” epoch 43, learning rate set to 0.05000

Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.77960

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_44.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_44

ğŸ•’  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9484 - loss: 0.4118 - val_accuracy: 0.7330 - val_loss: 1.4818

ğŸ”  StepLR applied â€” epoch 44, learning rate set to 0.05000

Epoch 45/200

Epoch 45: val_accuracy did not improve from 0.77960

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_45.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_45

ğŸ•’  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9486 - loss: 0.4159 - val_accuracy: 0.7430 - val_loss: 1.3060

ğŸ”  StepLR applied â€” epoch 45, learning rate set to 0.05000

Epoch 46/200

Epoch 46: val_accuracy did not improve from 0.77960

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_46.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_46

ğŸ•’  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9543 - loss: 0.3983 - val_accuracy: 0.7722 - val_loss: 1.1816

ğŸ”  StepLR applied â€” epoch 46, learning rate set to 0.05000

Epoch 47/200

Epoch 47: val_accuracy did not improve from 0.77960

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_47.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_47

ğŸ•’  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9526 - loss: 0.4051 - val_accuracy: 0.6984 - val_loss: 1.7791
Epoch 47: early stopping
Restoring model weights from the end of the best epoch: 32.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ“ˆ  TTA applied â€” averaged over 5 runs

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 3,
    "config_name": "m9_drop",
    "date": "2025-05-25",
    "time": "15:34:09",
    "duration": "0:07:55",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 160
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.39833468198776245,
    "min_train_loss_epoch": 46,
    "max_train_acc": 0.9543250203132629,
    "max_train_acc_epoch": 46,
    "min_val_loss": 0.868700385093689,
    "min_val_loss_epoch": 11,
    "max_val_acc": 0.7796000242233276,
    "max_val_acc_epoch": 32,
    "final_test_loss": 1.280393123626709,
    "final_test_acc": 0.7699999809265137
  }
]

âœ…   m9 run 3 with 'm9_drop' successfully executed

ğŸ“¦   Completed 5 total experiment runs
