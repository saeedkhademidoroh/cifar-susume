
📜  Logging experiment output:
/content/drive/MyDrive/src/cifar-susume/artifact/log/log_2025-05-25_14-40-28.txt

🎯  _load_previous_results

⚙️   Piplining experiment 1/5

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_base.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

🚀  Launching experiment m9_r1 with 'm9_base'

🎯  build_dataset

🎯  build_augmentation_transform

🎯  build_normalization_transform

🎯  build_normalization_transform

🎯  build_model

Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer         │ (None, 32, 32, 3) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d (Conv2D)     │ (None, 32, 32,    │        448 │ input_layer[0][0] │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalization │ (None, 32, 32,    │         64 │ conv2d[0][0]      │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation          │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_1 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation[0][0]  │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_1[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_1        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_2 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation_1[0][… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_2[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add (Add)           │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_2        │ (None, 32, 32,    │          0 │ add[0][0]         │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_3 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation_2[0][… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_3[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_3        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_4 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation_3[0][… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_4[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_1 (Add)         │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_2[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_4        │ (None, 32, 32,    │          0 │ add_1[0][0]       │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_5 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation_4[0][… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_5[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_5        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_6 (Conv2D)   │ (None, 32, 32,    │      2,320 │ activation_5[0][… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_6[0][0]    │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_2 (Add)         │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_4[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_6        │ (None, 32, 32,    │          0 │ add_2[0][0]       │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_7 (Conv2D)   │ (None, 16, 16,    │      4,640 │ activation_6[0][… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_7[0][0]    │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_7        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_8 (Conv2D)   │ (None, 16, 16,    │      9,248 │ activation_7[0][… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_8[0][0]    │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_9 (Conv2D)   │ (None, 16, 16,    │        544 │ activation_6[0][… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_3 (Add)         │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ conv2d_9[0][0]    │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_8        │ (None, 16, 16,    │          0 │ add_3[0][0]       │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_10 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_8[0][… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_10[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_9        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_11 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_9[0][… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_11[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_4 (Add)         │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_8[0][… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_10       │ (None, 16, 16,    │          0 │ add_4[0][0]       │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_12 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_10[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_12[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_11       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_13 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_11[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_13[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_5 (Add)         │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_10[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_12       │ (None, 16, 16,    │          0 │ add_5[0][0]       │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_14 (Conv2D)  │ (None, 8, 8, 64)  │     18,496 │ activation_12[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_14[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_13       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_15 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_13[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_15[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_16 (Conv2D)  │ (None, 8, 8, 64)  │      2,112 │ activation_12[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_6 (Add)         │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ conv2d_16[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_14       │ (None, 8, 8, 64)  │          0 │ add_6[0][0]       │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_17 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_14[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_17[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_15       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_18 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_15[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_18[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_7 (Add)         │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_14[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_16       │ (None, 8, 8, 64)  │          0 │ add_7[0][0]       │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_19 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_16[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_19[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_17       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_20 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_17[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_20[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_8 (Add)         │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_16[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_18       │ (None, 8, 8, 64)  │          0 │ add_8[0][0]       │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 64)        │          0 │ activation_18[0]… │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense (Dense)       │ (None, 10)        │        650 │ global_average_p… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🔁  Resuming experiment m9_r1_m9_base at epoch_161

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)


🎯  _print_training_context

🖥️   Available compute devices:
  • /device:CPU:0 (CPU)
  • /device:GPU:0 (GPU)

🧮  GPU detected: True
  • /physical_device:GPU:0

🧠  Printing training configuration:
Light Mode:         OFF — Using reduced dataset for fast testing
Augmentation:       ON — Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (λ = 0.0005)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 5 epochs, decay factor 0.1
Early Stopping:     ON — patience 15 epochs, restore best weights: True
Weight Averaging:   ON — starting at epoch 170
Test-Time Augment:  ON — running 5 augmented passes per sample
Epochs:             200
Batch Size:         128
Epoch 162/200

Epoch 162: val_accuracy improved from -inf to 0.79400, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 162: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_162.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_162

🕒  Recording time at 18:11

313/313 - 24s - 76ms/step - accuracy: 0.8184 - loss: 0.7699 - val_accuracy: 0.7940 - val_loss: 0.8041 - learning_rate: 5.0000e-04
Epoch 163/200

Epoch 163: val_accuracy improved from 0.79400 to 0.80220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 163: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_163.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_163

🕒  Recording time at 18:11

313/313 - 14s - 45ms/step - accuracy: 0.8641 - loss: 0.5271 - val_accuracy: 0.8022 - val_loss: 0.7244 - learning_rate: 5.0000e-04
Epoch 164/200

Epoch 164: val_accuracy improved from 0.80220 to 0.80720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 164: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_164.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_164

🕒  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.8926 - loss: 0.4417 - val_accuracy: 0.8072 - val_loss: 0.7178 - learning_rate: 5.0000e-04
Epoch 165/200

Epoch 165: val_accuracy improved from 0.80720 to 0.80960, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 165: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_165.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_165

🕒  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.9136 - loss: 0.3803 - val_accuracy: 0.8096 - val_loss: 0.7255 - learning_rate: 5.0000e-04
Epoch 166/200

Epoch 166: val_accuracy did not improve from 0.80960

Epoch 166: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_166.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_166

🕒  Recording time at 18:12

313/313 - 14s - 45ms/step - accuracy: 0.9291 - loss: 0.3399 - val_accuracy: 0.8078 - val_loss: 0.7350 - learning_rate: 5.0000e-04
Epoch 167/200

Epoch 167: val_accuracy did not improve from 0.80960

Epoch 167: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_167.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_167

🕒  Recording time at 18:12

313/313 - 14s - 46ms/step - accuracy: 0.9439 - loss: 0.3005 - val_accuracy: 0.8006 - val_loss: 0.7580 - learning_rate: 5.0000e-04
Epoch 168/200

Epoch 168: val_accuracy did not improve from 0.80960

Epoch 168: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_168.keras

Epoch 168: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_168

🕒  Recording time at 18:13

313/313 - 14s - 46ms/step - accuracy: 0.9562 - loss: 0.2676 - val_accuracy: 0.8016 - val_loss: 0.7673 - learning_rate: 5.0000e-04
Epoch 169/200

Epoch 169: val_accuracy did not improve from 0.80960

Epoch 169: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_169.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_169

🕒  Recording time at 18:13

313/313 - 15s - 47ms/step - accuracy: 0.9711 - loss: 0.2317 - val_accuracy: 0.8014 - val_loss: 0.7716 - learning_rate: 5.0000e-05
Epoch 170/200

Epoch 170: val_accuracy did not improve from 0.80960

Epoch 170: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_170.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_170

🕒  Recording time at 18:13

313/313 - 15s - 46ms/step - accuracy: 0.9733 - loss: 0.2284 - val_accuracy: 0.8030 - val_loss: 0.7714 - learning_rate: 5.0000e-05
Epoch 171/200

Epoch 171: val_accuracy did not improve from 0.80960

Epoch 171: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_171.keras

Epoch 171: ReduceLROnPlateau reducing learning rate to 1e-05.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_171

🕒  Recording time at 18:13

313/313 - 14s - 46ms/step - accuracy: 0.9747 - loss: 0.2234 - val_accuracy: 0.8046 - val_loss: 0.7740 - learning_rate: 5.0000e-05
Epoch 172/200

Epoch 172: val_accuracy did not improve from 0.80960

Epoch 172: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_172.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_172

🕒  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9765 - loss: 0.2204 - val_accuracy: 0.8034 - val_loss: 0.7758 - learning_rate: 1.0000e-05
Epoch 173/200

Epoch 173: val_accuracy did not improve from 0.80960

Epoch 173: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_173.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_173

🕒  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9761 - loss: 0.2211 - val_accuracy: 0.8038 - val_loss: 0.7759 - learning_rate: 1.0000e-05
Epoch 174/200

Epoch 174: val_accuracy did not improve from 0.80960

Epoch 174: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_174.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_174

🕒  Recording time at 18:14

313/313 - 14s - 46ms/step - accuracy: 0.9756 - loss: 0.2217 - val_accuracy: 0.8038 - val_loss: 0.7759 - learning_rate: 1.0000e-05
Epoch 175/200

Epoch 175: val_accuracy did not improve from 0.80960

Epoch 175: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_175.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_175

🕒  Recording time at 18:14

313/313 - 15s - 46ms/step - accuracy: 0.9759 - loss: 0.2197 - val_accuracy: 0.8032 - val_loss: 0.7767 - learning_rate: 1.0000e-05
Epoch 176/200

Epoch 176: val_accuracy did not improve from 0.80960

Epoch 176: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_176.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_176

🕒  Recording time at 18:14

313/313 - 15s - 46ms/step - accuracy: 0.9775 - loss: 0.2190 - val_accuracy: 0.8042 - val_loss: 0.7771 - learning_rate: 1.0000e-05
Epoch 177/200

Epoch 177: val_accuracy did not improve from 0.80960

Epoch 177: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_177.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_177

🕒  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9774 - loss: 0.2183 - val_accuracy: 0.8042 - val_loss: 0.7771 - learning_rate: 1.0000e-05
Epoch 178/200

Epoch 178: val_accuracy did not improve from 0.80960

Epoch 178: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_178.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_178

🕒  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9778 - loss: 0.2174 - val_accuracy: 0.8040 - val_loss: 0.7775 - learning_rate: 1.0000e-05
Epoch 179/200

Epoch 179: val_accuracy did not improve from 0.80960

Epoch 179: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_179.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_179

🕒  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9778 - loss: 0.2172 - val_accuracy: 0.8044 - val_loss: 0.7781 - learning_rate: 1.0000e-05
Epoch 180/200

Epoch 180: val_accuracy did not improve from 0.80960

Epoch 180: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_180.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_180

🕒  Recording time at 18:15

313/313 - 14s - 46ms/step - accuracy: 0.9768 - loss: 0.2188 - val_accuracy: 0.8050 - val_loss: 0.7789 - learning_rate: 1.0000e-05
Epoch 180: early stopping
Restoring model weights from the end of the best epoch: 165.

🎯  _save_training_history

🎯  extract_history_metrics

📥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

🎯  evaluate_model

🎯  extract_history_metrics

🎯  build_augmentation_transform

🎯  build_normalization_transform

📈  TTA applied — averaged over 5 runs

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 9,
    "run": 1,
    "config_name": "m9_base",
    "date": "2025-05-25",
    "time": "14:46:31",
    "duration": "0:06:02",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": 0.1,
        "patience": 3,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.21722985804080963,
    "min_train_loss_epoch": 18,
    "max_train_acc": 0.9778249859809875,
    "max_train_acc_epoch": 17,
    "min_val_loss": 0.7178073525428772,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.8095999956130981,
    "max_val_acc_epoch": 4,
    "final_test_loss": 0.6421958804130554,
    "final_test_acc": 0.8518999814987183
  }
]

✅   m9 run 1 with 'm9_base' successfully executed

⚙️   Piplining experiment 2/5

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_legacy.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

🚀  Launching experiment m6_r1 with 'm6_legacy'

🎯  build_dataset

🎯  build_augmentation_transform

🎯  build_normalization_transform

🎯  build_normalization_transform

🎯  build_model

Model: "functional_1"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_1       │ (None, 32, 32, 3) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_21 (Conv2D)  │ (None, 32, 32,    │        896 │ input_layer_1[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_21[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_19       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_22 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_19[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_22[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_20       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_23 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_20[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_23[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_9 (Add)         │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_19[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_21       │ (None, 32, 32,    │          0 │ add_9[0][0]       │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_24 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_21[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_24[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_22       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_25 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_22[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_25[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_10 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_21[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_23       │ (None, 32, 32,    │          0 │ add_10[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_27 (Conv2D)  │ (None, 16, 16,    │     18,496 │ activation_23[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_27[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_24       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_28 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_24[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_28[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_26 (Conv2D)  │ (None, 16, 16,    │      2,112 │ activation_23[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_11 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 64)               │            │ conv2d_26[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_25       │ (None, 16, 16,    │          0 │ add_11[0][0]      │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_29 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_25[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_29[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_26       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_30 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_26[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_30[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_12 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 64)               │            │ activation_25[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_27       │ (None, 16, 16,    │          0 │ add_12[0][0]      │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_32 (Conv2D)  │ (None, 8, 8, 128) │     73,856 │ activation_27[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_32[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_28       │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_33 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_28[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_33[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_31 (Conv2D)  │ (None, 8, 8, 128) │      8,320 │ activation_27[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_13 (Add)        │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│                     │                   │            │ conv2d_31[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_29       │ (None, 8, 8, 128) │          0 │ add_13[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_34 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_29[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_34[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_30       │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_35 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_30[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_35[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_14 (Add)        │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│                     │                   │            │ activation_29[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_31       │ (None, 8, 8, 128) │          0 │ add_14[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 128)       │          0 │ activation_31[0]… │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout (Dropout)   │ (None, 128)       │          0 │ global_average_p… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 10)        │      1,290 │ dropout[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)


🎯  _print_training_context

🖥️   Available compute devices:
  • /device:CPU:0 (CPU)
  • /device:GPU:0 (GPU)

🧮  GPU detected: True
  • /physical_device:GPU:0

🧠  Printing training configuration:
Light Mode:         OFF — Using reduced dataset for fast testing
Augmentation:       ON — Random Crop, Horizontal Flip
L2 Regularization:  ON (λ = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 0 epochs, decay factor 0.5
Early Stopping:     ON — patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  OFF
Epochs:             100
Batch Size:         32
Epoch 1/100

Epoch 1: val_accuracy improved from -inf to 0.38720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_01.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_1

🕒  Recording time at 18:17

1250/1250 - 27s - 21ms/step - accuracy: 0.3486 - loss: 2.1334 - val_accuracy: 0.3872 - val_loss: 2.2016 - learning_rate: 0.0500
Epoch 2/100

Epoch 2: val_accuracy improved from 0.38720 to 0.55360, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_02.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_2

🕒  Recording time at 18:17

1250/1250 - 14s - 11ms/step - accuracy: 0.5486 - loss: 1.5537 - val_accuracy: 0.5536 - val_loss: 1.5417 - learning_rate: 0.0500
Epoch 3/100

Epoch 3: val_accuracy did not improve from 0.55360

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_03.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_3

🕒  Recording time at 18:17

1250/1250 - 14s - 11ms/step - accuracy: 0.6394 - loss: 1.3539 - val_accuracy: 0.5416 - val_loss: 1.6438 - learning_rate: 0.0500
Epoch 4/100

Epoch 4: val_accuracy improved from 0.55360 to 0.59680, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_04.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_4

🕒  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.6870 - loss: 1.2757 - val_accuracy: 0.5968 - val_loss: 1.5545 - learning_rate: 0.0500
Epoch 5/100

Epoch 5: val_accuracy did not improve from 0.59680

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_05.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_5

🕒  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7120 - loss: 1.2492 - val_accuracy: 0.5362 - val_loss: 1.8778 - learning_rate: 0.0500
Epoch 6/100

Epoch 6: val_accuracy improved from 0.59680 to 0.60440, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_06.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_6

🕒  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7242 - loss: 1.2324 - val_accuracy: 0.6044 - val_loss: 1.6845 - learning_rate: 0.0500
Epoch 7/100

Epoch 7: val_accuracy improved from 0.60440 to 0.69220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_07.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_7

🕒  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7357 - loss: 1.2288 - val_accuracy: 0.6922 - val_loss: 1.2949 - learning_rate: 0.0500
Epoch 8/100

Epoch 8: val_accuracy did not improve from 0.69220

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_08.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_8

🕒  Recording time at 18:18

1250/1250 - 14s - 11ms/step - accuracy: 0.7461 - loss: 1.2226 - val_accuracy: 0.6752 - val_loss: 1.4182 - learning_rate: 0.0500
Epoch 9/100

Epoch 9: val_accuracy did not improve from 0.69220

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_09.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_9

🕒  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7458 - loss: 1.2268 - val_accuracy: 0.6192 - val_loss: 1.6468 - learning_rate: 0.0500
Epoch 10/100

Epoch 10: val_accuracy did not improve from 0.69220

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_10.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_10

🕒  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7523 - loss: 1.2222 - val_accuracy: 0.6718 - val_loss: 1.5163 - learning_rate: 0.0500
Epoch 11/100

Epoch 11: val_accuracy did not improve from 0.69220

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_11.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_11

🕒  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7566 - loss: 1.2233 - val_accuracy: 0.6700 - val_loss: 1.5401 - learning_rate: 0.0500
Epoch 12/100

Epoch 12: val_accuracy did not improve from 0.69220

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_12.keras

Epoch 12: ReduceLROnPlateau reducing learning rate to 0.02500000037252903.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_12

🕒  Recording time at 18:19

1250/1250 - 14s - 11ms/step - accuracy: 0.7605 - loss: 1.2234 - val_accuracy: 0.5540 - val_loss: 2.1300 - learning_rate: 0.0500
Epoch 13/100

Epoch 13: val_accuracy improved from 0.69220 to 0.73340, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_13.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_13

🕒  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8209 - loss: 0.9897 - val_accuracy: 0.7334 - val_loss: 1.2561 - learning_rate: 0.0250
Epoch 14/100

Epoch 14: val_accuracy did not improve from 0.73340

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_14.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_14

🕒  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8284 - loss: 0.9320 - val_accuracy: 0.7322 - val_loss: 1.2128 - learning_rate: 0.0250
Epoch 15/100

Epoch 15: val_accuracy did not improve from 0.73340

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_15.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_15

🕒  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8260 - loss: 0.9455 - val_accuracy: 0.6816 - val_loss: 1.3792 - learning_rate: 0.0250
Epoch 16/100

Epoch 16: val_accuracy did not improve from 0.73340

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_16.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_16

🕒  Recording time at 18:20

1250/1250 - 14s - 11ms/step - accuracy: 0.8308 - loss: 0.9437 - val_accuracy: 0.6132 - val_loss: 1.6371 - learning_rate: 0.0250
Epoch 17/100

Epoch 17: val_accuracy did not improve from 0.73340

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_17.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_17

🕒  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8344 - loss: 0.9459 - val_accuracy: 0.7028 - val_loss: 1.4423 - learning_rate: 0.0250
Epoch 18/100

Epoch 18: val_accuracy improved from 0.73340 to 0.78120, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_18.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_18

🕒  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8374 - loss: 0.9517 - val_accuracy: 0.7812 - val_loss: 1.1349 - learning_rate: 0.0250
Epoch 19/100

Epoch 19: val_accuracy did not improve from 0.78120

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_19.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_19

🕒  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8413 - loss: 0.9501 - val_accuracy: 0.6996 - val_loss: 1.4932 - learning_rate: 0.0250
Epoch 20/100

Epoch 20: val_accuracy did not improve from 0.78120

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_20.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_20

🕒  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8401 - loss: 0.9630 - val_accuracy: 0.6574 - val_loss: 1.6702 - learning_rate: 0.0250
Epoch 21/100

Epoch 21: val_accuracy did not improve from 0.78120

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_21.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_21

🕒  Recording time at 18:21

1250/1250 - 14s - 11ms/step - accuracy: 0.8411 - loss: 0.9702 - val_accuracy: 0.6948 - val_loss: 1.4395 - learning_rate: 0.0250
Epoch 22/100

Epoch 22: val_accuracy improved from 0.78120 to 0.78480, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_22.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_22

🕒  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8444 - loss: 0.9720 - val_accuracy: 0.7848 - val_loss: 1.1605 - learning_rate: 0.0250
Epoch 23/100

Epoch 23: val_accuracy did not improve from 0.78480

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_23.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_23

🕒  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8458 - loss: 0.9767 - val_accuracy: 0.7336 - val_loss: 1.3498 - learning_rate: 0.0250
Epoch 24/100

Epoch 24: val_accuracy did not improve from 0.78480

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_24.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_24

🕒  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8477 - loss: 0.9766 - val_accuracy: 0.7688 - val_loss: 1.2396 - learning_rate: 0.0250
Epoch 25/100

Epoch 25: val_accuracy did not improve from 0.78480

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_25.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_25

🕒  Recording time at 18:22

1250/1250 - 14s - 11ms/step - accuracy: 0.8493 - loss: 0.9770 - val_accuracy: 0.7272 - val_loss: 1.3799 - learning_rate: 0.0250
Epoch 26/100

Epoch 26: val_accuracy did not improve from 0.78480

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_26.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_26

🕒  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.8492 - loss: 0.9765 - val_accuracy: 0.7694 - val_loss: 1.1950 - learning_rate: 0.0250
Epoch 27/100

Epoch 27: val_accuracy did not improve from 0.78480

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_27.keras

Epoch 27: ReduceLROnPlateau reducing learning rate to 0.012500000186264515.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_27

🕒  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.8498 - loss: 0.9852 - val_accuracy: 0.7566 - val_loss: 1.2905 - learning_rate: 0.0250
Epoch 28/100

Epoch 28: val_accuracy improved from 0.78480 to 0.80720, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_28.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_28

🕒  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.9094 - loss: 0.7684 - val_accuracy: 0.8072 - val_loss: 1.0563 - learning_rate: 0.0125
Epoch 29/100

Epoch 29: val_accuracy did not improve from 0.80720

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_29.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_29

🕒  Recording time at 18:23

1250/1250 - 14s - 11ms/step - accuracy: 0.9257 - loss: 0.6734 - val_accuracy: 0.8058 - val_loss: 1.0492 - learning_rate: 0.0125
Epoch 30/100

Epoch 30: val_accuracy did not improve from 0.80720

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_30.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_30

🕒  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9175 - loss: 0.6821 - val_accuracy: 0.7866 - val_loss: 1.1216 - learning_rate: 0.0125
Epoch 31/100

Epoch 31: val_accuracy did not improve from 0.80720

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_31.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_31

🕒  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9143 - loss: 0.6930 - val_accuracy: 0.7470 - val_loss: 1.4144 - learning_rate: 0.0125
Epoch 32/100

Epoch 32: val_accuracy did not improve from 0.80720

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_32.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_32

🕒  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9150 - loss: 0.6933 - val_accuracy: 0.7592 - val_loss: 1.2430 - learning_rate: 0.0125
Epoch 33/100

Epoch 33: val_accuracy improved from 0.80720 to 0.81180, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_33.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_33

🕒  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9134 - loss: 0.7035 - val_accuracy: 0.8118 - val_loss: 1.0465 - learning_rate: 0.0125
Epoch 34/100

Epoch 34: val_accuracy did not improve from 0.81180

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_34.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_34

🕒  Recording time at 18:24

1250/1250 - 14s - 11ms/step - accuracy: 0.9190 - loss: 0.6983 - val_accuracy: 0.7620 - val_loss: 1.2311 - learning_rate: 0.0125
Epoch 35/100

Epoch 35: val_accuracy did not improve from 0.81180

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_35.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_35

🕒  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9172 - loss: 0.6985 - val_accuracy: 0.7938 - val_loss: 1.1554 - learning_rate: 0.0125
Epoch 36/100

Epoch 36: val_accuracy did not improve from 0.81180

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_36.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_36

🕒  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9200 - loss: 0.6993 - val_accuracy: 0.7752 - val_loss: 1.1677 - learning_rate: 0.0125
Epoch 37/100

Epoch 37: val_accuracy did not improve from 0.81180

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_37.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_37

🕒  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9188 - loss: 0.7059 - val_accuracy: 0.7776 - val_loss: 1.1959 - learning_rate: 0.0125
Epoch 38/100

Epoch 38: val_accuracy did not improve from 0.81180

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_38.keras

Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0062500000931322575.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_38

🕒  Recording time at 18:25

1250/1250 - 14s - 11ms/step - accuracy: 0.9182 - loss: 0.7168 - val_accuracy: 0.7928 - val_loss: 1.1652 - learning_rate: 0.0125
Epoch 39/100

Epoch 39: val_accuracy improved from 0.81180 to 0.84420, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_39.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_39

🕒  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9695 - loss: 0.5564 - val_accuracy: 0.8442 - val_loss: 0.9471 - learning_rate: 0.0063
Epoch 40/100

Epoch 40: val_accuracy improved from 0.84420 to 0.84740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_40.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_40

🕒  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9895 - loss: 0.4501 - val_accuracy: 0.8474 - val_loss: 0.9084 - learning_rate: 0.0063
Epoch 41/100

Epoch 41: val_accuracy did not improve from 0.84740

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_41.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_41

🕒  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9912 - loss: 0.3963 - val_accuracy: 0.8410 - val_loss: 0.9220 - learning_rate: 0.0063
Epoch 42/100

Epoch 42: val_accuracy did not improve from 0.84740

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_42.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_42

🕒  Recording time at 18:26

1250/1250 - 14s - 11ms/step - accuracy: 0.9841 - loss: 0.3840 - val_accuracy: 0.8260 - val_loss: 0.9827 - learning_rate: 0.0063
Epoch 43/100

Epoch 43: val_accuracy did not improve from 0.84740

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_43.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_43

🕒  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9669 - loss: 0.4189 - val_accuracy: 0.8122 - val_loss: 1.0386 - learning_rate: 0.0063
Epoch 44/100

Epoch 44: val_accuracy did not improve from 0.84740

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_44.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_44

🕒  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9606 - loss: 0.4363 - val_accuracy: 0.8186 - val_loss: 0.9724 - learning_rate: 0.0063
Epoch 45/100

Epoch 45: val_accuracy did not improve from 0.84740

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_45.keras

Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0031250000465661287.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_45

🕒  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9616 - loss: 0.4391 - val_accuracy: 0.8224 - val_loss: 0.9451 - learning_rate: 0.0063
Epoch 46/100

Epoch 46: val_accuracy improved from 0.84740 to 0.85040, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_46.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_46

🕒  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9875 - loss: 0.3611 - val_accuracy: 0.8504 - val_loss: 0.8415 - learning_rate: 0.0031
Epoch 47/100

Epoch 47: val_accuracy improved from 0.85040 to 0.85380, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_47.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_47

🕒  Recording time at 18:27

1250/1250 - 14s - 11ms/step - accuracy: 0.9975 - loss: 0.3124 - val_accuracy: 0.8538 - val_loss: 0.8122 - learning_rate: 0.0031
Epoch 48/100

Epoch 48: val_accuracy did not improve from 0.85380

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_48.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_48

🕒  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9989 - loss: 0.2863 - val_accuracy: 0.8520 - val_loss: 0.7982 - learning_rate: 0.0031
Epoch 49/100

Epoch 49: val_accuracy improved from 0.85380 to 0.85840, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_49.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_49

🕒  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.2652 - val_accuracy: 0.8584 - val_loss: 0.7673 - learning_rate: 0.0031
Epoch 50/100

Epoch 50: val_accuracy did not improve from 0.85840

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_50.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_50

🕒  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9996 - loss: 0.2461 - val_accuracy: 0.8584 - val_loss: 0.7479 - learning_rate: 0.0031
Epoch 51/100

Epoch 51: val_accuracy improved from 0.85840 to 0.86200, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_51.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_51

🕒  Recording time at 18:28

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.2293 - val_accuracy: 0.8620 - val_loss: 0.7304 - learning_rate: 0.0031
Epoch 52/100

Epoch 52: val_accuracy did not improve from 0.86200

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_52.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_52

🕒  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9997 - loss: 0.2130 - val_accuracy: 0.8600 - val_loss: 0.7122 - learning_rate: 0.0031
Epoch 53/100

Epoch 53: val_accuracy did not improve from 0.86200

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_53.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_53

🕒  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9997 - loss: 0.1980 - val_accuracy: 0.8582 - val_loss: 0.6992 - learning_rate: 0.0031
Epoch 54/100

Epoch 54: val_accuracy did not improve from 0.86200

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_54.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_54

🕒  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9995 - loss: 0.1859 - val_accuracy: 0.8566 - val_loss: 0.6882 - learning_rate: 0.0031
Epoch 55/100

Epoch 55: val_accuracy did not improve from 0.86200

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_55.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_55

🕒  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1726 - val_accuracy: 0.8616 - val_loss: 0.6596 - learning_rate: 0.0031
Epoch 56/100

Epoch 56: val_accuracy did not improve from 0.86200

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_56.keras

Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0015625000232830644.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_56

🕒  Recording time at 18:29

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1610 - val_accuracy: 0.8620 - val_loss: 0.6500 - learning_rate: 0.0031
Epoch 57/100

Epoch 57: val_accuracy improved from 0.86200 to 0.86300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_57.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_57

🕒  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1523 - val_accuracy: 0.8630 - val_loss: 0.6425 - learning_rate: 0.0016
Epoch 58/100

Epoch 58: val_accuracy did not improve from 0.86300

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_58.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_58

🕒  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1465 - val_accuracy: 0.8614 - val_loss: 0.6365 - learning_rate: 0.0016
Epoch 59/100

Epoch 59: val_accuracy did not improve from 0.86300

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_59.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_59

🕒  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9998 - loss: 0.1415 - val_accuracy: 0.8614 - val_loss: 0.6321 - learning_rate: 0.0016
Epoch 60/100

Epoch 60: val_accuracy did not improve from 0.86300

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_60.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_60

🕒  Recording time at 18:30

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1362 - val_accuracy: 0.8598 - val_loss: 0.6257 - learning_rate: 0.0016
Epoch 61/100

Epoch 61: val_accuracy did not improve from 0.86300

Epoch 61: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_61.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_61

🕒  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 0.9999 - loss: 0.1313 - val_accuracy: 0.8608 - val_loss: 0.6216 - learning_rate: 0.0016
Epoch 62/100

Epoch 62: val_accuracy did not improve from 0.86300

Epoch 62: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_62.keras

Epoch 62: ReduceLROnPlateau reducing learning rate to 0.0007812500116415322.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_62

🕒  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1266 - val_accuracy: 0.8610 - val_loss: 0.6172 - learning_rate: 0.0016
Epoch 63/100

Epoch 63: val_accuracy did not improve from 0.86300

Epoch 63: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_63.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_63

🕒  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1232 - val_accuracy: 0.8598 - val_loss: 0.6141 - learning_rate: 7.8125e-04
Epoch 64/100

Epoch 64: val_accuracy did not improve from 0.86300

Epoch 64: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_64.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_64

🕒  Recording time at 18:31

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1210 - val_accuracy: 0.8610 - val_loss: 0.6061 - learning_rate: 7.8125e-04
Epoch 65/100

Epoch 65: val_accuracy did not improve from 0.86300

Epoch 65: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_65.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_65

🕒  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1187 - val_accuracy: 0.8612 - val_loss: 0.6056 - learning_rate: 7.8125e-04
Epoch 66/100

Epoch 66: val_accuracy did not improve from 0.86300

Epoch 66: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_66.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_66

🕒  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1166 - val_accuracy: 0.8616 - val_loss: 0.6027 - learning_rate: 7.8125e-04
Epoch 67/100

Epoch 67: val_accuracy did not improve from 0.86300

Epoch 67: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_67.keras

Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0003906250058207661.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_67

🕒  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1146 - val_accuracy: 0.8604 - val_loss: 0.6023 - learning_rate: 7.8125e-04
Epoch 68/100

Epoch 68: val_accuracy did not improve from 0.86300

Epoch 68: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_68.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_68

🕒  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1130 - val_accuracy: 0.8612 - val_loss: 0.5983 - learning_rate: 3.9063e-04
Epoch 69/100

Epoch 69: val_accuracy did not improve from 0.86300

Epoch 69: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_69.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_69

🕒  Recording time at 18:32

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1120 - val_accuracy: 0.8618 - val_loss: 0.5988 - learning_rate: 3.9063e-04
Epoch 70/100

Epoch 70: val_accuracy did not improve from 0.86300

Epoch 70: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_70.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_70

🕒  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1110 - val_accuracy: 0.8608 - val_loss: 0.5978 - learning_rate: 3.9063e-04
Epoch 71/100

Epoch 71: val_accuracy did not improve from 0.86300

Epoch 71: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_71.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_71

🕒  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1100 - val_accuracy: 0.8608 - val_loss: 0.5977 - learning_rate: 3.9063e-04
Epoch 72/100

Epoch 72: val_accuracy did not improve from 0.86300

Epoch 72: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_72.keras

Epoch 72: ReduceLROnPlateau reducing learning rate to 0.00019531250291038305.

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_72

🕒  Recording time at 18:33

1250/1250 - 14s - 11ms/step - accuracy: 1.0000 - loss: 0.1091 - val_accuracy: 0.8610 - val_loss: 0.5960 - learning_rate: 3.9063e-04
Epoch 72: early stopping
Restoring model weights from the end of the best epoch: 57.

🎯  _save_training_history

🎯  extract_history_metrics

📥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

🎯  evaluate_model

🎯  extract_history_metrics

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 6,
    "run": 1,
    "config_name": "m6_legacy",
    "date": "2025-05-25",
    "time": "15:03:44",
    "duration": "0:17:13",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 0,
        "factor": 0.5,
        "patience": 5,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 0.10906655341386795,
    "min_train_loss_epoch": 72,
    "max_train_acc": 1.0,
    "max_train_acc_epoch": 63,
    "min_val_loss": 0.5960099697113037,
    "min_val_loss_epoch": 72,
    "max_val_acc": 0.8629999756813049,
    "max_val_acc_epoch": 57,
    "final_test_loss": 0.7124512195587158,
    "final_test_acc": 0.8601999878883362
  }
]

✅   m6 run 1 with 'm6_legacy' successfully executed

⚙️   Piplining experiment 3/5

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_rebase.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

🚀  Launching experiment m6_r2 with 'm6_rebase'

🎯  build_dataset

🎯  build_augmentation_transform

🎯  build_normalization_transform

🎯  build_normalization_transform

🎯  build_model

Model: "functional_2"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_2       │ (None, 32, 32, 3) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_36 (Conv2D)  │ (None, 32, 32,    │        896 │ input_layer_2[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_36[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_32       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_37 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_32[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_37[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_33       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_38 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_33[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_38[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_15 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_32[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_34       │ (None, 32, 32,    │          0 │ add_15[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_39 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_34[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_39[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_35       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_40 (Conv2D)  │ (None, 32, 32,    │      9,248 │ activation_35[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │        128 │ conv2d_40[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_16 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_34[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_36       │ (None, 32, 32,    │          0 │ add_16[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_42 (Conv2D)  │ (None, 16, 16,    │     18,496 │ activation_36[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_42[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_37       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_43 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_37[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_43[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_41 (Conv2D)  │ (None, 16, 16,    │      2,112 │ activation_36[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_17 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 64)               │            │ conv2d_41[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_38       │ (None, 16, 16,    │          0 │ add_17[0][0]      │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_44 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_38[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_44[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_39       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_45 (Conv2D)  │ (None, 16, 16,    │     36,928 │ activation_39[0]… │
│                     │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        256 │ conv2d_45[0][0]   │
│ (BatchNormalizatio… │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_18 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 64)               │            │ activation_38[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_40       │ (None, 16, 16,    │          0 │ add_18[0][0]      │
│ (Activation)        │ 64)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_47 (Conv2D)  │ (None, 8, 8, 128) │     73,856 │ activation_40[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_47[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_41       │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_48 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_41[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_48[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_46 (Conv2D)  │ (None, 8, 8, 128) │      8,320 │ activation_40[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_19 (Add)        │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│                     │                   │            │ conv2d_46[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_42       │ (None, 8, 8, 128) │          0 │ add_19[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_49 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_42[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_49[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_43       │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_50 (Conv2D)  │ (None, 8, 8, 128) │    147,584 │ activation_43[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 128) │        512 │ conv2d_50[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_20 (Add)        │ (None, 8, 8, 128) │          0 │ batch_normalizat… │
│                     │                   │            │ activation_42[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_44       │ (None, 8, 8, 128) │          0 │ add_20[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 128)       │          0 │ activation_44[0]… │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1 (Dropout) │ (None, 128)       │          0 │ global_average_p… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 10)        │      1,290 │ dropout_1[0][0]   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)


🎯  _print_training_context

🖥️   Available compute devices:
  • /device:CPU:0 (CPU)
  • /device:GPU:0 (GPU)

🧮  GPU detected: True
  • /physical_device:GPU:0

🧠  Printing training configuration:
Light Mode:         OFF — Using reduced dataset for fast testing
Augmentation:       ON — Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (λ = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON — patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  ON — running 5 augmented passes per sample
Epochs:             100
Batch Size:         32

🔁  StepLR applied — epoch 0, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 0, learning rate set to 0.01000

Epoch 1/100

Epoch 1: val_accuracy improved from -inf to 0.34300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_01.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_1

🕒  Recording time at 18:34

1250/1250 - 24s - 19ms/step - accuracy: 0.3490 - loss: 2.2070 - val_accuracy: 0.3430 - val_loss: 2.4257

🔁  StepLR applied — epoch 1, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 1, learning rate set to 0.02000

Epoch 2/100

Epoch 2: val_accuracy improved from 0.34300 to 0.46600, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_02.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_2

🕒  Recording time at 18:34

1250/1250 - 14s - 11ms/step - accuracy: 0.4949 - loss: 1.7875 - val_accuracy: 0.4660 - val_loss: 1.8872

🔁  StepLR applied — epoch 2, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 2, learning rate set to 0.03000

Epoch 3/100

Epoch 3: val_accuracy did not improve from 0.46600

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_03.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_3

🕒  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.5614 - loss: 1.5819 - val_accuracy: 0.4242 - val_loss: 2.2471

🔁  StepLR applied — epoch 3, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 3, learning rate set to 0.04000

Epoch 4/100

Epoch 4: val_accuracy improved from 0.46600 to 0.54480, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_04.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_4

🕒  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6033 - loss: 1.4883 - val_accuracy: 0.5448 - val_loss: 1.7313

🔁  StepLR applied — epoch 4, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 4, learning rate set to 0.05000

Epoch 5/100

Epoch 5: val_accuracy did not improve from 0.54480

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_05.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_5

🕒  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6266 - loss: 1.4788 - val_accuracy: 0.5286 - val_loss: 1.8470

🔁  StepLR applied — epoch 5, learning rate set to 0.05000

Epoch 6/100

Epoch 6: val_accuracy improved from 0.54480 to 0.58000, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_06.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_6

🕒  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6453 - loss: 1.4462 - val_accuracy: 0.5800 - val_loss: 1.7034

🔁  StepLR applied — epoch 6, learning rate set to 0.05000

Epoch 7/100

Epoch 7: val_accuracy did not improve from 0.58000

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_07.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_7

🕒  Recording time at 18:35

1250/1250 - 14s - 11ms/step - accuracy: 0.6625 - loss: 1.4300 - val_accuracy: 0.5546 - val_loss: 1.7715

🔁  StepLR applied — epoch 7, learning rate set to 0.05000

Epoch 8/100

Epoch 8: val_accuracy did not improve from 0.58000

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_08.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_8

🕒  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6708 - loss: 1.4144 - val_accuracy: 0.5770 - val_loss: 1.8003

🔁  StepLR applied — epoch 8, learning rate set to 0.05000

Epoch 9/100

Epoch 9: val_accuracy did not improve from 0.58000

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_09.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_9

🕒  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6828 - loss: 1.4109 - val_accuracy: 0.4722 - val_loss: 2.3730

🔁  StepLR applied — epoch 9, learning rate set to 0.05000

Epoch 10/100

Epoch 10: val_accuracy did not improve from 0.58000

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_10.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_10

🕒  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6806 - loss: 1.4180 - val_accuracy: 0.4818 - val_loss: 2.2048

🔁  StepLR applied — epoch 10, learning rate set to 0.05000

Epoch 11/100

Epoch 11: val_accuracy did not improve from 0.58000

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_11.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_11

🕒  Recording time at 18:36

1250/1250 - 14s - 11ms/step - accuracy: 0.6898 - loss: 1.4019 - val_accuracy: 0.4874 - val_loss: 1.9737

🔁  StepLR applied — epoch 11, learning rate set to 0.05000

Epoch 12/100

Epoch 12: val_accuracy improved from 0.58000 to 0.58740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_12.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_12

🕒  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6917 - loss: 1.4105 - val_accuracy: 0.5874 - val_loss: 1.8314

🔁  StepLR applied — epoch 12, learning rate set to 0.05000

Epoch 13/100

Epoch 13: val_accuracy improved from 0.58740 to 0.58760, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_13.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_13

🕒  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6957 - loss: 1.4066 - val_accuracy: 0.5876 - val_loss: 1.7643

🔁  StepLR applied — epoch 13, learning rate set to 0.05000

Epoch 14/100

Epoch 14: val_accuracy did not improve from 0.58760

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_14.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_14

🕒  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6985 - loss: 1.4068 - val_accuracy: 0.5684 - val_loss: 1.7364

🔁  StepLR applied — epoch 14, learning rate set to 0.05000

Epoch 15/100

Epoch 15: val_accuracy did not improve from 0.58760

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_15.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_15

🕒  Recording time at 18:37

1250/1250 - 14s - 11ms/step - accuracy: 0.6977 - loss: 1.4072 - val_accuracy: 0.5818 - val_loss: 1.7638

🔁  StepLR applied — epoch 15, learning rate set to 0.05000

Epoch 16/100

Epoch 16: val_accuracy improved from 0.58760 to 0.62180, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_16.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_16

🕒  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7041 - loss: 1.4043 - val_accuracy: 0.6218 - val_loss: 1.6960

🔁  StepLR applied — epoch 16, learning rate set to 0.05000

Epoch 17/100

Epoch 17: val_accuracy did not improve from 0.62180

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_17.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_17

🕒  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7058 - loss: 1.4072 - val_accuracy: 0.5786 - val_loss: 1.8239

🔁  StepLR applied — epoch 17, learning rate set to 0.05000

Epoch 18/100

Epoch 18: val_accuracy improved from 0.62180 to 0.64520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_18.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_18

🕒  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7066 - loss: 1.4099 - val_accuracy: 0.6452 - val_loss: 1.5998

🔁  StepLR applied — epoch 18, learning rate set to 0.05000

Epoch 19/100

Epoch 19: val_accuracy did not improve from 0.64520

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_19.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_19

🕒  Recording time at 18:38

1250/1250 - 14s - 11ms/step - accuracy: 0.7103 - loss: 1.4040 - val_accuracy: 0.6098 - val_loss: 1.7417

🔁  StepLR applied — epoch 19, learning rate set to 0.05000

Epoch 20/100

Epoch 20: val_accuracy did not improve from 0.64520

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_20.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_20

🕒  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7087 - loss: 1.4203 - val_accuracy: 0.6026 - val_loss: 1.7973

🔁  StepLR applied — epoch 20, learning rate set to 0.05000

Epoch 21/100

Epoch 21: val_accuracy improved from 0.64520 to 0.65680, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_21.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_21

🕒  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7113 - loss: 1.4085 - val_accuracy: 0.6568 - val_loss: 1.5570

🔁  StepLR applied — epoch 21, learning rate set to 0.05000

Epoch 22/100

Epoch 22: val_accuracy did not improve from 0.65680

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_22.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_22

🕒  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7133 - loss: 1.4098 - val_accuracy: 0.5494 - val_loss: 1.9204

🔁  StepLR applied — epoch 22, learning rate set to 0.05000

Epoch 23/100

Epoch 23: val_accuracy did not improve from 0.65680

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_23.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_23

🕒  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7167 - loss: 1.4047 - val_accuracy: 0.6014 - val_loss: 1.7473

🔁  StepLR applied — epoch 23, learning rate set to 0.05000

Epoch 24/100

Epoch 24: val_accuracy did not improve from 0.65680

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_24.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_24

🕒  Recording time at 18:39

1250/1250 - 14s - 11ms/step - accuracy: 0.7102 - loss: 1.4114 - val_accuracy: 0.5538 - val_loss: 1.8093

🔁  StepLR applied — epoch 24, learning rate set to 0.05000

Epoch 25/100

Epoch 25: val_accuracy did not improve from 0.65680

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_25.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_25

🕒  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7154 - loss: 1.4121 - val_accuracy: 0.6260 - val_loss: 1.6438

🔁  StepLR applied — epoch 25, learning rate set to 0.05000

Epoch 26/100

Epoch 26: val_accuracy did not improve from 0.65680

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_26.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_26

🕒  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7179 - loss: 1.4036 - val_accuracy: 0.5530 - val_loss: 1.9996

🔁  StepLR applied — epoch 26, learning rate set to 0.05000

Epoch 27/100

Epoch 27: val_accuracy did not improve from 0.65680

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_27.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_27

🕒  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7183 - loss: 1.4040 - val_accuracy: 0.5606 - val_loss: 1.9666

🔁  StepLR applied — epoch 27, learning rate set to 0.05000

Epoch 28/100

Epoch 28: val_accuracy did not improve from 0.65680

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_28.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_28

🕒  Recording time at 18:40

1250/1250 - 14s - 11ms/step - accuracy: 0.7162 - loss: 1.4136 - val_accuracy: 0.6174 - val_loss: 1.6526

🔁  StepLR applied — epoch 28, learning rate set to 0.05000

Epoch 29/100

Epoch 29: val_accuracy did not improve from 0.65680

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_29.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_29

🕒  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7176 - loss: 1.3987 - val_accuracy: 0.6406 - val_loss: 1.6566

🔁  StepLR applied — epoch 29, learning rate set to 0.05000

Epoch 30/100

Epoch 30: val_accuracy did not improve from 0.65680

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_30.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_30

🕒  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7189 - loss: 1.4048 - val_accuracy: 0.6480 - val_loss: 1.6249

🔁  StepLR applied — epoch 30, learning rate set to 0.05000

Epoch 31/100

Epoch 31: val_accuracy did not improve from 0.65680

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_31.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_31

🕒  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7199 - loss: 1.4129 - val_accuracy: 0.6540 - val_loss: 1.6328

🔁  StepLR applied — epoch 31, learning rate set to 0.05000

Epoch 32/100

Epoch 32: val_accuracy did not improve from 0.65680

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_32.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_32

🕒  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7206 - loss: 1.4077 - val_accuracy: 0.6388 - val_loss: 1.6326

🔁  StepLR applied — epoch 32, learning rate set to 0.05000

Epoch 33/100

Epoch 33: val_accuracy improved from 0.65680 to 0.66400, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_33.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_33

🕒  Recording time at 18:41

1250/1250 - 14s - 11ms/step - accuracy: 0.7238 - loss: 1.4014 - val_accuracy: 0.6640 - val_loss: 1.5346

🔁  StepLR applied — epoch 33, learning rate set to 0.05000

Epoch 34/100

Epoch 34: val_accuracy did not improve from 0.66400

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_34.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_34

🕒  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7192 - loss: 1.4095 - val_accuracy: 0.6036 - val_loss: 1.7646

🔁  StepLR applied — epoch 34, learning rate set to 0.05000

Epoch 35/100

Epoch 35: val_accuracy did not improve from 0.66400

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_35.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_35

🕒  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7224 - loss: 1.4022 - val_accuracy: 0.6300 - val_loss: 1.6947

🔁  StepLR applied — epoch 35, learning rate set to 0.05000

Epoch 36/100

Epoch 36: val_accuracy did not improve from 0.66400

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_36.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_36

🕒  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7199 - loss: 1.4087 - val_accuracy: 0.5994 - val_loss: 1.7751

🔁  StepLR applied — epoch 36, learning rate set to 0.05000

Epoch 37/100

Epoch 37: val_accuracy did not improve from 0.66400

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_37.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_37

🕒  Recording time at 18:42

1250/1250 - 14s - 11ms/step - accuracy: 0.7253 - loss: 1.3956 - val_accuracy: 0.5672 - val_loss: 1.8838

🔁  StepLR applied — epoch 37, learning rate set to 0.05000

Epoch 38/100

Epoch 38: val_accuracy did not improve from 0.66400

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_38.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_38

🕒  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7236 - loss: 1.4058 - val_accuracy: 0.5726 - val_loss: 1.9171

🔁  StepLR applied — epoch 38, learning rate set to 0.05000

Epoch 39/100

Epoch 39: val_accuracy did not improve from 0.66400

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_39.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_39

🕒  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7221 - loss: 1.4139 - val_accuracy: 0.5594 - val_loss: 1.9635

🔁  StepLR applied — epoch 39, learning rate set to 0.05000

Epoch 40/100

Epoch 40: val_accuracy did not improve from 0.66400

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_40.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_40

🕒  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7255 - loss: 1.4036 - val_accuracy: 0.5726 - val_loss: 1.8687

🔁  StepLR applied — epoch 40, learning rate set to 0.05000

Epoch 41/100

Epoch 41: val_accuracy did not improve from 0.66400

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_41.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_41

🕒  Recording time at 18:43

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4045 - val_accuracy: 0.6094 - val_loss: 1.8171

🔁  StepLR applied — epoch 41, learning rate set to 0.05000

Epoch 42/100

Epoch 42: val_accuracy did not improve from 0.66400

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_42.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_42

🕒  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7260 - loss: 1.4046 - val_accuracy: 0.5898 - val_loss: 1.7790

🔁  StepLR applied — epoch 42, learning rate set to 0.05000

Epoch 43/100

Epoch 43: val_accuracy did not improve from 0.66400

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_43.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_43

🕒  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4046 - val_accuracy: 0.5794 - val_loss: 2.0507

🔁  StepLR applied — epoch 43, learning rate set to 0.05000

Epoch 44/100

Epoch 44: val_accuracy did not improve from 0.66400

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_44.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_44

🕒  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7261 - loss: 1.3963 - val_accuracy: 0.6404 - val_loss: 1.6546

🔁  StepLR applied — epoch 44, learning rate set to 0.05000

Epoch 45/100

Epoch 45: val_accuracy improved from 0.66400 to 0.68580, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_45.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_45

🕒  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7261 - loss: 1.4052 - val_accuracy: 0.6858 - val_loss: 1.5176

🔁  StepLR applied — epoch 45, learning rate set to 0.05000

Epoch 46/100

Epoch 46: val_accuracy did not improve from 0.68580

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_46.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_46

🕒  Recording time at 18:44

1250/1250 - 14s - 11ms/step - accuracy: 0.7270 - loss: 1.3998 - val_accuracy: 0.6330 - val_loss: 1.6918

🔁  StepLR applied — epoch 46, learning rate set to 0.05000

Epoch 47/100

Epoch 47: val_accuracy did not improve from 0.68580

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_47.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_47

🕒  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7262 - loss: 1.4058 - val_accuracy: 0.6446 - val_loss: 1.6173

🔁  StepLR applied — epoch 47, learning rate set to 0.05000

Epoch 48/100

Epoch 48: val_accuracy did not improve from 0.68580

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_48.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_48

🕒  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7246 - loss: 1.4086 - val_accuracy: 0.5608 - val_loss: 2.0059

🔁  StepLR applied — epoch 48, learning rate set to 0.05000

Epoch 49/100

Epoch 49: val_accuracy did not improve from 0.68580

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_49.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_49

🕒  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7294 - loss: 1.3996 - val_accuracy: 0.5266 - val_loss: 2.1115

🔁  StepLR applied — epoch 49, learning rate set to 0.05000

Epoch 50/100

Epoch 50: val_accuracy did not improve from 0.68580

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_50.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_50

🕒  Recording time at 18:45

1250/1250 - 14s - 11ms/step - accuracy: 0.7306 - loss: 1.3959 - val_accuracy: 0.4774 - val_loss: 2.5955

🔁  StepLR applied — epoch 50, learning rate set to 0.05000

Epoch 51/100

Epoch 51: val_accuracy did not improve from 0.68580

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_51.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_51

🕒  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7256 - loss: 1.4062 - val_accuracy: 0.6318 - val_loss: 1.6524

🔁  StepLR applied — epoch 51, learning rate set to 0.05000

Epoch 52/100

Epoch 52: val_accuracy did not improve from 0.68580

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_52.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_52

🕒  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7282 - loss: 1.4057 - val_accuracy: 0.6300 - val_loss: 1.7030

🔁  StepLR applied — epoch 52, learning rate set to 0.05000

Epoch 53/100

Epoch 53: val_accuracy did not improve from 0.68580

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_53.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_53

🕒  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7265 - loss: 1.4013 - val_accuracy: 0.5626 - val_loss: 1.9467

🔁  StepLR applied — epoch 53, learning rate set to 0.05000

Epoch 54/100

Epoch 54: val_accuracy did not improve from 0.68580

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_54.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_54

🕒  Recording time at 18:46

1250/1250 - 14s - 11ms/step - accuracy: 0.7248 - loss: 1.4136 - val_accuracy: 0.5086 - val_loss: 2.0775

🔁  StepLR applied — epoch 54, learning rate set to 0.05000

Epoch 55/100

Epoch 55: val_accuracy did not improve from 0.68580

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_55.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_55

🕒  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7276 - loss: 1.4078 - val_accuracy: 0.5236 - val_loss: 2.0100

🔁  StepLR applied — epoch 55, learning rate set to 0.05000

Epoch 56/100

Epoch 56: val_accuracy did not improve from 0.68580

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_56.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_56

🕒  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7292 - loss: 1.4041 - val_accuracy: 0.6522 - val_loss: 1.6272

🔁  StepLR applied — epoch 56, learning rate set to 0.05000

Epoch 57/100

Epoch 57: val_accuracy did not improve from 0.68580

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_57.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_57

🕒  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7301 - loss: 1.4078 - val_accuracy: 0.6364 - val_loss: 1.7368

🔁  StepLR applied — epoch 57, learning rate set to 0.05000

Epoch 58/100

Epoch 58: val_accuracy did not improve from 0.68580

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_58.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_58

🕒  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7312 - loss: 1.4102 - val_accuracy: 0.6000 - val_loss: 1.8182

🔁  StepLR applied — epoch 58, learning rate set to 0.05000

Epoch 59/100

Epoch 59: val_accuracy did not improve from 0.68580

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_59.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_59

🕒  Recording time at 18:47

1250/1250 - 14s - 11ms/step - accuracy: 0.7270 - loss: 1.4105 - val_accuracy: 0.5868 - val_loss: 1.8197

🔁  StepLR applied — epoch 59, learning rate set to 0.05000

Epoch 60/100

Epoch 60: val_accuracy did not improve from 0.68580

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_60.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_60

🕒  Recording time at 18:48

1250/1250 - 14s - 11ms/step - accuracy: 0.7317 - loss: 1.4013 - val_accuracy: 0.6732 - val_loss: 1.5377
Epoch 60: early stopping
Restoring model weights from the end of the best epoch: 45.

🎯  _save_training_history

🎯  extract_history_metrics

📥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

🎯  evaluate_model

🎯  extract_history_metrics

🎯  build_augmentation_transform

🎯  build_normalization_transform

📈  TTA applied — averaged over 5 runs

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 6,
    "run": 2,
    "config_name": "m6_rebase",
    "date": "2025-05-25",
    "time": "15:18:47",
    "duration": "0:15:02",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 1.3956196308135986,
    "min_train_loss_epoch": 37,
    "max_train_acc": 0.7317000031471252,
    "max_train_acc_epoch": 60,
    "min_val_loss": 1.5175951719284058,
    "min_val_loss_epoch": 45,
    "max_val_acc": 0.6858000159263611,
    "max_val_acc_epoch": 45,
    "final_test_loss": 1.467358946800232,
    "final_test_acc": 0.7242000102996826
  }
]

✅   m6 run 2 with 'm6_rebase' successfully executed

⚙️   Piplining experiment 4/5

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_tuned.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

🚀  Launching experiment m9_r2 with 'm9_tuned'

🎯  build_dataset

🎯  build_augmentation_transform

🎯  build_normalization_transform

🎯  build_normalization_transform

🎯  build_model

Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_3       │ (None, 32, 32, 3) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_51 (Conv2D)  │ (None, 32, 32,    │        448 │ input_layer_3[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_51[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_45       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_52 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_45[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_52[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_46       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_53 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_46[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_53[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_21 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_45[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_47       │ (None, 32, 32,    │          0 │ add_21[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_54 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_47[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_54[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_48       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_55 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_48[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_55[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_22 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_47[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_49       │ (None, 32, 32,    │          0 │ add_22[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_56 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_49[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_56[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_50       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_57 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_50[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_57[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_23 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_49[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_51       │ (None, 32, 32,    │          0 │ add_23[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_58 (Conv2D)  │ (None, 16, 16,    │      4,640 │ activation_51[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_58[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_52       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_59 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_52[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_59[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_60 (Conv2D)  │ (None, 16, 16,    │        544 │ activation_51[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_24 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ conv2d_60[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_53       │ (None, 16, 16,    │          0 │ add_24[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_61 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_53[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_61[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_54       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_62 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_54[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_62[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_25 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_53[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_55       │ (None, 16, 16,    │          0 │ add_25[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_63 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_55[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_63[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_56       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_64 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_56[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_64[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_26 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_55[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_57       │ (None, 16, 16,    │          0 │ add_26[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_65 (Conv2D)  │ (None, 8, 8, 64)  │     18,496 │ activation_57[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_65[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_58       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_66 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_58[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_66[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_67 (Conv2D)  │ (None, 8, 8, 64)  │      2,112 │ activation_57[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_27 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ conv2d_67[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_59       │ (None, 8, 8, 64)  │          0 │ add_27[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_68 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_59[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_68[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_60       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_69 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_60[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_69[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_28 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_59[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_61       │ (None, 8, 8, 64)  │          0 │ add_28[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_70 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_61[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_70[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_62       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_71 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_62[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_71[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_29 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_61[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_63       │ (None, 8, 8, 64)  │          0 │ add_29[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 64)        │          0 │ activation_63[0]… │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3 (Dense)     │ (None, 10)        │        650 │ global_average_p… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)


🎯  _print_training_context

🖥️   Available compute devices:
  • /device:CPU:0 (CPU)
  • /device:GPU:0 (GPU)

🧮  GPU detected: True
  • /physical_device:GPU:0

🧠  Printing training configuration:
Light Mode:         OFF — Using reduced dataset for fast testing
Augmentation:       ON — Random Crop, Horizontal Flip
L2 Regularization:  ON (λ = 0.0001)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON — patience 15 epochs, restore best weights: True
Weight Averaging:   ON — starting at epoch 170
Test-Time Augment:  ON — running 5 augmented passes per sample
Epochs:             200
Batch Size:         128

🔁  StepLR applied — epoch 0, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 0, learning rate set to 0.01000

Epoch 1/200

Epoch 1: val_accuracy improved from -inf to 0.32020, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_01.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_1

🕒  Recording time at 18:49

313/313 - 30s - 95ms/step - accuracy: 0.3678 - loss: 1.7875 - val_accuracy: 0.3202 - val_loss: 2.0255

🔁  StepLR applied — epoch 1, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 1, learning rate set to 0.02000

Epoch 2/200

Epoch 2: val_accuracy improved from 0.32020 to 0.37220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_02.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_2

🕒  Recording time at 18:49

313/313 - 9s - 27ms/step - accuracy: 0.5103 - loss: 1.4106 - val_accuracy: 0.3722 - val_loss: 2.1162

🔁  StepLR applied — epoch 2, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 2, learning rate set to 0.03000

Epoch 3/200

Epoch 3: val_accuracy improved from 0.37220 to 0.43760, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_03.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_3

🕒  Recording time at 18:49

313/313 - 9s - 28ms/step - accuracy: 0.6143 - loss: 1.1589 - val_accuracy: 0.4376 - val_loss: 2.3789

🔁  StepLR applied — epoch 3, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 3, learning rate set to 0.04000

Epoch 4/200

Epoch 4: val_accuracy improved from 0.43760 to 0.55200, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_04.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_4

🕒  Recording time at 18:50

313/313 - 9s - 27ms/step - accuracy: 0.6813 - loss: 0.9873 - val_accuracy: 0.5520 - val_loss: 1.5126

🔁  StepLR applied — epoch 4, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 4, learning rate set to 0.05000

Epoch 5/200

Epoch 5: val_accuracy did not improve from 0.55200

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_05.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_5

🕒  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.7207 - loss: 0.8950 - val_accuracy: 0.5382 - val_loss: 1.7122

🔁  StepLR applied — epoch 5, learning rate set to 0.05000

Epoch 6/200

Epoch 6: val_accuracy improved from 0.55200 to 0.65800, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_06.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_6

🕒  Recording time at 18:50

313/313 - 8s - 27ms/step - accuracy: 0.7622 - loss: 0.7837 - val_accuracy: 0.6580 - val_loss: 1.0946

🔁  StepLR applied — epoch 6, learning rate set to 0.05000

Epoch 7/200

Epoch 7: val_accuracy improved from 0.65800 to 0.71300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_07.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_7

🕒  Recording time at 18:50

313/313 - 8s - 27ms/step - accuracy: 0.7959 - loss: 0.7041 - val_accuracy: 0.7130 - val_loss: 0.9871

🔁  StepLR applied — epoch 7, learning rate set to 0.05000

Epoch 8/200

Epoch 8: val_accuracy did not improve from 0.71300

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_08.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_8

🕒  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8156 - loss: 0.6534 - val_accuracy: 0.5248 - val_loss: 1.9036

🔁  StepLR applied — epoch 8, learning rate set to 0.05000

Epoch 9/200

Epoch 9: val_accuracy did not improve from 0.71300

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_09.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_9

🕒  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8333 - loss: 0.6055 - val_accuracy: 0.6412 - val_loss: 1.2340

🔁  StepLR applied — epoch 9, learning rate set to 0.05000

Epoch 10/200

Epoch 10: val_accuracy did not improve from 0.71300

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_10.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_10

🕒  Recording time at 18:50

313/313 - 8s - 26ms/step - accuracy: 0.8467 - loss: 0.5707 - val_accuracy: 0.7058 - val_loss: 1.0921

🔁  StepLR applied — epoch 10, learning rate set to 0.05000

Epoch 11/200

Epoch 11: val_accuracy did not improve from 0.71300

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_11.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_11

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8589 - loss: 0.5392 - val_accuracy: 0.6884 - val_loss: 1.0423

🔁  StepLR applied — epoch 11, learning rate set to 0.05000

Epoch 12/200

Epoch 12: val_accuracy did not improve from 0.71300

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_12.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_12

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8729 - loss: 0.5096 - val_accuracy: 0.6594 - val_loss: 1.3295

🔁  StepLR applied — epoch 12, learning rate set to 0.05000

Epoch 13/200

Epoch 13: val_accuracy did not improve from 0.71300

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_13.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_13

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8834 - loss: 0.4871 - val_accuracy: 0.6726 - val_loss: 1.3992

🔁  StepLR applied — epoch 13, learning rate set to 0.05000

Epoch 14/200

Epoch 14: val_accuracy did not improve from 0.71300

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_14.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_14

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8924 - loss: 0.4661 - val_accuracy: 0.6880 - val_loss: 1.3026

🔁  StepLR applied — epoch 14, learning rate set to 0.05000

Epoch 15/200

Epoch 15: val_accuracy did not improve from 0.71300

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_15.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_15

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.8992 - loss: 0.4511 - val_accuracy: 0.6610 - val_loss: 1.5440

🔁  StepLR applied — epoch 15, learning rate set to 0.05000

Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.71300

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_16.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_16

🕒  Recording time at 18:51

313/313 - 8s - 26ms/step - accuracy: 0.9081 - loss: 0.4327 - val_accuracy: 0.6906 - val_loss: 1.3796

🔁  StepLR applied — epoch 16, learning rate set to 0.05000

Epoch 17/200

Epoch 17: val_accuracy improved from 0.71300 to 0.72140, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_17.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_17

🕒  Recording time at 18:51

313/313 - 9s - 27ms/step - accuracy: 0.9156 - loss: 0.4184 - val_accuracy: 0.7214 - val_loss: 1.3642

🔁  StepLR applied — epoch 17, learning rate set to 0.05000

Epoch 18/200

Epoch 18: val_accuracy improved from 0.72140 to 0.72500, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_18.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_18

🕒  Recording time at 18:52

313/313 - 8s - 27ms/step - accuracy: 0.9201 - loss: 0.4109 - val_accuracy: 0.7250 - val_loss: 1.2447

🔁  StepLR applied — epoch 18, learning rate set to 0.05000

Epoch 19/200

Epoch 19: val_accuracy did not improve from 0.72500

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_19.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_19

🕒  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9240 - loss: 0.4062 - val_accuracy: 0.6302 - val_loss: 2.0122

🔁  StepLR applied — epoch 19, learning rate set to 0.05000

Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.72500

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_20.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_20

🕒  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9275 - loss: 0.4027 - val_accuracy: 0.6792 - val_loss: 1.9238

🔁  StepLR applied — epoch 20, learning rate set to 0.05000

Epoch 21/200

Epoch 21: val_accuracy did not improve from 0.72500

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_21.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_21

🕒  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9325 - loss: 0.3949 - val_accuracy: 0.7236 - val_loss: 1.3729

🔁  StepLR applied — epoch 21, learning rate set to 0.05000

Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.72500

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_22.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_22

🕒  Recording time at 18:52

313/313 - 8s - 26ms/step - accuracy: 0.9366 - loss: 0.3863 - val_accuracy: 0.7088 - val_loss: 1.6697

🔁  StepLR applied — epoch 22, learning rate set to 0.05000

Epoch 23/200

Epoch 23: val_accuracy improved from 0.72500 to 0.73620, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_23.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_23

🕒  Recording time at 18:52

313/313 - 8s - 27ms/step - accuracy: 0.9383 - loss: 0.3823 - val_accuracy: 0.7362 - val_loss: 1.3619

🔁  StepLR applied — epoch 23, learning rate set to 0.05000

Epoch 24/200

Epoch 24: val_accuracy improved from 0.73620 to 0.73740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_24.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_24

🕒  Recording time at 18:52

313/313 - 9s - 27ms/step - accuracy: 0.9470 - loss: 0.3654 - val_accuracy: 0.7374 - val_loss: 1.3658

🔁  StepLR applied — epoch 24, learning rate set to 0.05000

Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.73740

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_25.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_25

🕒  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9467 - loss: 0.3683 - val_accuracy: 0.7044 - val_loss: 1.5576

🔁  StepLR applied — epoch 25, learning rate set to 0.05000

Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.73740

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_26.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_26

🕒  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9479 - loss: 0.3685 - val_accuracy: 0.6764 - val_loss: 1.9882

🔁  StepLR applied — epoch 26, learning rate set to 0.05000

Epoch 27/200

Epoch 27: val_accuracy improved from 0.73740 to 0.74520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_27.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_27

🕒  Recording time at 18:53

313/313 - 8s - 27ms/step - accuracy: 0.9480 - loss: 0.3709 - val_accuracy: 0.7452 - val_loss: 1.2282

🔁  StepLR applied — epoch 27, learning rate set to 0.05000

Epoch 28/200

Epoch 28: val_accuracy improved from 0.74520 to 0.74740, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_28.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_28

🕒  Recording time at 18:53

313/313 - 9s - 29ms/step - accuracy: 0.9557 - loss: 0.3502 - val_accuracy: 0.7474 - val_loss: 1.2927

🔁  StepLR applied — epoch 28, learning rate set to 0.05000

Epoch 29/200

Epoch 29: val_accuracy improved from 0.74740 to 0.76700, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_29.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_29

🕒  Recording time at 18:53

313/313 - 9s - 27ms/step - accuracy: 0.9520 - loss: 0.3659 - val_accuracy: 0.7670 - val_loss: 1.2624

🔁  StepLR applied — epoch 29, learning rate set to 0.05000

Epoch 30/200

Epoch 30: val_accuracy did not improve from 0.76700

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_30.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_30

🕒  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9550 - loss: 0.3592 - val_accuracy: 0.7298 - val_loss: 1.5746

🔁  StepLR applied — epoch 30, learning rate set to 0.05000

Epoch 31/200

Epoch 31: val_accuracy did not improve from 0.76700

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_31.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_31

🕒  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9562 - loss: 0.3534 - val_accuracy: 0.7496 - val_loss: 1.3534

🔁  StepLR applied — epoch 31, learning rate set to 0.05000

Epoch 32/200

Epoch 32: val_accuracy did not improve from 0.76700

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_32.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_32

🕒  Recording time at 18:53

313/313 - 8s - 26ms/step - accuracy: 0.9535 - loss: 0.3650 - val_accuracy: 0.7406 - val_loss: 1.4698

🔁  StepLR applied — epoch 32, learning rate set to 0.05000

Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.76700

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_33.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_33

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9597 - loss: 0.3479 - val_accuracy: 0.6880 - val_loss: 1.7370

🔁  StepLR applied — epoch 33, learning rate set to 0.05000

Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.76700

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_34.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_34

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9638 - loss: 0.3381 - val_accuracy: 0.7434 - val_loss: 1.5414

🔁  StepLR applied — epoch 34, learning rate set to 0.05000

Epoch 35/200

Epoch 35: val_accuracy did not improve from 0.76700

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_35.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_35

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9628 - loss: 0.3422 - val_accuracy: 0.7222 - val_loss: 1.5945

🔁  StepLR applied — epoch 35, learning rate set to 0.05000

Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.76700

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_36.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_36

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9591 - loss: 0.3521 - val_accuracy: 0.6694 - val_loss: 2.2073

🔁  StepLR applied — epoch 36, learning rate set to 0.05000

Epoch 37/200

Epoch 37: val_accuracy did not improve from 0.76700

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_37.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_37

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9635 - loss: 0.3441 - val_accuracy: 0.7578 - val_loss: 1.3617

🔁  StepLR applied — epoch 37, learning rate set to 0.05000

Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.76700

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_38.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_38

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9653 - loss: 0.3363 - val_accuracy: 0.7192 - val_loss: 1.5206

🔁  StepLR applied — epoch 38, learning rate set to 0.05000

Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.76700

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_39.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_39

🕒  Recording time at 18:54

313/313 - 8s - 26ms/step - accuracy: 0.9612 - loss: 0.3484 - val_accuracy: 0.7504 - val_loss: 1.3339

🔁  StepLR applied — epoch 39, learning rate set to 0.05000

Epoch 40/200

Epoch 40: val_accuracy did not improve from 0.76700

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_40.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_40

🕒  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9634 - loss: 0.3409 - val_accuracy: 0.7184 - val_loss: 1.4740

🔁  StepLR applied — epoch 40, learning rate set to 0.05000

Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.76700

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_41.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_41

🕒  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9611 - loss: 0.3504 - val_accuracy: 0.7338 - val_loss: 1.4550

🔁  StepLR applied — epoch 41, learning rate set to 0.05000

Epoch 42/200

Epoch 42: val_accuracy did not improve from 0.76700

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_42.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_42

🕒  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9627 - loss: 0.3451 - val_accuracy: 0.6980 - val_loss: 1.6881

🔁  StepLR applied — epoch 42, learning rate set to 0.05000

Epoch 43/200

Epoch 43: val_accuracy did not improve from 0.76700

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_43.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_43

🕒  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9611 - loss: 0.3514 - val_accuracy: 0.7240 - val_loss: 1.4740

🔁  StepLR applied — epoch 43, learning rate set to 0.05000

Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.76700

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_44.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_44

🕒  Recording time at 18:55

313/313 - 8s - 26ms/step - accuracy: 0.9704 - loss: 0.3266 - val_accuracy: 0.7488 - val_loss: 1.5234
Epoch 44: early stopping
Restoring model weights from the end of the best epoch: 29.

🎯  _save_training_history

🎯  extract_history_metrics

📥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

🎯  evaluate_model

🎯  extract_history_metrics

🎯  build_augmentation_transform

🎯  build_normalization_transform

📈  TTA applied — averaged over 5 runs

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 9,
    "run": 2,
    "config_name": "m9_tuned",
    "date": "2025-05-25",
    "time": "15:26:14",
    "duration": "0:07:26",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.32662540674209595,
    "min_train_loss_epoch": 44,
    "max_train_acc": 0.9703750014305115,
    "max_train_acc_epoch": 44,
    "min_val_loss": 0.9870940446853638,
    "min_val_loss_epoch": 7,
    "max_val_acc": 0.7670000195503235,
    "max_val_acc_epoch": 29,
    "final_test_loss": 1.351456880569458,
    "final_test_acc": 0.771399974822998
  }
]

✅   m9 run 2 with 'm9_tuned' successfully executed

⚙️   Piplining experiment 5/5

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_drop.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

🚀  Launching experiment m9_r3 with 'm9_drop'

🎯  build_dataset

🎯  build_augmentation_transform

🎯  build_normalization_transform

🎯  build_normalization_transform

🎯  build_model

Model: "functional_4"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input_layer_4       │ (None, 32, 32, 3) │          0 │ -                 │
│ (InputLayer)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_72 (Conv2D)  │ (None, 32, 32,    │        448 │ input_layer_4[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_72[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_64       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_73 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_64[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_73[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_65       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_74 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_65[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_74[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_30 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_64[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_66       │ (None, 32, 32,    │          0 │ add_30[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_75 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_66[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_75[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_67       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_76 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_67[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_76[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_31 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_66[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_68       │ (None, 32, 32,    │          0 │ add_31[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_77 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_68[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_77[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_69       │ (None, 32, 32,    │          0 │ batch_normalizat… │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_78 (Conv2D)  │ (None, 32, 32,    │      2,320 │ activation_69[0]… │
│                     │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 32, 32,    │         64 │ conv2d_78[0][0]   │
│ (BatchNormalizatio… │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_32 (Add)        │ (None, 32, 32,    │          0 │ batch_normalizat… │
│                     │ 16)               │            │ activation_68[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_70       │ (None, 32, 32,    │          0 │ add_32[0][0]      │
│ (Activation)        │ 16)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_79 (Conv2D)  │ (None, 16, 16,    │      4,640 │ activation_70[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_79[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_71       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_80 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_71[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_80[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_81 (Conv2D)  │ (None, 16, 16,    │        544 │ activation_70[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_33 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ conv2d_81[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_72       │ (None, 16, 16,    │          0 │ add_33[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_82 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_72[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_82[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_73       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_83 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_73[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_83[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_34 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_72[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_74       │ (None, 16, 16,    │          0 │ add_34[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_84 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_74[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_84[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_75       │ (None, 16, 16,    │          0 │ batch_normalizat… │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_85 (Conv2D)  │ (None, 16, 16,    │      9,248 │ activation_75[0]… │
│                     │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 16, 16,    │        128 │ conv2d_85[0][0]   │
│ (BatchNormalizatio… │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_35 (Add)        │ (None, 16, 16,    │          0 │ batch_normalizat… │
│                     │ 32)               │            │ activation_74[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_76       │ (None, 16, 16,    │          0 │ add_35[0][0]      │
│ (Activation)        │ 32)               │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_86 (Conv2D)  │ (None, 8, 8, 64)  │     18,496 │ activation_76[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_86[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_77       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_87 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_77[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_87[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_88 (Conv2D)  │ (None, 8, 8, 64)  │      2,112 │ activation_76[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_36 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ conv2d_88[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_78       │ (None, 8, 8, 64)  │          0 │ add_36[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_89 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_78[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_89[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_79       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_90 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_79[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_90[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_37 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_78[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_80       │ (None, 8, 8, 64)  │          0 │ add_37[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_91 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_80[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_91[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_81       │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv2d_92 (Conv2D)  │ (None, 8, 8, 64)  │     36,928 │ activation_81[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ batch_normalizatio… │ (None, 8, 8, 64)  │        256 │ conv2d_92[0][0]   │
│ (BatchNormalizatio… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ add_38 (Add)        │ (None, 8, 8, 64)  │          0 │ batch_normalizat… │
│                     │                   │            │ activation_80[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ activation_82       │ (None, 8, 8, 64)  │          0 │ add_38[0][0]      │
│ (Activation)        │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ global_average_poo… │ (None, 64)        │          0 │ activation_82[0]… │
│ (GlobalAveragePool… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2 (Dropout) │ (None, 64)        │          0 │ global_average_p… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_4 (Dense)     │ (None, 10)        │        650 │ dropout_2[0][0]   │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)


🎯  _print_training_context

🖥️   Available compute devices:
  • /device:CPU:0 (CPU)
  • /device:GPU:0 (GPU)

🧮  GPU detected: True
  • /physical_device:GPU:0

🧠  Printing training configuration:
Light Mode:         OFF — Using reduced dataset for fast testing
Augmentation:       ON — Random Crop, Horizontal Flip
L2 Regularization:  ON (λ = 0.0001)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON — patience 15 epochs, restore best weights: True
Weight Averaging:   ON — starting at epoch 160
Test-Time Augment:  ON — running 5 augmented passes per sample
Epochs:             200
Batch Size:         128

🔁  StepLR applied — epoch 0, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 0, learning rate set to 0.01000

Epoch 1/200

Epoch 1: val_accuracy improved from -inf to 0.22920, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 1: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_01.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_1

🕒  Recording time at 18:57

313/313 - 30s - 96ms/step - accuracy: 0.3192 - loss: 1.9030 - val_accuracy: 0.2292 - val_loss: 3.1916

🔁  StepLR applied — epoch 1, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 1, learning rate set to 0.02000

Epoch 2/200

Epoch 2: val_accuracy improved from 0.22920 to 0.38020, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 2: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_02.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_2

🕒  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.4668 - loss: 1.5259 - val_accuracy: 0.3802 - val_loss: 2.2680

🔁  StepLR applied — epoch 2, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 2, learning rate set to 0.03000

Epoch 3/200

Epoch 3: val_accuracy improved from 0.38020 to 0.48060, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 3: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_03.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_3

🕒  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.5677 - loss: 1.2789 - val_accuracy: 0.4806 - val_loss: 1.8876

🔁  StepLR applied — epoch 3, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 3, learning rate set to 0.04000

Epoch 4/200

Epoch 4: val_accuracy improved from 0.48060 to 0.49520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 4: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_04.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_4

🕒  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.6316 - loss: 1.1219 - val_accuracy: 0.4952 - val_loss: 1.8482

🔁  StepLR applied — epoch 4, learning rate set to 0.05000


🔥  WarmupLR applied — epoch 4, learning rate set to 0.05000

Epoch 5/200

Epoch 5: val_accuracy improved from 0.49520 to 0.63300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 5: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_05.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_5

🕒  Recording time at 18:57

313/313 - 9s - 28ms/step - accuracy: 0.6798 - loss: 1.0105 - val_accuracy: 0.6330 - val_loss: 1.2658

🔁  StepLR applied — epoch 5, learning rate set to 0.05000

Epoch 6/200

Epoch 6: val_accuracy did not improve from 0.63300

Epoch 6: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_06.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_6

🕒  Recording time at 18:57

313/313 - 8s - 27ms/step - accuracy: 0.7251 - loss: 0.9015 - val_accuracy: 0.5322 - val_loss: 1.9594

🔁  StepLR applied — epoch 6, learning rate set to 0.05000

Epoch 7/200

Epoch 7: val_accuracy improved from 0.63300 to 0.67320, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 7: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_07.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_7

🕒  Recording time at 18:57

313/313 - 9s - 27ms/step - accuracy: 0.7547 - loss: 0.8208 - val_accuracy: 0.6732 - val_loss: 1.1420

🔁  StepLR applied — epoch 7, learning rate set to 0.05000

Epoch 8/200

Epoch 8: val_accuracy improved from 0.67320 to 0.71460, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 8: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_08.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_8

🕒  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.7811 - loss: 0.7553 - val_accuracy: 0.7146 - val_loss: 0.9816

🔁  StepLR applied — epoch 8, learning rate set to 0.05000

Epoch 9/200

Epoch 9: val_accuracy improved from 0.71460 to 0.71560, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 9: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_09.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_9

🕒  Recording time at 18:58

313/313 - 9s - 27ms/step - accuracy: 0.7981 - loss: 0.7169 - val_accuracy: 0.7156 - val_loss: 1.0697

🔁  StepLR applied — epoch 9, learning rate set to 0.05000

Epoch 10/200

Epoch 10: val_accuracy did not improve from 0.71560

Epoch 10: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_10.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_10

🕒  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.8156 - loss: 0.6691 - val_accuracy: 0.7060 - val_loss: 1.0624

🔁  StepLR applied — epoch 10, learning rate set to 0.05000

Epoch 11/200

Epoch 11: val_accuracy improved from 0.71560 to 0.74700, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 11: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_11.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_11

🕒  Recording time at 18:58

313/313 - 9s - 28ms/step - accuracy: 0.8292 - loss: 0.6390 - val_accuracy: 0.7470 - val_loss: 0.8687

🔁  StepLR applied — epoch 11, learning rate set to 0.05000

Epoch 12/200

Epoch 12: val_accuracy did not improve from 0.74700

Epoch 12: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_12.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_12

🕒  Recording time at 18:58

313/313 - 8s - 27ms/step - accuracy: 0.8392 - loss: 0.6144 - val_accuracy: 0.6732 - val_loss: 1.2394

🔁  StepLR applied — epoch 12, learning rate set to 0.05000

Epoch 13/200

Epoch 13: val_accuracy did not improve from 0.74700

Epoch 13: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_13.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_13

🕒  Recording time at 18:58

313/313 - 9s - 28ms/step - accuracy: 0.8503 - loss: 0.5891 - val_accuracy: 0.7274 - val_loss: 1.1147

🔁  StepLR applied — epoch 13, learning rate set to 0.05000

Epoch 14/200

Epoch 14: val_accuracy did not improve from 0.74700

Epoch 14: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_14.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_14

🕒  Recording time at 18:58

313/313 - 9s - 27ms/step - accuracy: 0.8605 - loss: 0.5649 - val_accuracy: 0.6822 - val_loss: 1.1741

🔁  StepLR applied — epoch 14, learning rate set to 0.05000

Epoch 15/200

Epoch 15: val_accuracy did not improve from 0.74700

Epoch 15: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_15.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_15

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8676 - loss: 0.5490 - val_accuracy: 0.7214 - val_loss: 1.1425

🔁  StepLR applied — epoch 15, learning rate set to 0.05000

Epoch 16/200

Epoch 16: val_accuracy did not improve from 0.74700

Epoch 16: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_16.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_16

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8777 - loss: 0.5227 - val_accuracy: 0.7206 - val_loss: 1.0881

🔁  StepLR applied — epoch 16, learning rate set to 0.05000

Epoch 17/200

Epoch 17: val_accuracy did not improve from 0.74700

Epoch 17: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_17.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_17

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8836 - loss: 0.5158 - val_accuracy: 0.7114 - val_loss: 1.1080

🔁  StepLR applied — epoch 17, learning rate set to 0.05000

Epoch 18/200

Epoch 18: val_accuracy did not improve from 0.74700

Epoch 18: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_18.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_18

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8899 - loss: 0.5022 - val_accuracy: 0.7150 - val_loss: 1.2614

🔁  StepLR applied — epoch 18, learning rate set to 0.05000

Epoch 19/200

Epoch 19: val_accuracy did not improve from 0.74700

Epoch 19: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_19.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_19

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8966 - loss: 0.4877 - val_accuracy: 0.6182 - val_loss: 1.9345

🔁  StepLR applied — epoch 19, learning rate set to 0.05000

Epoch 20/200

Epoch 20: val_accuracy did not improve from 0.74700

Epoch 20: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_20.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_20

🕒  Recording time at 18:59

313/313 - 8s - 26ms/step - accuracy: 0.8990 - loss: 0.4895 - val_accuracy: 0.6522 - val_loss: 1.6315

🔁  StepLR applied — epoch 20, learning rate set to 0.05000

Epoch 21/200

Epoch 21: val_accuracy improved from 0.74700 to 0.75900, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 21: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_21.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_21

🕒  Recording time at 18:59

313/313 - 9s - 27ms/step - accuracy: 0.9079 - loss: 0.4653 - val_accuracy: 0.7590 - val_loss: 1.1308

🔁  StepLR applied — epoch 21, learning rate set to 0.05000

Epoch 22/200

Epoch 22: val_accuracy did not improve from 0.75900

Epoch 22: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_22.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_22

🕒  Recording time at 19:00

313/313 - 8s - 26ms/step - accuracy: 0.9048 - loss: 0.4763 - val_accuracy: 0.7004 - val_loss: 1.4640

🔁  StepLR applied — epoch 22, learning rate set to 0.05000

Epoch 23/200

Epoch 23: val_accuracy did not improve from 0.75900

Epoch 23: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_23.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_23

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9118 - loss: 0.4670 - val_accuracy: 0.5998 - val_loss: 1.8911

🔁  StepLR applied — epoch 23, learning rate set to 0.05000

Epoch 24/200

Epoch 24: val_accuracy did not improve from 0.75900

Epoch 24: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_24.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_24

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9153 - loss: 0.4606 - val_accuracy: 0.7248 - val_loss: 1.4108

🔁  StepLR applied — epoch 24, learning rate set to 0.05000

Epoch 25/200

Epoch 25: val_accuracy did not improve from 0.75900

Epoch 25: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_25.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_25

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9214 - loss: 0.4488 - val_accuracy: 0.7228 - val_loss: 1.2478

🔁  StepLR applied — epoch 25, learning rate set to 0.05000

Epoch 26/200

Epoch 26: val_accuracy did not improve from 0.75900

Epoch 26: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_26.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_26

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9254 - loss: 0.4405 - val_accuracy: 0.6516 - val_loss: 1.8442

🔁  StepLR applied — epoch 26, learning rate set to 0.05000

Epoch 27/200

Epoch 27: val_accuracy did not improve from 0.75900

Epoch 27: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_27.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_27

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9265 - loss: 0.4425 - val_accuracy: 0.7512 - val_loss: 1.1791

🔁  StepLR applied — epoch 27, learning rate set to 0.05000

Epoch 28/200

Epoch 28: val_accuracy did not improve from 0.75900

Epoch 28: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_28.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_28

🕒  Recording time at 19:00

313/313 - 8s - 27ms/step - accuracy: 0.9299 - loss: 0.4385 - val_accuracy: 0.7574 - val_loss: 1.2305

🔁  StepLR applied — epoch 28, learning rate set to 0.05000

Epoch 29/200

Epoch 29: val_accuracy did not improve from 0.75900

Epoch 29: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_29.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_29

🕒  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9341 - loss: 0.4310 - val_accuracy: 0.7456 - val_loss: 1.2688

🔁  StepLR applied — epoch 29, learning rate set to 0.05000

Epoch 30/200

Epoch 30: val_accuracy did not improve from 0.75900

Epoch 30: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_30.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_30

🕒  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9361 - loss: 0.4226 - val_accuracy: 0.7244 - val_loss: 1.3107

🔁  StepLR applied — epoch 30, learning rate set to 0.05000

Epoch 31/200

Epoch 31: val_accuracy did not improve from 0.75900

Epoch 31: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_31.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_31

🕒  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9369 - loss: 0.4294 - val_accuracy: 0.7360 - val_loss: 1.2586

🔁  StepLR applied — epoch 31, learning rate set to 0.05000

Epoch 32/200

Epoch 32: val_accuracy improved from 0.75900 to 0.77960, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 32: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_32.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_32

🕒  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9408 - loss: 0.4176 - val_accuracy: 0.7796 - val_loss: 1.1445

🔁  StepLR applied — epoch 32, learning rate set to 0.05000

Epoch 33/200

Epoch 33: val_accuracy did not improve from 0.77960

Epoch 33: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_33.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_33

🕒  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9394 - loss: 0.4215 - val_accuracy: 0.7658 - val_loss: 1.1015

🔁  StepLR applied — epoch 33, learning rate set to 0.05000

Epoch 34/200

Epoch 34: val_accuracy did not improve from 0.77960

Epoch 34: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_34.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_34

🕒  Recording time at 19:01

313/313 - 8s - 27ms/step - accuracy: 0.9409 - loss: 0.4246 - val_accuracy: 0.7572 - val_loss: 1.2689

🔁  StepLR applied — epoch 34, learning rate set to 0.05000

Epoch 35/200

Epoch 35: val_accuracy did not improve from 0.77960

Epoch 35: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_35.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_35

🕒  Recording time at 19:01

313/313 - 8s - 26ms/step - accuracy: 0.9413 - loss: 0.4243 - val_accuracy: 0.7656 - val_loss: 1.1685

🔁  StepLR applied — epoch 35, learning rate set to 0.05000

Epoch 36/200

Epoch 36: val_accuracy did not improve from 0.77960

Epoch 36: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_36.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_36

🕒  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9416 - loss: 0.4255 - val_accuracy: 0.7770 - val_loss: 1.2026

🔁  StepLR applied — epoch 36, learning rate set to 0.05000

Epoch 37/200

Epoch 37: val_accuracy did not improve from 0.77960

Epoch 37: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_37.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_37

🕒  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9444 - loss: 0.4170 - val_accuracy: 0.7612 - val_loss: 1.1638

🔁  StepLR applied — epoch 37, learning rate set to 0.05000

Epoch 38/200

Epoch 38: val_accuracy did not improve from 0.77960

Epoch 38: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_38.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_38

🕒  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9495 - loss: 0.4051 - val_accuracy: 0.7576 - val_loss: 1.3194

🔁  StepLR applied — epoch 38, learning rate set to 0.05000

Epoch 39/200

Epoch 39: val_accuracy did not improve from 0.77960

Epoch 39: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_39.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_39

🕒  Recording time at 19:02

313/313 - 8s - 27ms/step - accuracy: 0.9452 - loss: 0.4169 - val_accuracy: 0.7556 - val_loss: 1.1856

🔁  StepLR applied — epoch 39, learning rate set to 0.05000

Epoch 40/200

Epoch 40: val_accuracy did not improve from 0.77960

Epoch 40: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_40.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_40

🕒  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9492 - loss: 0.4077 - val_accuracy: 0.7090 - val_loss: 1.6402

🔁  StepLR applied — epoch 40, learning rate set to 0.05000

Epoch 41/200

Epoch 41: val_accuracy did not improve from 0.77960

Epoch 41: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_41.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_41

🕒  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9492 - loss: 0.4084 - val_accuracy: 0.6970 - val_loss: 1.6289

🔁  StepLR applied — epoch 41, learning rate set to 0.05000

Epoch 42/200

Epoch 42: val_accuracy did not improve from 0.77960

Epoch 42: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_42.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_42

🕒  Recording time at 19:02

313/313 - 8s - 26ms/step - accuracy: 0.9484 - loss: 0.4156 - val_accuracy: 0.7242 - val_loss: 1.5309

🔁  StepLR applied — epoch 42, learning rate set to 0.05000

Epoch 43/200

Epoch 43: val_accuracy did not improve from 0.77960

Epoch 43: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_43.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_43

🕒  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9534 - loss: 0.3997 - val_accuracy: 0.7272 - val_loss: 1.4719

🔁  StepLR applied — epoch 43, learning rate set to 0.05000

Epoch 44/200

Epoch 44: val_accuracy did not improve from 0.77960

Epoch 44: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_44.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_44

🕒  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9484 - loss: 0.4118 - val_accuracy: 0.7330 - val_loss: 1.4818

🔁  StepLR applied — epoch 44, learning rate set to 0.05000

Epoch 45/200

Epoch 45: val_accuracy did not improve from 0.77960

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_45.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_45

🕒  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9486 - loss: 0.4159 - val_accuracy: 0.7430 - val_loss: 1.3060

🔁  StepLR applied — epoch 45, learning rate set to 0.05000

Epoch 46/200

Epoch 46: val_accuracy did not improve from 0.77960

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_46.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_46

🕒  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9543 - loss: 0.3983 - val_accuracy: 0.7722 - val_loss: 1.1816

🔁  StepLR applied — epoch 46, learning rate set to 0.05000

Epoch 47/200

Epoch 47: val_accuracy did not improve from 0.77960

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_47.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_47

🕒  Recording time at 19:03

313/313 - 8s - 26ms/step - accuracy: 0.9526 - loss: 0.4051 - val_accuracy: 0.6984 - val_loss: 1.7791
Epoch 47: early stopping
Restoring model weights from the end of the best epoch: 32.

🎯  _save_training_history

🎯  extract_history_metrics

📥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

🎯  evaluate_model

🎯  extract_history_metrics

🎯  build_augmentation_transform

🎯  build_normalization_transform

📈  TTA applied — averaged over 5 runs

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 9,
    "run": 3,
    "config_name": "m9_drop",
    "date": "2025-05-25",
    "time": "15:34:09",
    "duration": "0:07:55",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 160
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.39833468198776245,
    "min_train_loss_epoch": 46,
    "max_train_acc": 0.9543250203132629,
    "max_train_acc_epoch": 46,
    "min_val_loss": 0.868700385093689,
    "min_val_loss_epoch": 11,
    "max_val_acc": 0.7796000242233276,
    "max_val_acc_epoch": 32,
    "final_test_loss": 1.280393123626709,
    "final_test_acc": 0.7699999809265137
  }
]

✅   m9 run 3 with 'm9_drop' successfully executed

📦   Completed 5 total experiment runs
