
ğŸ“œ  Logging experiment output:
/content/drive/MyDrive/src/cifar-susume/artifact/log/log_2025-05-26_05-16-42.txt

ğŸ¯  _load_previous_results

âš™ï¸   Piplining experiment 1/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_base.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r1 with 'm9_base'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer         â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)     â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer[0][0] â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d[0][0]      â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation          â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation[0][0]  â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_1[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_1[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_2[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)           â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation[0][0]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2        â”‚ (None, 32, 32,    â”‚          0 â”‚ add[0][0]         â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_2[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_3[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_3        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_3[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_4[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_2[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_4        â”‚ (None, 32, 32,    â”‚          0 â”‚ add_1[0][0]       â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_4[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_5[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_5        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)   â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_5[0][â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_6[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_2 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_4[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_6        â”‚ (None, 32, 32,    â”‚          0 â”‚ add_2[0][0]       â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)   â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_6[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_7[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_7        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)   â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_7[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_8[0][0]    â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)   â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_6[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_3 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_9[0][0]    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_8        â”‚ (None, 16, 16,    â”‚          0 â”‚ add_3[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_8[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_10[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_9        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_9[0][â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_11[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_4 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_8[0][â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_10       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_4[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_10[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_12[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_11       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_11[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_13[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_5 (Add)         â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_10[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_12       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_5[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_12[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_14[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_13       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_13[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_15[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_12[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_6 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_16[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_14       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_6[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_14[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_17[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_15       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_15[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_18[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_7 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_14[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_16       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_7[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_16[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_19[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_17       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_17[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_20[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_8 (Add)         â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_16[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_18       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_8[0][0]       â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_18[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)       â”‚ (None, 10)        â”‚        650 â”‚ global_average_pâ€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m9_r1_m9_base at epoch_180

âš ï¸  Continuing training and rebuilding partial history

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.1
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 170
Test-Time Augment:  OFF
Epochs:             200
Batch Size:         128

Epoch 181/200

Epoch 181: val_accuracy improved from -inf to 0.80220, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 181: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_181.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_181

ğŸ•’  Recording time at 08:47

313/313 - 24s - 78ms/step - accuracy: 0.8263 - loss: 0.6874 - val_accuracy: 0.8022 - val_loss: 0.7954 - learning_rate: 1.0000e-05
Epoch 182/200

Epoch 182: val_accuracy improved from 0.80220 to 0.80300, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 182: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_182.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_182

ğŸ•’  Recording time at 08:48

313/313 - 14s - 46ms/step - accuracy: 0.8292 - loss: 0.6731 - val_accuracy: 0.8030 - val_loss: 0.7895 - learning_rate: 1.0000e-05
Epoch 183/200

Epoch 183: val_accuracy improved from 0.80300 to 0.80400, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 183: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_183.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_183

ğŸ•’  Recording time at 08:48

313/313 - 14s - 45ms/step - accuracy: 0.8303 - loss: 0.6668 - val_accuracy: 0.8040 - val_loss: 0.7833 - learning_rate: 1.0000e-05
Epoch 184/200

Epoch 184: val_accuracy improved from 0.80400 to 0.80520, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 184: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_184.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_184

ğŸ•’  Recording time at 08:48

313/313 - 14s - 45ms/step - accuracy: 0.8321 - loss: 0.6531 - val_accuracy: 0.8052 - val_loss: 0.7794 - learning_rate: 1.0000e-05
Epoch 185/200

Epoch 185: val_accuracy did not improve from 0.80520

Epoch 185: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_185.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_185

ğŸ•’  Recording time at 08:48

313/313 - 14s - 45ms/step - accuracy: 0.8336 - loss: 0.6471 - val_accuracy: 0.8042 - val_loss: 0.7747 - learning_rate: 1.0000e-05
Epoch 186/200

Epoch 186: val_accuracy did not improve from 0.80520

Epoch 186: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_186.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_186

ğŸ•’  Recording time at 08:49

313/313 - 14s - 45ms/step - accuracy: 0.8370 - loss: 0.6359 - val_accuracy: 0.8048 - val_loss: 0.7706 - learning_rate: 1.0000e-05
Epoch 187/200

Epoch 187: val_accuracy did not improve from 0.80520

Epoch 187: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_187.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_187

ğŸ•’  Recording time at 08:49

313/313 - 14s - 45ms/step - accuracy: 0.8384 - loss: 0.6263 - val_accuracy: 0.8044 - val_loss: 0.7667 - learning_rate: 1.0000e-05
Epoch 188/200

Epoch 188: val_accuracy did not improve from 0.80520

Epoch 188: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_188.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_188

ğŸ•’  Recording time at 08:49

313/313 - 14s - 45ms/step - accuracy: 0.8379 - loss: 0.6241 - val_accuracy: 0.8040 - val_loss: 0.7641 - learning_rate: 1.0000e-05
Epoch 189/200

Epoch 189: val_accuracy did not improve from 0.80520

Epoch 189: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_189.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_189

ğŸ•’  Recording time at 08:49

313/313 - 14s - 45ms/step - accuracy: 0.8404 - loss: 0.6133 - val_accuracy: 0.8050 - val_loss: 0.7608 - learning_rate: 1.0000e-05
Epoch 190/200

Epoch 190: val_accuracy improved from 0.80520 to 0.80660, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 190: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_190.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_190

ğŸ•’  Recording time at 08:50

313/313 - 14s - 46ms/step - accuracy: 0.8417 - loss: 0.6068 - val_accuracy: 0.8066 - val_loss: 0.7566 - learning_rate: 1.0000e-05
Epoch 191/200

Epoch 191: val_accuracy did not improve from 0.80660

Epoch 191: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_191.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_191

ğŸ•’  Recording time at 08:50

313/313 - 14s - 46ms/step - accuracy: 0.8425 - loss: 0.6003 - val_accuracy: 0.8056 - val_loss: 0.7541 - learning_rate: 1.0000e-05
Epoch 192/200

Epoch 192: val_accuracy improved from 0.80660 to 0.80680, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 192: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_192.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_192

ğŸ•’  Recording time at 08:50

313/313 - 15s - 47ms/step - accuracy: 0.8439 - loss: 0.5965 - val_accuracy: 0.8068 - val_loss: 0.7520 - learning_rate: 1.0000e-05
Epoch 193/200

Epoch 193: val_accuracy improved from 0.80680 to 0.80700, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 193: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_193.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_193

ğŸ•’  Recording time at 08:50

313/313 - 15s - 47ms/step - accuracy: 0.8440 - loss: 0.5911 - val_accuracy: 0.8070 - val_loss: 0.7487 - learning_rate: 1.0000e-05
Epoch 194/200

Epoch 194: val_accuracy improved from 0.80700 to 0.80800, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 194: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_194.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_194

ğŸ•’  Recording time at 08:51

313/313 - 15s - 47ms/step - accuracy: 0.8460 - loss: 0.5850 - val_accuracy: 0.8080 - val_loss: 0.7462 - learning_rate: 1.0000e-05
Epoch 195/200

Epoch 195: val_accuracy did not improve from 0.80800

Epoch 195: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_195.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_195

ğŸ•’  Recording time at 08:51

313/313 - 15s - 47ms/step - accuracy: 0.8497 - loss: 0.5791 - val_accuracy: 0.8078 - val_loss: 0.7437 - learning_rate: 1.0000e-05
Epoch 196/200

Epoch 196: val_accuracy improved from 0.80800 to 0.80920, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

Epoch 196: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_196.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_196

ğŸ•’  Recording time at 08:51

313/313 - 15s - 48ms/step - accuracy: 0.8482 - loss: 0.5773 - val_accuracy: 0.8092 - val_loss: 0.7426 - learning_rate: 1.0000e-05
Epoch 197/200

Epoch 197: val_accuracy did not improve from 0.80920

Epoch 197: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_197.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_197

ğŸ•’  Recording time at 08:51

313/313 - 15s - 47ms/step - accuracy: 0.8497 - loss: 0.5689 - val_accuracy: 0.8092 - val_loss: 0.7403 - learning_rate: 1.0000e-05
Epoch 198/200

Epoch 198: val_accuracy did not improve from 0.80920

Epoch 198: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_198.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_198

ğŸ•’  Recording time at 08:51

313/313 - 15s - 46ms/step - accuracy: 0.8515 - loss: 0.5637 - val_accuracy: 0.8090 - val_loss: 0.7380 - learning_rate: 1.0000e-05
Epoch 199/200

Epoch 199: val_accuracy did not improve from 0.80920

Epoch 199: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_199.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_199

ğŸ•’  Recording time at 08:52

313/313 - 15s - 46ms/step - accuracy: 0.8526 - loss: 0.5593 - val_accuracy: 0.8082 - val_loss: 0.7371 - learning_rate: 1.0000e-05
Epoch 200/200

Epoch 200: val_accuracy did not improve from 0.80920

Epoch 200: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/epoch_200.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_200

ğŸ•’  Recording time at 08:52

313/313 - 15s - 47ms/step - accuracy: 0.8538 - loss: 0.5542 - val_accuracy: 0.8092 - val_loss: 0.7360 - learning_rate: 1.0000e-05
Restoring model weights from the end of the best epoch: 196.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r1_m9_base/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 1,
    "config_name": "m9_base",
    "date": "2025-05-26",
    "time": "05:22:35",
    "duration": "0:05:53",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": 0.1,
        "patience": 3,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.21722985804080963,
    "min_train_loss_epoch": 18,
    "max_train_acc": 0.9778249859809875,
    "max_train_acc_epoch": 17,
    "min_val_loss": 0.7178073525428772,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.8095999956130981,
    "max_val_acc_epoch": 4,
    "final_test_loss": 0.6464659571647644,
    "final_test_acc": 0.8529000282287598
  }
]

âœ…   m9 run 1 with 'm9_base' successfully executed

âš™ï¸   Piplining experiment 2/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_legacy.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m6_r1 with 'm6_legacy'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_1       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21 (Conv2D)  â”‚ (None, 32, 32,    â”‚        896 â”‚ input_layer_1[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_21[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_19       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_22 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_19[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_22[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_20       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_23 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_20[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_23[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_9 (Add)         â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_19[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_21       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_9[0][0]       â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_24 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_21[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_24[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_22       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_25 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_22[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_25[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_10 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_21[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_23       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_10[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_27 (Conv2D)  â”‚ (None, 16, 16,    â”‚     18,496 â”‚ activation_23[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_27[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_24       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_28 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_24[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_28[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_26 (Conv2D)  â”‚ (None, 16, 16,    â”‚      2,112 â”‚ activation_23[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_11 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ conv2d_26[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_25       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_11[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_29 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_25[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_29[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_26       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_30 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_26[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_30[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_12 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ activation_25[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_27       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_12[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_32 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚     73,856 â”‚ activation_27[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_32[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_28       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_33 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_28[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_33[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_31 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚      8,320 â”‚ activation_27[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_13 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_31[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_29       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_13[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_34 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_29[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_34[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_30       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_35 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_30[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_35[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_14 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_29[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_31       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_14[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 128)       â”‚          0 â”‚ activation_31[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)   â”‚ (None, 128)       â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)     â”‚ (None, 10)        â”‚      1,290 â”‚ dropout[0][0]     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m6_r1_m6_legacy at epoch_72

âš ï¸  Continuing training and rebuilding partial history

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 0 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  OFF
Epochs:             100
Batch Size:         32

Epoch 73/100

Epoch 73: val_accuracy improved from -inf to 0.87000, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 73: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_73.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_73

ğŸ•’  Recording time at 08:53

1250/1250 - 26s - 21ms/step - accuracy: 0.8870 - loss: 0.4713 - val_accuracy: 0.8700 - val_loss: 0.5129 - learning_rate: 1.9531e-04
Epoch 74/100

Epoch 74: val_accuracy improved from 0.87000 to 0.87640, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 74: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_74.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_74

ğŸ•’  Recording time at 08:53

1250/1250 - 14s - 11ms/step - accuracy: 0.9270 - loss: 0.3304 - val_accuracy: 0.8764 - val_loss: 0.5026 - learning_rate: 1.9531e-04
Epoch 75/100

Epoch 75: val_accuracy improved from 0.87640 to 0.87800, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

Epoch 75: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_75.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_75

ğŸ•’  Recording time at 08:53

1250/1250 - 14s - 11ms/step - accuracy: 0.9474 - loss: 0.2713 - val_accuracy: 0.8780 - val_loss: 0.5046 - learning_rate: 1.9531e-04
Epoch 76/100

Epoch 76: val_accuracy did not improve from 0.87800

Epoch 76: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_76.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_76

ğŸ•’  Recording time at 08:54

1250/1250 - 14s - 11ms/step - accuracy: 0.9650 - loss: 0.2288 - val_accuracy: 0.8762 - val_loss: 0.5104 - learning_rate: 1.9531e-04
Epoch 77/100

Epoch 77: val_accuracy did not improve from 0.87800

Epoch 77: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_77.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_77

ğŸ•’  Recording time at 08:54

1250/1250 - 14s - 11ms/step - accuracy: 0.9751 - loss: 0.1998 - val_accuracy: 0.8750 - val_loss: 0.5166 - learning_rate: 1.9531e-04
Epoch 78/100

Epoch 78: val_accuracy did not improve from 0.87800

Epoch 78: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_78.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_78

ğŸ•’  Recording time at 08:54

1250/1250 - 14s - 11ms/step - accuracy: 0.9836 - loss: 0.1777 - val_accuracy: 0.8758 - val_loss: 0.5291 - learning_rate: 1.9531e-04
Epoch 79/100

Epoch 79: val_accuracy did not improve from 0.87800

Epoch 79: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_79.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_79

ğŸ•’  Recording time at 08:54

1250/1250 - 14s - 11ms/step - accuracy: 0.9884 - loss: 0.1633 - val_accuracy: 0.8734 - val_loss: 0.5341 - learning_rate: 1.9531e-04
Epoch 80/100

Epoch 80: val_accuracy did not improve from 0.87800

Epoch 80: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_80.keras

Epoch 80: ReduceLROnPlateau reducing learning rate to 9.765625145519152e-05.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_80

ğŸ•’  Recording time at 08:55

1250/1250 - 14s - 11ms/step - accuracy: 0.9922 - loss: 0.1527 - val_accuracy: 0.8762 - val_loss: 0.5337 - learning_rate: 1.9531e-04
Epoch 81/100

Epoch 81: val_accuracy did not improve from 0.87800

Epoch 81: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_81.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_81

ğŸ•’  Recording time at 08:55

1250/1250 - 14s - 11ms/step - accuracy: 0.9947 - loss: 0.1442 - val_accuracy: 0.8760 - val_loss: 0.5364 - learning_rate: 9.7656e-05
Epoch 82/100

Epoch 82: val_accuracy did not improve from 0.87800

Epoch 82: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_82.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_82

ğŸ•’  Recording time at 08:55

1250/1250 - 14s - 11ms/step - accuracy: 0.9962 - loss: 0.1390 - val_accuracy: 0.8766 - val_loss: 0.5393 - learning_rate: 9.7656e-05
Epoch 83/100

Epoch 83: val_accuracy did not improve from 0.87800

Epoch 83: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_83.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_83

ğŸ•’  Recording time at 08:55

1250/1250 - 14s - 11ms/step - accuracy: 0.9966 - loss: 0.1364 - val_accuracy: 0.8758 - val_loss: 0.5417 - learning_rate: 9.7656e-05
Epoch 84/100

Epoch 84: val_accuracy did not improve from 0.87800

Epoch 84: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_84.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_84

ğŸ•’  Recording time at 08:56

1250/1250 - 14s - 11ms/step - accuracy: 0.9972 - loss: 0.1341 - val_accuracy: 0.8758 - val_loss: 0.5436 - learning_rate: 9.7656e-05
Epoch 85/100

Epoch 85: val_accuracy did not improve from 0.87800

Epoch 85: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_85.keras

Epoch 85: ReduceLROnPlateau reducing learning rate to 4.882812572759576e-05.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_85

ğŸ•’  Recording time at 08:56

1250/1250 - 14s - 11ms/step - accuracy: 0.9970 - loss: 0.1328 - val_accuracy: 0.8730 - val_loss: 0.5476 - learning_rate: 9.7656e-05
Epoch 86/100

Epoch 86: val_accuracy did not improve from 0.87800

Epoch 86: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_86.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_86

ğŸ•’  Recording time at 08:56

1250/1250 - 14s - 11ms/step - accuracy: 0.9976 - loss: 0.1306 - val_accuracy: 0.8726 - val_loss: 0.5478 - learning_rate: 4.8828e-05
Epoch 87/100

Epoch 87: val_accuracy did not improve from 0.87800

Epoch 87: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_87.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_87

ğŸ•’  Recording time at 08:56

1250/1250 - 14s - 11ms/step - accuracy: 0.9974 - loss: 0.1290 - val_accuracy: 0.8738 - val_loss: 0.5479 - learning_rate: 4.8828e-05
Epoch 88/100

Epoch 88: val_accuracy did not improve from 0.87800

Epoch 88: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_88.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_88

ğŸ•’  Recording time at 08:56

1250/1250 - 14s - 11ms/step - accuracy: 0.9977 - loss: 0.1286 - val_accuracy: 0.8730 - val_loss: 0.5518 - learning_rate: 4.8828e-05
Epoch 89/100

Epoch 89: val_accuracy did not improve from 0.87800

Epoch 89: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_89.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_89

ğŸ•’  Recording time at 08:57

1250/1250 - 14s - 11ms/step - accuracy: 0.9982 - loss: 0.1280 - val_accuracy: 0.8730 - val_loss: 0.5525 - learning_rate: 4.8828e-05
Epoch 90/100

Epoch 90: val_accuracy did not improve from 0.87800

Epoch 90: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/epoch_90.keras

Epoch 90: ReduceLROnPlateau reducing learning rate to 2.441406286379788e-05.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_90

ğŸ•’  Recording time at 08:57

1250/1250 - 14s - 11ms/step - accuracy: 0.9984 - loss: 0.1267 - val_accuracy: 0.8740 - val_loss: 0.5532 - learning_rate: 4.8828e-05
Epoch 90: early stopping
Restoring model weights from the end of the best epoch: 75.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r1_m6_legacy/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 6,
    "run": 1,
    "config_name": "m6_legacy",
    "date": "2025-05-26",
    "time": "05:27:31",
    "duration": "0:04:55",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 0,
        "factor": 0.5,
        "patience": 5,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 0.10906655341386795,
    "min_train_loss_epoch": 72,
    "max_train_acc": 1.0,
    "max_train_acc_epoch": 63,
    "min_val_loss": 0.5025977492332458,
    "min_val_loss_epoch": 74,
    "max_val_acc": 0.878000020980835,
    "max_val_acc_epoch": 75,
    "final_test_loss": 0.5446161031723022,
    "final_test_acc": 0.8754000067710876
  }
]

âœ…   m6 run 1 with 'm6_legacy' successfully executed

âš™ï¸   Piplining experiment 3/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m6_rebase.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m6_r2 with 'm6_rebase'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_2"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_2       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_36 (Conv2D)  â”‚ (None, 32, 32,    â”‚        896 â”‚ input_layer_2[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_36[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_32       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_37 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_32[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_37[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_33       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_38 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_33[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_38[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_15 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_32[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_34       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_15[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_39 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_34[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_39[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_35       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_40 (Conv2D)  â”‚ (None, 32, 32,    â”‚      9,248 â”‚ activation_35[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚        128 â”‚ conv2d_40[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_16 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_34[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_36       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_16[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_42 (Conv2D)  â”‚ (None, 16, 16,    â”‚     18,496 â”‚ activation_36[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_42[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_37       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_43 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_37[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_43[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_41 (Conv2D)  â”‚ (None, 16, 16,    â”‚      2,112 â”‚ activation_36[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_17 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ conv2d_41[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_38       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_17[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_44 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_38[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_44[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_39       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_45 (Conv2D)  â”‚ (None, 16, 16,    â”‚     36,928 â”‚ activation_39[0]â€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        256 â”‚ conv2d_45[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_18 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 64)               â”‚            â”‚ activation_38[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_40       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_18[0][0]      â”‚
â”‚ (Activation)        â”‚ 64)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_47 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚     73,856 â”‚ activation_40[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_47[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_41       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_48 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_41[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_48[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_46 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚      8,320 â”‚ activation_40[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_19 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_46[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_42       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_19[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_49 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_42[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_49[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_43       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_50 (Conv2D)  â”‚ (None, 8, 8, 128) â”‚    147,584 â”‚ activation_43[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 128) â”‚        512 â”‚ conv2d_50[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_20 (Add)        â”‚ (None, 8, 8, 128) â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_42[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_44       â”‚ (None, 8, 8, 128) â”‚          0 â”‚ add_20[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 128)       â”‚          0 â”‚ activation_44[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout) â”‚ (None, 128)       â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)     â”‚ (None, 10)        â”‚      1,290 â”‚ dropout_1[0][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m6_r2_m6_rebase at epoch_60

âš ï¸  Continuing training and rebuilding partial history

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip, Cutout
L2 Regularization:  ON (Î» = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   OFF
Test-Time Augment:  OFF
Epochs:             100
Batch Size:         32


ğŸ”  StepLR applied â€” epoch 60, learning rate set to 0.05000

Epoch 61/100

Epoch 61: val_accuracy improved from -inf to 0.66440, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 61: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_61.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_61

ğŸ•’  Recording time at 08:58

1250/1250 - 24s - 19ms/step - accuracy: 0.7006 - loss: 1.4521 - val_accuracy: 0.6644 - val_loss: 1.5263

ğŸ”  StepLR applied â€” epoch 61, learning rate set to 0.05000

Epoch 62/100

Epoch 62: val_accuracy did not improve from 0.66440

Epoch 62: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_62.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_62

ğŸ•’  Recording time at 08:58

1250/1250 - 14s - 11ms/step - accuracy: 0.7133 - loss: 1.4005 - val_accuracy: 0.6048 - val_loss: 1.7117

ğŸ”  StepLR applied â€” epoch 62, learning rate set to 0.05000

Epoch 63/100

Epoch 63: val_accuracy did not improve from 0.66440

Epoch 63: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_63.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_63

ğŸ•’  Recording time at 08:58

1250/1250 - 14s - 11ms/step - accuracy: 0.7183 - loss: 1.3978 - val_accuracy: 0.6048 - val_loss: 1.8142

ğŸ”  StepLR applied â€” epoch 63, learning rate set to 0.05000

Epoch 64/100

Epoch 64: val_accuracy did not improve from 0.66440

Epoch 64: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_64.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_64

ğŸ•’  Recording time at 08:59

1250/1250 - 14s - 11ms/step - accuracy: 0.7207 - loss: 1.3929 - val_accuracy: 0.4476 - val_loss: 2.3285

ğŸ”  StepLR applied â€” epoch 64, learning rate set to 0.05000

Epoch 65/100

Epoch 65: val_accuracy improved from 0.66440 to 0.67500, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

Epoch 65: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_65.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_65

ğŸ•’  Recording time at 08:59

1250/1250 - 14s - 11ms/step - accuracy: 0.7250 - loss: 1.3896 - val_accuracy: 0.6750 - val_loss: 1.5253

ğŸ”  StepLR applied â€” epoch 65, learning rate set to 0.05000

Epoch 66/100

Epoch 66: val_accuracy did not improve from 0.67500

Epoch 66: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_66.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_66

ğŸ•’  Recording time at 08:59

1250/1250 - 14s - 11ms/step - accuracy: 0.7236 - loss: 1.3967 - val_accuracy: 0.4988 - val_loss: 2.3883

ğŸ”  StepLR applied â€” epoch 66, learning rate set to 0.05000

Epoch 67/100

Epoch 67: val_accuracy did not improve from 0.67500

Epoch 67: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_67.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_67

ğŸ•’  Recording time at 08:59

1250/1250 - 14s - 11ms/step - accuracy: 0.7256 - loss: 1.3970 - val_accuracy: 0.6162 - val_loss: 1.7181

ğŸ”  StepLR applied â€” epoch 67, learning rate set to 0.05000

Epoch 68/100

Epoch 68: val_accuracy did not improve from 0.67500

Epoch 68: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_68.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_68

ğŸ•’  Recording time at 09:00

1250/1250 - 14s - 11ms/step - accuracy: 0.7276 - loss: 1.3948 - val_accuracy: 0.5838 - val_loss: 1.8095

ğŸ”  StepLR applied â€” epoch 68, learning rate set to 0.05000

Epoch 69/100

Epoch 69: val_accuracy did not improve from 0.67500

Epoch 69: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_69.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_69

ğŸ•’  Recording time at 09:00

1250/1250 - 14s - 11ms/step - accuracy: 0.7247 - loss: 1.3983 - val_accuracy: 0.6400 - val_loss: 1.6687

ğŸ”  StepLR applied â€” epoch 69, learning rate set to 0.05000

Epoch 70/100

Epoch 70: val_accuracy did not improve from 0.67500

Epoch 70: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_70.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_70

ğŸ•’  Recording time at 09:00

1250/1250 - 14s - 11ms/step - accuracy: 0.7278 - loss: 1.3974 - val_accuracy: 0.6434 - val_loss: 1.6372

ğŸ”  StepLR applied â€” epoch 70, learning rate set to 0.05000

Epoch 71/100

Epoch 71: val_accuracy did not improve from 0.67500

Epoch 71: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_71.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_71

ğŸ•’  Recording time at 09:00

1250/1250 - 14s - 11ms/step - accuracy: 0.7284 - loss: 1.3966 - val_accuracy: 0.5504 - val_loss: 1.9487

ğŸ”  StepLR applied â€” epoch 71, learning rate set to 0.05000

Epoch 72/100

Epoch 72: val_accuracy did not improve from 0.67500

Epoch 72: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_72.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_72

ğŸ•’  Recording time at 09:00

1250/1250 - 14s - 11ms/step - accuracy: 0.7285 - loss: 1.4012 - val_accuracy: 0.4548 - val_loss: 2.3932

ğŸ”  StepLR applied â€” epoch 72, learning rate set to 0.05000

Epoch 73/100

Epoch 73: val_accuracy did not improve from 0.67500

Epoch 73: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_73.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_73

ğŸ•’  Recording time at 09:01

1250/1250 - 14s - 11ms/step - accuracy: 0.7290 - loss: 1.4006 - val_accuracy: 0.5164 - val_loss: 2.0915

ğŸ”  StepLR applied â€” epoch 73, learning rate set to 0.05000

Epoch 74/100

Epoch 74: val_accuracy did not improve from 0.67500

Epoch 74: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_74.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_74

ğŸ•’  Recording time at 09:01

1250/1250 - 14s - 11ms/step - accuracy: 0.7326 - loss: 1.3965 - val_accuracy: 0.5290 - val_loss: 1.9851

ğŸ”  StepLR applied â€” epoch 74, learning rate set to 0.05000

Epoch 75/100

Epoch 75: val_accuracy did not improve from 0.67500

Epoch 75: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_75.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_75

ğŸ•’  Recording time at 09:01

1250/1250 - 14s - 11ms/step - accuracy: 0.7256 - loss: 1.4071 - val_accuracy: 0.6166 - val_loss: 1.7850

ğŸ”  StepLR applied â€” epoch 75, learning rate set to 0.05000

Epoch 76/100

Epoch 76: val_accuracy did not improve from 0.67500

Epoch 76: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_76.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_76

ğŸ•’  Recording time at 09:01

1250/1250 - 14s - 11ms/step - accuracy: 0.7283 - loss: 1.4054 - val_accuracy: 0.5940 - val_loss: 1.7904

ğŸ”  StepLR applied â€” epoch 76, learning rate set to 0.05000

Epoch 77/100

Epoch 77: val_accuracy did not improve from 0.67500

Epoch 77: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_77.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_77

ğŸ•’  Recording time at 09:02

1250/1250 - 14s - 11ms/step - accuracy: 0.7297 - loss: 1.4051 - val_accuracy: 0.6194 - val_loss: 1.6961

ğŸ”  StepLR applied â€” epoch 77, learning rate set to 0.05000

Epoch 78/100

Epoch 78: val_accuracy did not improve from 0.67500

Epoch 78: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_78.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_78

ğŸ•’  Recording time at 09:02

1250/1250 - 14s - 11ms/step - accuracy: 0.7310 - loss: 1.4068 - val_accuracy: 0.6310 - val_loss: 1.6676

ğŸ”  StepLR applied â€” epoch 78, learning rate set to 0.05000

Epoch 79/100

Epoch 79: val_accuracy did not improve from 0.67500

Epoch 79: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_79.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_79

ğŸ•’  Recording time at 09:02

1250/1250 - 14s - 11ms/step - accuracy: 0.7282 - loss: 1.4074 - val_accuracy: 0.5512 - val_loss: 1.9270

ğŸ”  StepLR applied â€” epoch 79, learning rate set to 0.05000

Epoch 80/100

Epoch 80: val_accuracy did not improve from 0.67500

Epoch 80: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/epoch_80.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_80

ğŸ•’  Recording time at 09:02

1250/1250 - 14s - 11ms/step - accuracy: 0.7300 - loss: 1.4023 - val_accuracy: 0.5952 - val_loss: 1.7688
Epoch 80: early stopping
Restoring model weights from the end of the best epoch: 65.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m6_r2_m6_rebase/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 6,
    "run": 2,
    "config_name": "m6_rebase",
    "date": "2025-05-26",
    "time": "05:32:56",
    "duration": "0:05:24",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": true
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": false,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 100,
      "BATCH_SIZE": 32
    },
    "min_train_loss": 1.3896182775497437,
    "min_train_loss_epoch": 65,
    "max_train_acc": 0.7326250076293945,
    "max_train_acc_epoch": 74,
    "min_val_loss": 1.5175951719284058,
    "min_val_loss_epoch": 45,
    "max_val_acc": 0.6858000159263611,
    "max_val_acc_epoch": 45,
    "final_test_loss": 1.3790611028671265,
    "final_test_acc": 0.7369999885559082
  }
]

âœ…   m6 run 2 with 'm6_rebase' successfully executed

âš™ï¸   Piplining experiment 4/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_tuned.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r2 with 'm9_tuned'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_3"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_3       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_51 (Conv2D)  â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer_3[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_51[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_45       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_52 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_45[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_52[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_46       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_53 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_46[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_53[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_21 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_45[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_47       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_21[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_54 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_47[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_54[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_48       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_55 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_48[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_55[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_22 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_47[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_49       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_22[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_56 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_49[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_56[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_50       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_57 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_50[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_57[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_23 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_49[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_51       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_23[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_58 (Conv2D)  â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_51[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_58[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_52       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_59 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_52[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_59[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_60 (Conv2D)  â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_51[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_24 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_60[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_53       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_24[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_61 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_53[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_61[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_54       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_62 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_54[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_62[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_25 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_53[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_55       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_25[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_63 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_55[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_63[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_56       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_64 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_56[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_64[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_26 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_55[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_57       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_26[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_65 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_57[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_65[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_58       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_66 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_58[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_66[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_67 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_57[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_27 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_67[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_59       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_27[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_68 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_59[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_68[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_60       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_69 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_60[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_69[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_28 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_59[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_61       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_28[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_70 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_61[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_70[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_62       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_71 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_62[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_71[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_29 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_61[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_63       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_29[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_63[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)     â”‚ (None, 10)        â”‚        650 â”‚ global_average_pâ€¦ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m9_r2_m9_tuned at epoch_44

âš ï¸  Continuing training and rebuilding partial history

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0001)
Dropout:            OFF (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 170
Test-Time Augment:  OFF
Epochs:             200
Batch Size:         128


ğŸ”  StepLR applied â€” epoch 44, learning rate set to 0.05000

Epoch 45/200

Epoch 45: val_accuracy improved from -inf to 0.78860, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

Epoch 45: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_45.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_45

ğŸ•’  Recording time at 09:03

313/313 - 29s - 92ms/step - accuracy: 0.8114 - loss: 0.8170 - val_accuracy: 0.7886 - val_loss: 0.8880

ğŸ”  StepLR applied â€” epoch 45, learning rate set to 0.05000

Epoch 46/200

Epoch 46: val_accuracy did not improve from 0.78860

Epoch 46: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_46.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_46

ğŸ•’  Recording time at 09:04

313/313 - 8s - 27ms/step - accuracy: 0.8687 - loss: 0.6190 - val_accuracy: 0.7632 - val_loss: 0.9490

ğŸ”  StepLR applied â€” epoch 46, learning rate set to 0.05000

Epoch 47/200

Epoch 47: val_accuracy did not improve from 0.78860

Epoch 47: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_47.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_47

ğŸ•’  Recording time at 09:04

313/313 - 8s - 26ms/step - accuracy: 0.8921 - loss: 0.5437 - val_accuracy: 0.7770 - val_loss: 0.9762

ğŸ”  StepLR applied â€” epoch 47, learning rate set to 0.05000

Epoch 48/200

Epoch 48: val_accuracy did not improve from 0.78860

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_48.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_48

ğŸ•’  Recording time at 09:04

313/313 - 8s - 27ms/step - accuracy: 0.9075 - loss: 0.4980 - val_accuracy: 0.7726 - val_loss: 1.0229

ğŸ”  StepLR applied â€” epoch 48, learning rate set to 0.05000

Epoch 49/200

Epoch 49: val_accuracy did not improve from 0.78860

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_49.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_49

ğŸ•’  Recording time at 09:04

313/313 - 8s - 27ms/step - accuracy: 0.9169 - loss: 0.4684 - val_accuracy: 0.7602 - val_loss: 1.2210

ğŸ”  StepLR applied â€” epoch 49, learning rate set to 0.05000

Epoch 50/200

Epoch 50: val_accuracy did not improve from 0.78860

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_50.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_50

ğŸ•’  Recording time at 09:04

313/313 - 8s - 27ms/step - accuracy: 0.9243 - loss: 0.4474 - val_accuracy: 0.7708 - val_loss: 1.0391

ğŸ”  StepLR applied â€” epoch 50, learning rate set to 0.05000

Epoch 51/200

Epoch 51: val_accuracy did not improve from 0.78860

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_51.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_51

ğŸ•’  Recording time at 09:04

313/313 - 8s - 26ms/step - accuracy: 0.9291 - loss: 0.4332 - val_accuracy: 0.7848 - val_loss: 1.0487

ğŸ”  StepLR applied â€” epoch 51, learning rate set to 0.05000

Epoch 52/200

Epoch 52: val_accuracy did not improve from 0.78860

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_52.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_52

ğŸ•’  Recording time at 09:04

313/313 - 8s - 26ms/step - accuracy: 0.9367 - loss: 0.4161 - val_accuracy: 0.7644 - val_loss: 1.1566

ğŸ”  StepLR applied â€” epoch 52, learning rate set to 0.05000

Epoch 53/200

Epoch 53: val_accuracy did not improve from 0.78860

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_53.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_53

ğŸ•’  Recording time at 09:04

313/313 - 8s - 26ms/step - accuracy: 0.9396 - loss: 0.4070 - val_accuracy: 0.7688 - val_loss: 1.1719

ğŸ”  StepLR applied â€” epoch 53, learning rate set to 0.05000

Epoch 54/200

Epoch 54: val_accuracy did not improve from 0.78860

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_54.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_54

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9443 - loss: 0.3997 - val_accuracy: 0.7548 - val_loss: 1.2450

ğŸ”  StepLR applied â€” epoch 54, learning rate set to 0.05000

Epoch 55/200

Epoch 55: val_accuracy did not improve from 0.78860

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_55.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_55

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9508 - loss: 0.3791 - val_accuracy: 0.7242 - val_loss: 1.4999

ğŸ”  StepLR applied â€” epoch 55, learning rate set to 0.05000

Epoch 56/200

Epoch 56: val_accuracy did not improve from 0.78860

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_56.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_56

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9475 - loss: 0.3929 - val_accuracy: 0.7548 - val_loss: 1.2462

ğŸ”  StepLR applied â€” epoch 56, learning rate set to 0.05000

Epoch 57/200

Epoch 57: val_accuracy did not improve from 0.78860

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_57.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_57

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9476 - loss: 0.3903 - val_accuracy: 0.7182 - val_loss: 1.6791

ğŸ”  StepLR applied â€” epoch 57, learning rate set to 0.05000

Epoch 58/200

Epoch 58: val_accuracy did not improve from 0.78860

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_58.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_58

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9525 - loss: 0.3811 - val_accuracy: 0.7632 - val_loss: 1.2427

ğŸ”  StepLR applied â€” epoch 58, learning rate set to 0.05000

Epoch 59/200

Epoch 59: val_accuracy did not improve from 0.78860

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_59.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_59

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9578 - loss: 0.3646 - val_accuracy: 0.7520 - val_loss: 1.3558

ğŸ”  StepLR applied â€” epoch 59, learning rate set to 0.05000

Epoch 60/200

Epoch 60: val_accuracy did not improve from 0.78860

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/epoch_60.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_60

ğŸ•’  Recording time at 09:05

313/313 - 8s - 26ms/step - accuracy: 0.9609 - loss: 0.3598 - val_accuracy: 0.7498 - val_loss: 1.4736
Epoch 60: early stopping
Restoring model weights from the end of the best epoch: 45.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r2_m9_tuned/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 2,
    "config_name": "m9_tuned",
    "date": "2025-05-26",
    "time": "05:36:05",
    "duration": "0:03:09",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": false,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.32662540674209595,
    "min_train_loss_epoch": 44,
    "max_train_acc": 0.9703750014305115,
    "max_train_acc_epoch": 44,
    "min_val_loss": 0.8879655003547668,
    "min_val_loss_epoch": 45,
    "max_val_acc": 0.7886000275611877,
    "max_val_acc_epoch": 45,
    "final_test_loss": 0.9213802814483643,
    "final_test_acc": 0.7792999744415283
  }
]

âœ…   m9 run 2 with 'm9_tuned' successfully executed

âš™ï¸   Piplining experiment 5/5

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/content/drive/MyDrive/src/cifar-susume/artifact/config/m9_drop.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/content/drive/MyDrive/src/cifar-susume/artifact/log
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint
/content/drive/MyDrive/src/cifar-susume/artifact/result
/content/drive/MyDrive/src/cifar-susume/artifact/model
/content/drive/MyDrive/src/cifar-susume/artifact/error

ğŸš€  Launching experiment m9_r3 with 'm9_drop'

ğŸ¯  build_dataset

ğŸ¯  build_augmentation_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_normalization_transform

ğŸ¯  build_model

Model: "functional_4"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)        â”ƒ Output Shape      â”ƒ    Param # â”ƒ Connected to      â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_4       â”‚ (None, 32, 32, 3) â”‚          0 â”‚ -                 â”‚
â”‚ (InputLayer)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_72 (Conv2D)  â”‚ (None, 32, 32,    â”‚        448 â”‚ input_layer_4[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_72[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_64       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_73 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_64[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_73[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_65       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_74 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_65[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_74[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_30 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_64[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_66       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_30[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_75 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_66[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_75[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_67       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_76 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_67[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_76[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_31 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_66[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_68       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_31[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_77 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_68[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_77[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_69       â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_78 (Conv2D)  â”‚ (None, 32, 32,    â”‚      2,320 â”‚ activation_69[0]â€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 32, 32,    â”‚         64 â”‚ conv2d_78[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_32 (Add)        â”‚ (None, 32, 32,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 16)               â”‚            â”‚ activation_68[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_70       â”‚ (None, 32, 32,    â”‚          0 â”‚ add_32[0][0]      â”‚
â”‚ (Activation)        â”‚ 16)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_79 (Conv2D)  â”‚ (None, 16, 16,    â”‚      4,640 â”‚ activation_70[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_79[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_71       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_80 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_71[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_80[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_81 (Conv2D)  â”‚ (None, 16, 16,    â”‚        544 â”‚ activation_70[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_33 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ conv2d_81[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_72       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_33[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_82 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_72[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_82[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_73       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_83 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_73[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_83[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_34 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_72[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_74       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_34[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_84 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_74[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_84[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_75       â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_85 (Conv2D)  â”‚ (None, 16, 16,    â”‚      9,248 â”‚ activation_75[0]â€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 16, 16,    â”‚        128 â”‚ conv2d_85[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_35 (Add)        â”‚ (None, 16, 16,    â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚ 32)               â”‚            â”‚ activation_74[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_76       â”‚ (None, 16, 16,    â”‚          0 â”‚ add_35[0][0]      â”‚
â”‚ (Activation)        â”‚ 32)               â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_86 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     18,496 â”‚ activation_76[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_86[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_77       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_87 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_77[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_87[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_88 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚      2,112 â”‚ activation_76[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_36 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ conv2d_88[0][0]   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_78       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_36[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_89 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_78[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_89[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_79       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_90 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_79[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_90[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_37 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_78[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_80       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_37[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_91 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_80[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_91[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_81       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_92 (Conv2D)  â”‚ (None, 8, 8, 64)  â”‚     36,928 â”‚ activation_81[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatioâ€¦ â”‚ (None, 8, 8, 64)  â”‚        256 â”‚ conv2d_92[0][0]   â”‚
â”‚ (BatchNormalizatioâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_38 (Add)        â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ batch_normalizatâ€¦ â”‚
â”‚                     â”‚                   â”‚            â”‚ activation_80[0]â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_82       â”‚ (None, 8, 8, 64)  â”‚          0 â”‚ add_38[0][0]      â”‚
â”‚ (Activation)        â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_pooâ€¦ â”‚ (None, 64)        â”‚          0 â”‚ activation_82[0]â€¦ â”‚
â”‚ (GlobalAveragePoolâ€¦ â”‚                   â”‚            â”‚                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout) â”‚ (None, 64)        â”‚          0 â”‚ global_average_pâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)     â”‚ (None, 10)        â”‚        650 â”‚ dropout_2[0][0]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ”  Resuming experiment m9_r3_m9_drop at epoch_47

âš ï¸  Continuing training and rebuilding partial history

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)


ğŸ¯  _print_training_context

ğŸ–¥ï¸   Available compute devices:
  â€¢ /device:CPU:0 (CPU)
  â€¢ /device:GPU:0 (GPU)

ğŸ§®  GPU detected: True
  â€¢ /physical_device:GPU:0

ğŸ§   Printing training configuration:
Light Mode:         OFF â€” Using reduced dataset for fast testing
Augmentation:       ON â€” Random Crop, Horizontal Flip
L2 Regularization:  ON (Î» = 0.0001)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON â€” warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON â€” patience 15 epochs, restore best weights: True
Weight Averaging:   ON â€” starting at epoch 160
Test-Time Augment:  OFF
Epochs:             200
Batch Size:         128


ğŸ”  StepLR applied â€” epoch 47, learning rate set to 0.05000

Epoch 48/200

Epoch 48: val_accuracy improved from -inf to 0.72980, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 48: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_48.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_48

ğŸ•’  Recording time at 09:07

313/313 - 28s - 89ms/step - accuracy: 0.8202 - loss: 0.8190 - val_accuracy: 0.7298 - val_loss: 1.1487

ğŸ”  StepLR applied â€” epoch 48, learning rate set to 0.05000

Epoch 49/200

Epoch 49: val_accuracy improved from 0.72980 to 0.78780, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 49: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_49.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_49

ğŸ•’  Recording time at 09:07

313/313 - 9s - 27ms/step - accuracy: 0.8625 - loss: 0.6647 - val_accuracy: 0.7878 - val_loss: 0.9268

ğŸ”  StepLR applied â€” epoch 49, learning rate set to 0.05000

Epoch 50/200

Epoch 50: val_accuracy improved from 0.78780 to 0.80580, saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

Epoch 50: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_50.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_50

ğŸ•’  Recording time at 09:07

313/313 - 9s - 27ms/step - accuracy: 0.8827 - loss: 0.6010 - val_accuracy: 0.8058 - val_loss: 0.8390

ğŸ”  StepLR applied â€” epoch 50, learning rate set to 0.05000

Epoch 51/200

Epoch 51: val_accuracy did not improve from 0.80580

Epoch 51: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_51.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_51

ğŸ•’  Recording time at 09:07

313/313 - 8s - 27ms/step - accuracy: 0.8939 - loss: 0.5687 - val_accuracy: 0.8004 - val_loss: 0.8465

ğŸ”  StepLR applied â€” epoch 51, learning rate set to 0.05000

Epoch 52/200

Epoch 52: val_accuracy did not improve from 0.80580

Epoch 52: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_52.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_52

ğŸ•’  Recording time at 09:07

313/313 - 8s - 27ms/step - accuracy: 0.9015 - loss: 0.5398 - val_accuracy: 0.7712 - val_loss: 1.0804

ğŸ”  StepLR applied â€” epoch 52, learning rate set to 0.05000

Epoch 53/200

Epoch 53: val_accuracy did not improve from 0.80580

Epoch 53: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_53.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_53

ğŸ•’  Recording time at 09:07

313/313 - 8s - 27ms/step - accuracy: 0.9112 - loss: 0.5105 - val_accuracy: 0.7652 - val_loss: 1.1719

ğŸ”  StepLR applied â€” epoch 53, learning rate set to 0.05000

Epoch 54/200

Epoch 54: val_accuracy did not improve from 0.80580

Epoch 54: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_54.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_54

ğŸ•’  Recording time at 09:07

313/313 - 8s - 26ms/step - accuracy: 0.9158 - loss: 0.4976 - val_accuracy: 0.7516 - val_loss: 1.2341

ğŸ”  StepLR applied â€” epoch 54, learning rate set to 0.05000

Epoch 55/200

Epoch 55: val_accuracy did not improve from 0.80580

Epoch 55: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_55.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_55

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9192 - loss: 0.4901 - val_accuracy: 0.7392 - val_loss: 1.3360

ğŸ”  StepLR applied â€” epoch 55, learning rate set to 0.05000

Epoch 56/200

Epoch 56: val_accuracy did not improve from 0.80580

Epoch 56: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_56.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_56

ğŸ•’  Recording time at 09:08

313/313 - 8s - 27ms/step - accuracy: 0.9235 - loss: 0.4772 - val_accuracy: 0.7812 - val_loss: 1.0536

ğŸ”  StepLR applied â€” epoch 56, learning rate set to 0.05000

Epoch 57/200

Epoch 57: val_accuracy did not improve from 0.80580

Epoch 57: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_57.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_57

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9324 - loss: 0.4567 - val_accuracy: 0.7618 - val_loss: 1.1835

ğŸ”  StepLR applied â€” epoch 57, learning rate set to 0.05000

Epoch 58/200

Epoch 58: val_accuracy did not improve from 0.80580

Epoch 58: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_58.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_58

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9346 - loss: 0.4498 - val_accuracy: 0.7972 - val_loss: 1.0688

ğŸ”  StepLR applied â€” epoch 58, learning rate set to 0.05000

Epoch 59/200

Epoch 59: val_accuracy did not improve from 0.80580

Epoch 59: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_59.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_59

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9388 - loss: 0.4396 - val_accuracy: 0.7414 - val_loss: 1.2819

ğŸ”  StepLR applied â€” epoch 59, learning rate set to 0.05000

Epoch 60/200

Epoch 60: val_accuracy did not improve from 0.80580

Epoch 60: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_60.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_60

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9343 - loss: 0.4551 - val_accuracy: 0.7946 - val_loss: 1.0893

ğŸ”  StepLR applied â€” epoch 60, learning rate set to 0.05000

Epoch 61/200

Epoch 61: val_accuracy did not improve from 0.80580

Epoch 61: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_61.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_61

ğŸ•’  Recording time at 09:08

313/313 - 8s - 26ms/step - accuracy: 0.9387 - loss: 0.4420 - val_accuracy: 0.7790 - val_loss: 1.1147

ğŸ”  StepLR applied â€” epoch 61, learning rate set to 0.05000

Epoch 62/200

Epoch 62: val_accuracy did not improve from 0.80580

Epoch 62: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_62.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_62

ğŸ•’  Recording time at 09:08

313/313 - 8s - 27ms/step - accuracy: 0.9423 - loss: 0.4341 - val_accuracy: 0.7376 - val_loss: 1.3534

ğŸ”  StepLR applied â€” epoch 62, learning rate set to 0.05000

Epoch 63/200

Epoch 63: val_accuracy did not improve from 0.80580

Epoch 63: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_63.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_63

ğŸ•’  Recording time at 09:09

313/313 - 8s - 26ms/step - accuracy: 0.9434 - loss: 0.4265 - val_accuracy: 0.7942 - val_loss: 1.0103

ğŸ”  StepLR applied â€” epoch 63, learning rate set to 0.05000

Epoch 64/200

Epoch 64: val_accuracy did not improve from 0.80580

Epoch 64: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_64.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_64

ğŸ•’  Recording time at 09:09

313/313 - 8s - 26ms/step - accuracy: 0.9464 - loss: 0.4238 - val_accuracy: 0.7230 - val_loss: 1.4881

ğŸ”  StepLR applied â€” epoch 64, learning rate set to 0.05000

Epoch 65/200

Epoch 65: val_accuracy did not improve from 0.80580

Epoch 65: saving model to /content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/epoch_65.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_65

ğŸ•’  Recording time at 09:09

313/313 - 8s - 26ms/step - accuracy: 0.9459 - loss: 0.4249 - val_accuracy: 0.7574 - val_loss: 1.3585
Epoch 65: early stopping
Restoring model weights from the end of the best epoch: 50.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ“¥  Restored best model from:
/content/drive/MyDrive/src/cifar-susume/artifact/checkpoint/m9_r3_m9_drop/best.keras

ğŸ¯  evaluate_model

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 9,
    "run": 3,
    "config_name": "m9_drop",
    "date": "2025-05-26",
    "time": "05:39:33",
    "duration": "0:03:27",
    "parameters": {
      "LIGHT_MODE": false,
      "AUGMENT_MODE": {
        "enabled": true,
        "random_crop": true,
        "random_flip": true,
        "cutout": false
      },
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0001
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": null,
        "patience": null,
        "min_lr": null
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 15,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 160
      },
      "TTA_MODE": {
        "enabled": false,
        "runs": 5
      },
      "EPOCHS_COUNT": 200,
      "BATCH_SIZE": 128
    },
    "min_train_loss": 0.39833468198776245,
    "min_train_loss_epoch": 46,
    "max_train_acc": 0.9543250203132629,
    "max_train_acc_epoch": 46,
    "min_val_loss": 0.8389862179756165,
    "min_val_loss_epoch": 50,
    "max_val_acc": 0.8058000206947327,
    "max_val_acc_epoch": 50,
    "final_test_loss": 0.8774023652076721,
    "final_test_acc": 0.8055999875068665
  }
]

âœ…   m9 run 3 with 'm9_drop' successfully executed

ğŸ“¦   Completed 5 total experiment runs
