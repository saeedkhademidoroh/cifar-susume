
📜  Logging experiment output:
/home/saeed/projects/ml/src/cifar-susume/artifact/log/log_2025-05-24_17-14-34.txt

🎯  _load_previous_results

⚙️   Piplining experiment 1/1

🎯  _run_single_pipeline_entry

🎯  load_config

📂  Loading configuration file:
/home/saeed/projects/ml/src/cifar-susume/artifact/config/default.json

🎯  _ensure_output_directories

📂  Ensuring output directories
/home/saeed/projects/ml/src/cifar-susume/artifact/log
/home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint
/home/saeed/projects/ml/src/cifar-susume/artifact/result
/home/saeed/projects/ml/src/cifar-susume/artifact/model
/home/saeed/projects/ml/src/cifar-susume/artifact/error

🚀  Launching experiment m9_r1 with 'default'

🎯  build_dataset
Files already downloaded and verified
Files already downloaded and verified

🎯  build_model

Model: "functional"
┏━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━┓
┃                ┃               ┃  Param ┃               ┃
┃ Layer (type)   ┃ Output Shape  ┃      # ┃ Connected to  ┃
┡━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━┩
│ input_layer    │ (None, 32,    │      0 │ -             │
│ (InputLayer)   │ 32, 3)        │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d         │ (None, 32,    │    448 │ input_layer[… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d[0][0]  │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation     │ (None, 32,    │      0 │ batch_normal… │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_1       │ (None, 32,    │  2,320 │ activation[0… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_1[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_1   │ (None, 32,    │      0 │ batch_normal… │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_2       │ (None, 32,    │  2,320 │ activation_1… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_2[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add (Add)      │ (None, 32,    │      0 │ batch_normal… │
│                │ 32, 16)       │        │ activation[0… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_2   │ (None, 32,    │      0 │ add[0][0]     │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_3       │ (None, 32,    │  2,320 │ activation_2… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_3[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_3   │ (None, 32,    │      0 │ batch_normal… │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_4       │ (None, 32,    │  2,320 │ activation_3… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_4[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_1 (Add)    │ (None, 32,    │      0 │ batch_normal… │
│                │ 32, 16)       │        │ activation_2… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_4   │ (None, 32,    │      0 │ add_1[0][0]   │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_5       │ (None, 32,    │  2,320 │ activation_4… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_5[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_5   │ (None, 32,    │      0 │ batch_normal… │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_6       │ (None, 32,    │  2,320 │ activation_5… │
│ (Conv2D)       │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 32,    │     64 │ conv2d_6[0][… │
│ (BatchNormali… │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_2 (Add)    │ (None, 32,    │      0 │ batch_normal… │
│                │ 32, 16)       │        │ activation_4… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_6   │ (None, 32,    │      0 │ add_2[0][0]   │
│ (Activation)   │ 32, 16)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_7       │ (None, 16,    │  4,640 │ activation_6… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_7[0][… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_7   │ (None, 16,    │      0 │ batch_normal… │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_8       │ (None, 16,    │  9,248 │ activation_7… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_8[0][… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_9       │ (None, 16,    │    544 │ activation_6… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_3 (Add)    │ (None, 16,    │      0 │ batch_normal… │
│                │ 16, 32)       │        │ conv2d_9[0][… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_8   │ (None, 16,    │      0 │ add_3[0][0]   │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_10      │ (None, 16,    │  9,248 │ activation_8… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_10[0]… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_9   │ (None, 16,    │      0 │ batch_normal… │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_11      │ (None, 16,    │  9,248 │ activation_9… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_11[0]… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_4 (Add)    │ (None, 16,    │      0 │ batch_normal… │
│                │ 16, 32)       │        │ activation_8… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_10  │ (None, 16,    │      0 │ add_4[0][0]   │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_12      │ (None, 16,    │  9,248 │ activation_1… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_12[0]… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_11  │ (None, 16,    │      0 │ batch_normal… │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_13      │ (None, 16,    │  9,248 │ activation_1… │
│ (Conv2D)       │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 16,    │    128 │ conv2d_13[0]… │
│ (BatchNormali… │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_5 (Add)    │ (None, 16,    │      0 │ batch_normal… │
│                │ 16, 32)       │        │ activation_1… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_12  │ (None, 16,    │      0 │ add_5[0][0]   │
│ (Activation)   │ 16, 32)       │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_14      │ (None, 8, 8,  │ 18,496 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_14[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_13  │ (None, 8, 8,  │      0 │ batch_normal… │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_15      │ (None, 8, 8,  │ 36,928 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_15[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_16      │ (None, 8, 8,  │  2,112 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_6 (Add)    │ (None, 8, 8,  │      0 │ batch_normal… │
│                │ 64)           │        │ conv2d_16[0]… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_14  │ (None, 8, 8,  │      0 │ add_6[0][0]   │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_17      │ (None, 8, 8,  │ 36,928 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_17[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_15  │ (None, 8, 8,  │      0 │ batch_normal… │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_18      │ (None, 8, 8,  │ 36,928 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_18[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_7 (Add)    │ (None, 8, 8,  │      0 │ batch_normal… │
│                │ 64)           │        │ activation_1… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_16  │ (None, 8, 8,  │      0 │ add_7[0][0]   │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_19      │ (None, 8, 8,  │ 36,928 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_19[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_17  │ (None, 8, 8,  │      0 │ batch_normal… │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ conv2d_20      │ (None, 8, 8,  │ 36,928 │ activation_1… │
│ (Conv2D)       │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ batch_normali… │ (None, 8, 8,  │    256 │ conv2d_20[0]… │
│ (BatchNormali… │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ add_8 (Add)    │ (None, 8, 8,  │      0 │ batch_normal… │
│                │ 64)           │        │ activation_1… │
├────────────────┼───────────────┼────────┼───────────────┤
│ activation_18  │ (None, 8, 8,  │      0 │ add_8[0][0]   │
│ (Activation)   │ 64)           │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ global_averag… │ (None, 64)    │      0 │ activation_1… │
│ (GlobalAverag… │               │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ dropout        │ (None, 64)    │      0 │ global_avera… │
│ (Dropout)      │               │        │               │
├────────────────┼───────────────┼────────┼───────────────┤
│ dense (Dense)  │ (None, 10)    │    650 │ dropout[0][0] │
└────────────────┴───────────────┴────────┴───────────────┘
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

🎯  train_model

🎯  _resume_from_checkpoint

🎯  _load_from_checkpoint

🎯  _split_dataset

🎯  _prepare_checkpoint_callback

🎯  __init__ (RecoveryCheckpoint)

🧠  Printing training configuration:
Light Mode:         ON — Using reduced dataset for fast testing
Augmentation:       ON — Random crop, flip, and Cutout enabled
L2 Regularization:  ON (λ = 0.0005)
Dropout:            ON (rate = 0.3)
Optimizer:          SGD (lr = 0.05)
Momentum:           0.9
LR Scheduler:       ON — warmup for 5 epochs, decay factor 0.5
Early Stopping:     ON — patience 10 epochs, restore best weights: True
Weight Averaging:   ON — starting at epoch 170
Test-Time Augment:  ON — running 5 augmented passes per sample
Epochs:             4
Batch Size:         4

🔁  StepLR applied — epoch 0, learning rate set to 0.05000

⏫  Warmup applied — epoch 0, learning rate set to 0.01000

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.20200, saving model to /home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint/m9_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint/m9_r1_default/epoch_01.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_1

🕒  Recording time at 17:15

1000/1000 - 45s - 45ms/step - accuracy: 0.1475 - loss: 2.6623 - val_accuracy: 0.2020 - val_loss: 3.0123

🔁  StepLR applied — epoch 1, learning rate set to 0.05000

⏫  Warmup applied — epoch 1, learning rate set to 0.02000

Epoch 2/4

Epoch 2: val_accuracy did not improve from 0.20200

Epoch 2: saving model to /home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint/m9_r1_default/epoch_02.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_2

🕒  Recording time at 17:15

1000/1000 - 34s - 34ms/step - accuracy: 0.1678 - loss: 2.5004 - val_accuracy: 0.1620 - val_loss: 2.9121

🔁  StepLR applied — epoch 2, learning rate set to 0.05000

⏫  Warmup applied — epoch 2, learning rate set to 0.03000

Epoch 3/4

Epoch 3: val_accuracy did not improve from 0.20200

Epoch 3: saving model to /home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint/m9_r1_default/epoch_03.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_3

🕒  Recording time at 17:16

1000/1000 - 35s - 35ms/step - accuracy: 0.1647 - loss: 2.4117 - val_accuracy: 0.2000 - val_loss: 2.3204

🔁  StepLR applied — epoch 3, learning rate set to 0.05000

⏫  Warmup applied — epoch 3, learning rate set to 0.04000

Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.20200

Epoch 4: saving model to /home/saeed/projects/ml/src/cifar-susume/artifact/checkpoint/m9_r1_default/epoch_04.keras

🎯  on_epoch_end

💾  Checkpointing experiment at epoch_4

🕒  Recording time at 17:17

1000/1000 - 31s - 31ms/step - accuracy: 0.1845 - loss: 2.3526 - val_accuracy: 0.1310 - val_loss: 2.9453
Restoring model weights from the end of the best epoch: 1.

🎯  _save_training_history

🎯  extract_history_metrics

🎯  _create_evaluation_dictionary

📊  Dumping experiment results:
[
  {
    "model": 9,
    "run": 1,
    "config_name": "default",
    "date": "2025-05-24",
    "time": "17:17:08",
    "duration": "0:02:34",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.3
      },
      "OPTIMIZER": {
        "type": "sgd",
        "learning_rate": 0.05,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": {
        "enabled": true,
        "warmup_epochs": 5,
        "factor": 0.5,
        "patience": 3,
        "min_lr": 1e-05
      },
      "EARLY_STOP_MODE": {
        "enabled": true,
        "patience": 10,
        "restore_best_weights": true
      },
      "AVERAGE_MODE": {
        "enabled": true,
        "start_epoch": 170
      },
      "TTA_MODE": {
        "enabled": true,
        "runs": 5
      },
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.3526418209075928,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.18449999392032623,
    "max_train_acc_epoch": 4,
    "min_val_loss": 2.320371389389038,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.20200000703334808,
    "max_val_acc_epoch": 1,
    "final_test_loss": 4.007192611694336,
    "final_test_acc": 0.1940000057220459
  }
]

✅   m9 run 1 with 'default' successfully executed
