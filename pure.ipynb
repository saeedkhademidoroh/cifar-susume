{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ddfc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Load and normalize data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train, x_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "std = np.array([0.2023, 0.1994, 0.2010])\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "x_val, y_val = x_train[-5000:], y_train[-5000:]\n",
    "x_train, y_train = x_train[:-5000], y_train[:-5000]\n",
    "\n",
    "# One-hot encode with label smoothing\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_val = tf.keras.utils.to_categorical(y_val, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Augmentation: CutMix + light color jitter\n",
    "def color_jitter(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hsv = hsv.astype(np.float32)\n",
    "    hsv[..., 1] *= np.random.uniform(0.9, 1.1)  # saturation\n",
    "    hsv[..., 2] *= np.random.uniform(0.9, 1.1)  # brightness\n",
    "    hsv = np.clip(hsv, 0, 255).astype(np.uint8)\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)\n",
    "\n",
    "def cutmix(images, labels, alpha=1.0):\n",
    "    batch_size = images.shape[0]\n",
    "    indices = tf.random.shuffle(tf.range(batch_size))\n",
    "    shuffled_images = tf.gather(images, indices)\n",
    "    shuffled_labels = tf.gather(labels, indices)\n",
    "\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    rx, ry = np.random.randint(32), np.random.randint(32)\n",
    "    rw, rh = int(32 * np.sqrt(1 - lam)), int(32 * np.sqrt(1 - lam))\n",
    "    x1, y1 = np.clip(rx - rw // 2, 0, 32), np.clip(ry - rh // 2, 0, 32)\n",
    "    x2, y2 = np.clip(rx + rw // 2, 0, 32), np.clip(ry + rh // 2, 0, 32)\n",
    "\n",
    "    images[:, y1:y2, x1:x2, :] = shuffled_images[:, y1:y2, x1:x2, :]\n",
    "    lam = 1 - ((x2 - x1) * (y2 - y1) / (32 * 32))\n",
    "    labels = lam * labels + (1 - lam) * shuffled_labels\n",
    "    return images, labels\n",
    "\n",
    "def augment_batch(images, labels):\n",
    "    batch = []\n",
    "    for img in images:\n",
    "        img = (img * std + mean) * 255.0\n",
    "        img = img.astype(np.uint8)\n",
    "        img = tf.image.random_flip_left_right(img)\n",
    "        img = tf.image.pad_to_bounding_box(img, 4, 4, 40, 40)\n",
    "        img = tf.image.random_crop(img, [32, 32, 3])\n",
    "        img = color_jitter(img.numpy())\n",
    "        img = (img.astype(np.float32) / 255.0 - mean) / std\n",
    "        batch.append(img)\n",
    "    batch = np.stack(batch)\n",
    "    return cutmix(batch, labels)\n",
    "\n",
    "def data_generator(x, y, batch_size):\n",
    "    while True:\n",
    "        idx = np.random.permutation(len(x))\n",
    "        x, y = x[idx], y[idx]\n",
    "        for i in range(0, len(x), batch_size):\n",
    "            images, labels = x[i:i+batch_size], y[i:i+batch_size]\n",
    "            yield augment_batch(images, labels)\n",
    "\n",
    "# Model\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(3):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(32, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(64, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, weight_decay=5e-4),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 0.1 if epoch < 82 else (0.01 if epoch < 123 else 0.001)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    data_generator(x_train, y_train, 128),\n",
    "    steps_per_epoch=len(x_train) // 128,\n",
    "    epochs=164,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_schedule],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.load_weights(\"best_model.h5\")\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=100, verbose=2)\n",
    "print(f\"\\n✅ Final test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# ✅ Experiment 3 — Advanced Augmentations\n",
    "\n",
    "#     Augmentation: CutMix + Color Jitter + Label Smoothing\n",
    "\n",
    "#     Loss: CategoricalCrossentropy with label_smoothing=0.1\n",
    "\n",
    "#     Optimizer: SGD + momentum, weight_decay=5e-4\n",
    "\n",
    "#     Batching: Custom generator\n",
    "\n",
    "#     Accuracy: 91.73% (final test accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28265d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=4/32,\n",
    "    height_shift_range=4/32,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"reflect\"\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(3):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(32, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(64, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, weight_decay=5e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\", verbose=1\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 0.1 if epoch < 82 else (0.01 if epoch < 123 else 0.001)\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),\n",
    "    epochs=164,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[checkpoint, lr_schedule],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "model.load_weights(\"best_model.h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=100, verbose=2)\n",
    "print(f\"\\n✅ Final test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "#  Experiment 2 — Tuned Regularization\n",
    "\n",
    "#     Augmentation: Standard flip + shift (ImageDataGenerator)\n",
    "\n",
    "#     Loss: SparseCategoricalCrossentropy\n",
    "\n",
    "#     Optimizer: SGD + momentum, weight_decay=5e-4\n",
    "\n",
    "#     Checkpointing: Enabled\n",
    "\n",
    "#     Accuracy: 90.90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50900706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std = [0.2023, 0.1994, 0.2010]\n",
    "x_train = (x_train - mean) / std\n",
    "x_test = (x_test - mean) / std\n",
    "\n",
    "# Split 5,000 samples from training set for validation\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    width_shift_range=4/32,\n",
    "    height_shift_range=4/32,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"reflect\"\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "inputs = layers.Input(shape=(32, 32, 3))\n",
    "x = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(3):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(16, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(32, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(32, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(32, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "shortcut = layers.Conv2D(64, 1, strides=2, use_bias=False)(x)\n",
    "shortcut = layers.BatchNormalization()(shortcut)\n",
    "x = layers.Conv2D(64, 3, strides=2, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.add([shortcut, x])\n",
    "x = layers.ReLU()(x)\n",
    "\n",
    "for _ in range(2):\n",
    "    shortcut = x\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(x)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.ReLU()(y)\n",
    "    y = layers.Conv2D(64, 3, padding=\"same\", use_bias=False)(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    x = layers.add([shortcut, y])\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = models.Model(inputs, outputs)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9, weight_decay=1e-4),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),\n",
    "    epochs=164,\n",
    "    validation_data=(x_val, y_val),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.LearningRateScheduler(\n",
    "            lambda epoch: 0.1 if epoch < 82 else (0.01 if epoch < 123 else 0.001)\n",
    "        )\n",
    "    ],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Final test set evaluation\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, batch_size=100, verbose=2)\n",
    "print(f\"\\n✅ Final test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "#  Experiment 1 — Baseline ResNet-20\n",
    "\n",
    "#     Augmentation: Standard flip + shift (ImageDataGenerator)\n",
    "\n",
    "#     Loss: SparseCategoricalCrossentropy\n",
    "\n",
    "#     Optimizer: SGD + momentum, weight_decay=1e-4\n",
    "\n",
    "#     Accuracy: 90.39%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
